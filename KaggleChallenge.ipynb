{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime as dt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">1. Preprocessing </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color:indigo\"> 1.1 Dataset observation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lecture du fichier .csv par la libraire Pandas\n",
    "data=pd.read_csv('train.csv')\n",
    "df1=copy.deepcopy(data)\n",
    "data_test=pd.read_csv('evaluation.csv')\n",
    "df_test1=copy.deepcopy(data_test)\n",
    "\n",
    "#We need to separate X and Y\n",
    "#X=data.loc[:,data.columns!=\"retweets_count\"]\n",
    "#Y=data['retweets_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">1.2 Features explanations </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.quantile(0.99) #We check if there is a lot ludicrous values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#If our dataset contains empty values, we put the mean value of the collum\n",
    "if df.isnull().sum().sum()!=0: \n",
    "    imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "else: \n",
    "    print(\"No missing_values in this dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "corr_matrix = df.corr()\n",
    "plt.figure(figsize=(28,24))\n",
    "sns.heatmap(data = corr_matrix,cmap='BrBG', annot=True, linewidths=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ------> We observe that the only strong correlation that we can see at this time is the one between [favorite_count] \n",
    "and [retweet_count] , so we can already say that to predict the number of retweet, the number of favorite count is very important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#checking for missing values in output\n",
    "for i in range(df.shape[0]):\n",
    "    if df['retweets_count'][i]==[]:\n",
    "        print(df['retweets_count'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">1.3 Normalisations </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On doit normaliser les données mais chaque colonne doit être normalisé différemment. \n",
    "- \"favorites_count\" -> moins de 1% de valeurs abhérantes (au top)\n",
    "- \"followers_count\", -> Exponential \n",
    "- \"statutes_count\",\n",
    "- \"friends_count\" -> moins de 1% de valeurs abhérantes (au top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization.quantile(0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_into_df(D):\n",
    "    result=pd.DataFrame(D, columns=[\"month\", \"day\", \"moment\"]) \n",
    "    #the command above tells you you initialise result with the same number of lines as D\n",
    "    #and you take its columns \"month\"... only , but as they do not exist it will be filled with NaN\n",
    "    timestamps=np.array(D[\"timestamp\"])\n",
    "    \n",
    "    for i in range(timestamps.shape[0]):\n",
    "        date=dt.fromtimestamp(timestamps[i]/1000)\n",
    "        result[\"month\"][i]=date.month\n",
    "        result[\"day\"][i]=date.day\n",
    "        result[\"moment\"][i]=date.hour+date.minute/60\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(x):\n",
    "     return np.log(1+x)\n",
    "\n",
    "def Normaliser(Df, Df_test):\n",
    "    \n",
    "    D=copy.deepcopy(Df)\n",
    "    D_test=copy.deepcopy(Df_test)\n",
    "    \n",
    "    column_names=[\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\"]\n",
    "    \n",
    "    #Create DFs and apply log to them\n",
    "    \n",
    "    Norm_train=pd.DataFrame(D,columns=[\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\"])\n",
    "    Norm_train['favorites_count'] = Norm_train['favorites_count'].transform(myfunc)\n",
    "    Norm_train['followers_count'] = Norm_train['followers_count'].transform(myfunc)\n",
    "    Norm_train['friends_count'] = Norm_train['friends_count'].transform(myfunc)\n",
    "    Norm_train['statuses_count'] = Norm_train['statuses_count'].transform(myfunc)\n",
    "    \n",
    "    Norm_rt=pd.DataFrame(D,columns=[\"retweets_count\"])\n",
    "    Norm_rt['retweets_count'] = Norm_rt['retweets_count'].transform(myfunc)\n",
    "    \n",
    "    Norm_test=pd.DataFrame(D_test,columns=[\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\"])\n",
    "    Norm_test['favorites_count'] = Norm_test['favorites_count'].transform(myfunc)\n",
    "    Norm_test['followers_count'] = Norm_test['followers_count'].transform(myfunc)\n",
    "    Norm_test['friends_count'] = Norm_test['friends_count'].transform(myfunc)\n",
    "    Norm_test['statuses_count'] = Norm_test['statuses_count'].transform(myfunc)\n",
    "    \n",
    "    #Also add time\n",
    "    \n",
    "    Time_train=get_time_into_df(D)\n",
    "    Time_test=get_time_into_df(D_test)\n",
    "    \n",
    "    #Now rescale with min-max\n",
    "    \n",
    "    scaler_train=MinMaxScaler()\n",
    "    scaler_train.fit(Norm_train)\n",
    "    norm_train=scaler_train.transform(Norm_train)\n",
    "    norm_test=scaler_train.transform(Norm_test)\n",
    "    \n",
    "    scaler_rt=MinMaxScaler()\n",
    "    scaler_rt.fit(Norm_rt)\n",
    "    norm_rt=scaler_rt.transform(Norm_rt)\n",
    "    \n",
    "    scaler_time=MinMaxScaler()\n",
    "    scaler_time.fit(Time_train)\n",
    "    norm_time_train=scaler_time.transform(Time_train)\n",
    "    norm_time_test=scaler_time.transform(Time_test)\n",
    "    \n",
    "    #Now put the rescaled results into the original DFs\n",
    "    \n",
    "    Norm_train=pd.DataFrame(norm_train,columns=column_names)\n",
    "    Norm_test=pd.DataFrame(norm_test,columns=column_names)\n",
    "    Norm_rt=pd.DataFrame(norm_rt,columns=[\"retweets_count\"])\n",
    "    \n",
    "    NormT_train=pd.DataFrame(norm_time_train,columns=[\"month\", \"day\", \"moment\"])\n",
    "    NormT_test=pd.DataFrame(norm_time_test,columns=[\"month\", \"day\", \"moment\"])\n",
    "    \n",
    "    D['favorites_count']=Norm_train['favorites_count']\n",
    "    D['followers_count']=Norm_train['followers_count'] \n",
    "    D['statuses_count']=Norm_train['statuses_count']\n",
    "    D['friends_count']=Norm_train['friends_count']\n",
    "    D['retweets_count']=Norm_rt['retweets_count']\n",
    "    \n",
    "    D_test['favorites_count']=Norm_test['favorites_count']\n",
    "    D_test['followers_count']=Norm_test['followers_count'] \n",
    "    D_test['statuses_count']=Norm_test['statuses_count']\n",
    "    D_test['friends_count']=Norm_test['friends_count']\n",
    "    \n",
    "    D[\"month\"]=NormT_train[\"month\"]\n",
    "    D[\"day\"]=NormT_train[\"day\"]\n",
    "    D[\"moment\"]=NormT_train[\"moment\"]\n",
    "    \n",
    "    D_test[\"month\"]=NormT_test[\"month\"]\n",
    "    D_test[\"day\"]=NormT_test[\"day\"]\n",
    "    D_test[\"moment\"]=NormT_test[\"moment\"]\n",
    "\n",
    "    return D, D_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF, DF_test= Normaliser(df1,df_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">2. PCA Text and # treatment </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:indigo\">2.1 Preprocessing of hashtags and texts </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for hashtags\n",
    "\n",
    "def most_important_hashtags(df, criteria):\n",
    "    DICO2={} #DICO2 is for hashtags\n",
    "    I=df.shape[0]\n",
    "    for i in range(I):\n",
    "        sentence=df[\"hashtags\"][i][1:-1].replace(' ', '').split(',')\n",
    "        for word in sentence:\n",
    "            extracted_word=word[1:-1]\n",
    "            if extracted_word in DICO2:\n",
    "                DICO2[extracted_word]+=1\n",
    "            else:\n",
    "                DICO2[extracted_word]=1\n",
    "    most_occurr_DICO2={}\n",
    "    for word in DICO2:\n",
    "        if DICO2[word]>criteria :#and word!=''\n",
    "            most_occurr_DICO2[word]=0\n",
    "    \n",
    "    important_hashtags=list(most_occurr_DICO2.keys())\n",
    "    \n",
    "    measurer2={}\n",
    "    for i in range(len(important_hashtags)):\n",
    "        measurer2[important_hashtags[i]]=i\n",
    "    measurer2\n",
    "    return important_hashtags, measurer2\n",
    "\n",
    "def make_array_training_hashtags(df, criteria):\n",
    "    possibilities, measurer=most_important_hashtags(df, criteria)\n",
    "    result=np.zeros((df.shape[0], len(possibilities)))\n",
    "    for line in range(df.shape[0]):\n",
    "        sentence=df[\"hashtags\"][line][1:-1].replace(' ', '').split(',')\n",
    "        for word in sentence:\n",
    "            extracted_word=word[1:-1]\n",
    "            if extracted_word in possibilities:\n",
    "                result[line,measurer[extracted_word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "def make_array_test_hashtags(df_test, criteria):\n",
    "    possibilities, measurer=most_important_hashtags(df, criteria)\n",
    "    result=np.zeros((df_test.shape[0], len(possibilities)))\n",
    "    for line in range(df_test.shape[0]):\n",
    "        sentence=df_test[\"hashtags\"][line][1:-1].replace(' ', '').split(',')\n",
    "        for word in sentence:\n",
    "            extracted_word=word[1:-1]\n",
    "            if extracted_word in possibilities:\n",
    "                result[line,measurer[extracted_word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "array_train_hashtags=make_array_training_hashtags(DF,10)\n",
    "array_test_hashtags=make_array_test_hashtags(DF_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for texts\n",
    "\n",
    "def most_important_words(df, criteria):\n",
    "    DICO={}\n",
    "    I=df.shape[0]\n",
    "    for i in range(I):\n",
    "        sentence=df[\"text\"][i].split()\n",
    "        for word in sentence:\n",
    "            if word in DICO:\n",
    "                DICO[word]+=1\n",
    "            else:\n",
    "                DICO[word]=1\n",
    "            \n",
    "    most_occurr_DICO={}\n",
    "    for word in DICO:\n",
    "        if DICO[word]>criteria:\n",
    "            most_occurr_DICO[word]=0\n",
    "    \n",
    "    important_words=list(most_occurr_DICO.keys())\n",
    "    measurer={}\n",
    "    for i in range(len(important_words)):\n",
    "        measurer[important_words[i]]=i\n",
    "    measurer\n",
    "    \n",
    "    return important_words, measurer\n",
    "\n",
    "def make_array_training_words(df, criteria):\n",
    "    possibilities, measurer=most_important_words(df, criteria)\n",
    "    result=np.zeros((df.shape[0], len(possibilities)))\n",
    "    for line in range(df.shape[0]):\n",
    "        sentence=df[\"text\"][line].split()\n",
    "        for word in sentence:\n",
    "            if word in possibilities:\n",
    "                result[line,measurer[word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "def make_array_test_words(df_test, criteria):\n",
    "    possibilities, measurer=most_important_words(df, criteria)\n",
    "    result=np.zeros((df_test.shape[0], len(possibilities)))\n",
    "    for line in range(df_test.shape[0]):\n",
    "        sentence=df_test[\"text\"][line].split()\n",
    "        for word in sentence:\n",
    "            if word in possibilities:\n",
    "                result[line,measurer[word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "array_train_text=make_array_training_words(DF,5000)\n",
    "array_test_text=make_array_test_words(DF_test, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "## <span style=\"color:indigo\">2.2 PCA on words and hashtags: Understanding the main components of bags of words </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_training(array, n_comp):\n",
    "    n=array.shape[1]\n",
    "    for col in range(n):\n",
    "        mean=np.mean(array[:,col])\n",
    "        array[:,col]-=mean\n",
    "            \n",
    "    C=np.matmul(array.T,array)\n",
    "    C/=array.shape[1]\n",
    "    \n",
    "    Lambda, Q=np.linalg.eigh(C)\n",
    "\n",
    "    Qk=np.zeros((n,n_comp))\n",
    "    for col in range(n_comp):\n",
    "        Qk[:,col]=Q[:,n-col-1]\n",
    "    return np.matmul(array,Qk), Qk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_test(training_array, test_array, n_comp):\n",
    "    return np.matmul(test_array,PCA_training(training_array,n_comp)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_TRAIN_TEXT=PCA_training(array_train_text, 4)\n",
    "PCA_TRAIN_HASHTAGS=PCA_training(array_train_hashtags, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA_TEST_TEXT=PCA_test(array_train_text, array_test_text, 4)\n",
    "PCA_TEST_HASHTAGS=PCA_test(array_train_hashtags, array_test_hashtags, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">3. Preparing RNN on word sequences: Understanding relations between words </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:indigo\"> 3.1 Pre-treatment for word embedding </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the FastText method. We divide each word into groups of 3 letters (spaces are the \"empty letter\"). We keep the order in the text and make an embedding also using the adjacent words. For instance:\n",
    "\"macron demission\"==> -ma,mac,acr,...,on-,n-d,-de,dem,... (- is the empty letter)\n",
    "\n",
    "The fast text method will guess the adjacent 3 letters to each given patch of 3 letters. Hence for \"mac\" we want a high probability of \"---\" (3 times empty letter) and \"ron\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  device = \"cuda:0\" \n",
    "else:  \n",
    "  device = \"cpu\"  \n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns an array with the words in the sentence cut (n=3 that is in pieces of 3)\n",
    "\n",
    "def cutter(sent, n):\n",
    "    sentence=sent.split()\n",
    "    length=len(sentence)+2-n\n",
    "    for word in sentence:\n",
    "        length+=len(word)\n",
    "    result=[]\n",
    "    padding=''\n",
    "    for i in range(n):\n",
    "        padding+=' '\n",
    "    sent=' '+sent+' '\n",
    "    padd_sent=padding+sent+padding\n",
    "    \n",
    "    for i in range(length):\n",
    "        middle=sent[i:i+n]\n",
    "        before=padd_sent[i:i+n]\n",
    "        after=padd_sent[2*n+i:3*n+i]\n",
    "        result.append([before, middle, after])\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphabet=30\n",
    "\n",
    "def batch_maker(size):\n",
    "    X=np.zeros((size,3*n_alphabet))\n",
    "    Y=np.zeros((size,6*n_alphabet))\n",
    "    for i in range(size):\n",
    "        \n",
    "        line=random.randrange(0,350000)\n",
    "        cut=cutter(df[\"text\"][line],3)\n",
    "        \n",
    "        alphabet={\n",
    "        ' ':0,'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,\n",
    "        'o':15,'p':16,'q':17,'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26,'é':27,\n",
    "        'è':28,\n",
    "        #thus use mod 30 (as 29 is for any other letter (arabic...))\n",
    "        }\n",
    "        \n",
    "        possibilities=[        \n",
    "        ' ','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x',\n",
    "        'y','z','é','è',]\n",
    "        \n",
    "        length=cut.shape[0]\n",
    "        word_index=random.randrange(0,length)\n",
    "        \n",
    "        word0=cut[word_index, 0]\n",
    "        word1=cut[word_index, 1]\n",
    "        word2=cut[word_index, 2]\n",
    "        for letter_ind in range(3):\n",
    "            index0=0\n",
    "            index1=0\n",
    "            index2=0\n",
    "            if (word0[letter_ind] not in possibilities):\n",
    "                index0=29\n",
    "            else:\n",
    "                index0=alphabet[word0[letter_ind]]\n",
    "                \n",
    "            if (word1[letter_ind] not in possibilities):\n",
    "                index1=29\n",
    "            else:\n",
    "                index1=alphabet[word1[letter_ind]]\n",
    "                \n",
    "            if (word2[letter_ind] not in possibilities):\n",
    "                index2=29\n",
    "            else:\n",
    "                index2=alphabet[word2[letter_ind]]\n",
    "                \n",
    "            Y[i,letter_ind*n_alphabet+index0]=1\n",
    "            X[i,letter_ind*n_alphabet+index1]=1\n",
    "            Y[i,3*n_alphabet+letter_ind*n_alphabet+index2]=1\n",
    "        \n",
    "    return torch.tensor(X, requires_grad=True).float(),torch.tensor(Y, requires_grad=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 90])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_maker(100)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\"> 3.2 Encoder/decoder to mimic FastText</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model takes a \"word\" (3 letters patch) as input and return a size 100 vector who is encoded to take into consideration the past and future patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class embedd(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        #A sequential container: Modules will be added to it in the order they are passed in the constructor. \n",
    "        self.encoder=nn.Sequential(\n",
    "            \n",
    "        nn.Linear(3*n_alphabet,70,bias=True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(70,45,bias=True),\n",
    "        nn.Sigmoid())\n",
    "        \n",
    "        self.decoder=nn.Sequential(\n",
    "        \n",
    "        nn.Linear(45,110, bias=True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(110,6*n_alphabet,bias=True),\n",
    "        )\n",
    "        \n",
    "        #The forward() method of Sequential accepts \n",
    "        #any input and forwards it to the first module it contains.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x=self.encoder(x)\n",
    "        x=self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# PARAMS\n",
    "\n",
    "BATCH_SIZE=1000\n",
    "NUM_BACKWARDS=10000\n",
    "LEARNING_RATE=0.001\n",
    "\n",
    "LOAD_MODEL = True\n",
    "\n",
    "###############\n",
    "\n",
    "loss_list=[]\n",
    "Emb=embedd().to(device)\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    Emb.load_state_dict(torch.load(\"Model.h5\"))\n",
    "else:\n",
    "    Emb.train()\n",
    "    optimizer = Adam(Emb.parameters(),lr=LEARNING_RATE)\n",
    "\n",
    "    for n in tqdm(range(NUM_BACKWARDS)):\n",
    "        \n",
    "        x,y_target=batch_maker(BATCH_SIZE)\n",
    "        x = x.to(device) #we put the model and the variable on the gpu\n",
    "        y=Emb(x)\n",
    "        y = y.to(device)\n",
    "        y_target = y_target.to(device) #because we use y_target after and we neet to put it on the gpu\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss_func=nn.CrossEntropyLoss()\n",
    "        loss1_target = (y_target[:,:n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "        loss2_target = (y_target[:,n_alphabet:2*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "        loss3_target = (y_target[:,2*n_alphabet:3*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "        \n",
    "        loss4_target = (y_target[:,3*n_alphabet:4*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "        loss5_target = (y_target[:,4*n_alphabet:5*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "        loss6_target = (y_target[:,5*n_alphabet:6*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "\n",
    "        loss1=loss_func(y[:,:n_alphabet],loss1_target)\n",
    "        loss2=loss_func(y[:,n_alphabet:2*n_alphabet],loss2_target)\n",
    "        loss3=loss_func(y[:,2*n_alphabet:3*n_alphabet],loss3_target)\n",
    "        \n",
    "        loss4=loss_func(y[:,3*n_alphabet:4*n_alphabet],loss4_target)\n",
    "        loss5=loss_func(y[:,4*n_alphabet:5*n_alphabet],loss5_target)\n",
    "        loss6=loss_func(y[:,5*n_alphabet:6*n_alphabet],loss6_target)\n",
    "        \n",
    "        \n",
    "        loss=(loss1+loss2+loss3+loss4+loss5+loss6)/6\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss.item()) #All this to update the loss plot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(loss_list)\n",
    "        fig.savefig(\"loss plot embedd bigbatch.png\")\n",
    "        plt.close(fig)\n",
    "        \n",
    "        if NUM_BACKWARDS%1000==0:\n",
    "            torch.save(Emb.state_dict(),\"Model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_output(Model, word):\n",
    "\n",
    "    rev_alphabet={0:'_', 1:'a', 2:'b', 3:'c', 4:'d',5:'e',6:'f',7:'g',8:'h',9:'i',10:'j',11:'k',12:'l',\n",
    "                 13:'m',14:'n',15:'o',16:'p',17:'q',18:'r',19:'s',20:'t',21:'u',22:'v',23:'w',24:'x',\n",
    "                 25:'y',26:'z',27:'é',28:'è',29:'others'}\n",
    "\n",
    "    alphabet={\n",
    "            ' ':0,'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,\n",
    "            'o':15,'p':16,'q':17,'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26,'é':27,\n",
    "            'è':28}\n",
    "\n",
    "    possibilities=[        \n",
    "            ' ','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x',\n",
    "            'y','z','é','è',]\n",
    "\n",
    "    inp=np.zeros((1,3*n_alphabet))\n",
    "    for letter_ind in range(3):\n",
    "        if word[letter_ind] in possibilities:\n",
    "            inp[0,letter_ind*n_alphabet+alphabet[word[letter_ind]]]=1\n",
    "        else:\n",
    "            inp[0,letter_ind*n_alphabet+29]=1\n",
    "\n",
    "    inp=torch.tensor(inp, requires_grad=True).float()\n",
    "    y=Model(inp.to(device))\n",
    "    y = y.cpu()\n",
    "\n",
    "    y00=np.argmax(y[:,:n_alphabet].detach().numpy())\n",
    "    y01=np.argmax(y[:,n_alphabet:2*n_alphabet].detach().numpy())\n",
    "    y02=np.argmax(y[:,2*n_alphabet:3*n_alphabet].detach().numpy())\n",
    "    y10=np.argmax(y[:,3*n_alphabet:4*n_alphabet].detach().numpy())\n",
    "    y11=np.argmax(y[:,4*n_alphabet:5*n_alphabet].detach().numpy())\n",
    "    y12=np.argmax(y[:,5*n_alphabet:6*n_alphabet].detach().numpy())\n",
    "\n",
    "    before=rev_alphabet[y00]+rev_alphabet[y01]+rev_alphabet[y02]\n",
    "    after=rev_alphabet[y10]+rev_alphabet[y11]+rev_alphabet[y12]\n",
    "\n",
    "    return before, after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('_ma', 'n__')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Emb = embedd()\n",
    "#Emb.load_state_dict(torch.load(\"C:/Users/feoni/OneDrive/Bureau/Polytechnique/ML/DeepLearning_Project/Model.h5\"))\n",
    "#Emb.eval()\n",
    "\n",
    "find_output(Emb, \"cro\")\n",
    "#Encoder avec plus de perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_encoded(df, line):\n",
    "    \n",
    "    cut=cutter(df[\"text\"][line],3)\n",
    "    length=cut.shape[0]\n",
    "    X=np.zeros((length,3*n_alphabet))\n",
    "    \n",
    "    alphabet={\n",
    "        ' ':0,'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,\n",
    "        'o':15,'p':16,'q':17,'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26,'é':27,\n",
    "        'è':28,\n",
    "        #thus use mod 30 (as 29 is for any other letter (arabic...))\n",
    "        }\n",
    "        \n",
    "    possibilities=[        \n",
    "        ' ','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x',\n",
    "        'y','z','é','è',]\n",
    "\n",
    "    for word_index in range(length):\n",
    "\n",
    "        word=cut[word_index,1]\n",
    "        inp=np.zeros(3*n_alphabet)\n",
    "\n",
    "        for letter_ind in range(3):\n",
    "            \n",
    "            index=0\n",
    "\n",
    "            if (word[letter_ind] not in possibilities):\n",
    "                index0=29\n",
    "            else:\n",
    "                index0=alphabet[word[letter_ind]]   \n",
    "\n",
    "            X[word_index,letter_ind*n_alphabet+index0]=1\n",
    "        \n",
    "    return Emb.encoder(torch.tensor(X, requires_grad=True).float().to(device))#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8223, 0.2261, 0.8208, 0.8241, 0.5557, 0.2595, 0.5573, 0.5733, 0.0806,\n",
       "         0.0239, 0.6891, 0.2196, 0.2209, 0.5990, 0.8919, 0.9206, 0.2708, 0.3076,\n",
       "         0.4675, 0.2187, 0.8067, 0.0669, 0.8678, 0.6768, 0.0477, 0.4120, 0.4137,\n",
       "         0.6062, 0.2296, 0.4518, 0.1442, 0.8090, 0.9532, 0.3318, 0.8183, 0.2753,\n",
       "         0.6855, 0.3344, 0.6050, 0.9705, 0.9005, 0.4857, 0.9307, 0.3302, 0.0529],\n",
       "        [0.9955, 0.1860, 0.9436, 0.8721, 0.2193, 0.6894, 0.8869, 0.2775, 0.8995,\n",
       "         0.8266, 0.8841, 0.3540, 0.6382, 0.8770, 0.6117, 0.2996, 0.0775, 0.9558,\n",
       "         0.5516, 0.8851, 0.6858, 0.4825, 0.8610, 0.0313, 0.3631, 0.3780, 0.5814,\n",
       "         0.4109, 0.8921, 0.9181, 0.1364, 0.9728, 0.8243, 0.1617, 0.3826, 0.0589,\n",
       "         0.4889, 0.7155, 0.8793, 0.3931, 0.5750, 0.4299, 0.2341, 0.5651, 0.5942],\n",
       "        [0.4809, 0.9429, 0.5859, 0.7591, 0.4716, 0.6337, 0.4583, 0.5440, 0.7112,\n",
       "         0.8922, 0.5824, 0.4694, 0.8352, 0.0660, 0.2168, 0.0088, 0.3626, 0.4835,\n",
       "         0.2788, 0.4502, 0.7511, 0.7248, 0.1286, 0.4592, 0.7001, 0.6296, 0.3264,\n",
       "         0.7369, 0.2504, 0.2897, 0.8299, 0.3506, 0.4935, 0.0912, 0.8461, 0.1879,\n",
       "         0.3923, 0.8357, 0.9600, 0.0769, 0.4783, 0.3380, 0.7661, 0.9745, 0.7782],\n",
       "        [0.9873, 0.2331, 0.3788, 0.1151, 0.2498, 0.1232, 0.5050, 0.6209, 0.2413,\n",
       "         0.8431, 0.6340, 0.5360, 0.8635, 0.0548, 0.6271, 0.0152, 0.3528, 0.4025,\n",
       "         0.0090, 0.5703, 0.0203, 0.2172, 0.1768, 0.0359, 0.8073, 0.8692, 0.6401,\n",
       "         0.7610, 0.3078, 0.7508, 0.1674, 0.7330, 0.1808, 0.2681, 0.7831, 0.1619,\n",
       "         0.7058, 0.2165, 0.9635, 0.1259, 0.3816, 0.2900, 0.9918, 0.9721, 0.8156],\n",
       "        [0.6651, 0.7736, 0.8693, 0.4679, 0.5446, 0.0716, 0.2399, 0.9357, 0.5625,\n",
       "         0.3440, 0.8839, 0.3960, 0.0260, 0.8460, 0.6582, 0.1376, 0.6212, 0.0930,\n",
       "         0.6558, 0.3617, 0.4471, 0.1643, 0.7778, 0.8767, 0.4346, 0.1540, 0.4545,\n",
       "         0.1520, 0.0211, 0.4268, 0.7671, 0.7420, 0.7045, 0.1067, 0.4262, 0.7994,\n",
       "         0.4078, 0.2572, 0.0781, 0.6029, 0.7214, 0.3948, 0.7273, 0.9614, 0.0454],\n",
       "        [0.9553, 0.2384, 0.2270, 0.9233, 0.0879, 0.1085, 0.3643, 0.7713, 0.2459,\n",
       "         0.0332, 0.5705, 0.2858, 0.3989, 0.7774, 0.9749, 0.9414, 0.6396, 0.4382,\n",
       "         0.3313, 0.2727, 0.3571, 0.4710, 0.9566, 0.3833, 0.1393, 0.2659, 0.4420,\n",
       "         0.1620, 0.5651, 0.0942, 0.1119, 0.7731, 0.6728, 0.4743, 0.6374, 0.2752,\n",
       "         0.5827, 0.0991, 0.8156, 0.9173, 0.8022, 0.1134, 0.8924, 0.3751, 0.1123],\n",
       "        [0.8383, 0.8996, 0.9769, 0.6908, 0.6465, 0.5674, 0.7634, 0.9088, 0.9284,\n",
       "         0.3533, 0.9177, 0.2823, 0.0286, 0.9137, 0.6490, 0.7880, 0.5526, 0.8160,\n",
       "         0.8357, 0.7318, 0.8142, 0.5203, 0.8755, 0.7082, 0.4804, 0.4001, 0.7775,\n",
       "         0.5111, 0.4888, 0.3461, 0.7159, 0.3448, 0.8505, 0.0129, 0.3262, 0.0862,\n",
       "         0.3903, 0.4834, 0.4854, 0.2887, 0.8176, 0.3319, 0.0803, 0.8620, 0.2724],\n",
       "        [0.3938, 0.5153, 0.6444, 0.6405, 0.6439, 0.7971, 0.3264, 0.3619, 0.5468,\n",
       "         0.2691, 0.0853, 0.5695, 0.0412, 0.4846, 0.6697, 0.2818, 0.2827, 0.4190,\n",
       "         0.3362, 0.3297, 0.9447, 0.1137, 0.2899, 0.9121, 0.0836, 0.6107, 0.1021,\n",
       "         0.6037, 0.2528, 0.4792, 0.2921, 0.5142, 0.9273, 0.1971, 0.9316, 0.3941,\n",
       "         0.8589, 0.6760, 0.8994, 0.7944, 0.4997, 0.3727, 0.9500, 0.4576, 0.4920],\n",
       "        [0.9746, 0.5172, 0.9295, 0.7169, 0.4663, 0.5532, 0.5346, 0.7621, 0.7943,\n",
       "         0.6046, 0.7209, 0.4453, 0.2892, 0.8266, 0.4457, 0.2719, 0.2504, 0.7772,\n",
       "         0.3441, 0.7455, 0.6778, 0.2756, 0.7787, 0.1722, 0.7669, 0.2171, 0.6032,\n",
       "         0.5792, 0.6036, 0.8601, 0.6891, 0.8771, 0.6344, 0.0534, 0.4639, 0.0882,\n",
       "         0.2132, 0.4757, 0.6673, 0.4117, 0.2508, 0.4091, 0.3499, 0.7601, 0.4899],\n",
       "        [0.8780, 0.6023, 0.1726, 0.8479, 0.5578, 0.8071, 0.1094, 0.7779, 0.6126,\n",
       "         0.6701, 0.1075, 0.8857, 0.5234, 0.4294, 0.5774, 0.2064, 0.1253, 0.3500,\n",
       "         0.0917, 0.1760, 0.3447, 0.2385, 0.5097, 0.2672, 0.8593, 0.3431, 0.0360,\n",
       "         0.5230, 0.1368, 0.9391, 0.4274, 0.8402, 0.6064, 0.1217, 0.8204, 0.7073,\n",
       "         0.8460, 0.3754, 0.6361, 0.2449, 0.0659, 0.6827, 0.9148, 0.8474, 0.7971],\n",
       "        [0.9968, 0.6626, 0.7993, 0.7442, 0.1281, 0.2809, 0.3574, 0.8004, 0.6698,\n",
       "         0.8986, 0.9534, 0.5066, 0.2018, 0.8867, 0.7328, 0.1596, 0.2348, 0.6760,\n",
       "         0.6325, 0.4796, 0.3030, 0.3208, 0.5967, 0.0484, 0.6187, 0.3213, 0.3883,\n",
       "         0.1167, 0.4561, 0.9583, 0.5286, 0.9645, 0.6024, 0.1711, 0.3467, 0.6213,\n",
       "         0.5974, 0.4811, 0.8505, 0.5437, 0.3362, 0.2776, 0.6063, 0.8718, 0.7343],\n",
       "        [0.9631, 0.3420, 0.0516, 0.6527, 0.0927, 0.1815, 0.2439, 0.5894, 0.4309,\n",
       "         0.3031, 0.1643, 0.7879, 0.3730, 0.2529, 0.8563, 0.2738, 0.4776, 0.1789,\n",
       "         0.0466, 0.2283, 0.1320, 0.3238, 0.4159, 0.2629, 0.4010, 0.3085, 0.4695,\n",
       "         0.2176, 0.2379, 0.4869, 0.3738, 0.5160, 0.4139, 0.2898, 0.4060, 0.3344,\n",
       "         0.2624, 0.0291, 0.7466, 0.6437, 0.1183, 0.0753, 0.9523, 0.5885, 0.3533],\n",
       "        [0.3358, 0.7351, 0.7759, 0.7324, 0.1284, 0.0031, 0.0328, 0.9758, 0.2307,\n",
       "         0.0534, 0.8734, 0.1578, 0.3257, 0.8476, 0.8928, 0.1995, 0.7762, 0.3086,\n",
       "         0.2427, 0.4217, 0.0751, 0.0722, 0.9040, 0.5883, 0.0425, 0.2913, 0.7096,\n",
       "         0.0911, 0.0157, 0.1146, 0.3075, 0.5239, 0.4700, 0.3470, 0.7487, 0.7642,\n",
       "         0.0355, 0.1611, 0.0407, 0.9020, 0.8737, 0.1903, 0.9933, 0.9875, 0.0100],\n",
       "        [0.8539, 0.0691, 0.2345, 0.9489, 0.0825, 0.3544, 0.2499, 0.1318, 0.0313,\n",
       "         0.0312, 0.6045, 0.3448, 0.3438, 0.8684, 0.9624, 0.8033, 0.1809, 0.4687,\n",
       "         0.1512, 0.6242, 0.5534, 0.1516, 0.9465, 0.2980, 0.0202, 0.1017, 0.4676,\n",
       "         0.2658, 0.6236, 0.3412, 0.0590, 0.8978, 0.9356, 0.5349, 0.8574, 0.5165,\n",
       "         0.4861, 0.0810, 0.0787, 0.9755, 0.8613, 0.4024, 0.9949, 0.2812, 0.1135],\n",
       "        [0.9717, 0.6443, 0.9674, 0.6377, 0.1713, 0.2368, 0.7636, 0.7735, 0.8279,\n",
       "         0.6448, 0.9495, 0.3571, 0.8002, 0.9607, 0.3961, 0.6407, 0.0433, 0.7902,\n",
       "         0.6144, 0.7483, 0.7489, 0.4003, 0.5986, 0.1688, 0.8691, 0.4984, 0.9134,\n",
       "         0.2705, 0.6797, 0.6279, 0.5615, 0.8397, 0.9164, 0.0280, 0.6096, 0.1542,\n",
       "         0.2440, 0.6355, 0.5744, 0.6738, 0.5349, 0.1112, 0.2510, 0.6208, 0.1394],\n",
       "        [0.7989, 0.6104, 0.5066, 0.6691, 0.2622, 0.7896, 0.5827, 0.8543, 0.7185,\n",
       "         0.6893, 0.2582, 0.4670, 0.4761, 0.5057, 0.3398, 0.1293, 0.3662, 0.7392,\n",
       "         0.4488, 0.7596, 0.5160, 0.4641, 0.3716, 0.3360, 0.8112, 0.2216, 0.5956,\n",
       "         0.4017, 0.3884, 0.5294, 0.6540, 0.5365, 0.5082, 0.5066, 0.8552, 0.2301,\n",
       "         0.6140, 0.6514, 0.8099, 0.2771, 0.3193, 0.6389, 0.8893, 0.8639, 0.3697],\n",
       "        [0.7940, 0.8302, 0.9083, 0.4507, 0.2848, 0.2137, 0.5546, 0.9579, 0.7212,\n",
       "         0.5726, 0.8063, 0.4783, 0.4947, 0.7258, 0.1097, 0.1133, 0.3092, 0.9100,\n",
       "         0.7889, 0.7468, 0.1570, 0.1737, 0.3663, 0.1754, 0.6362, 0.6560, 0.8333,\n",
       "         0.4633, 0.3135, 0.7049, 0.6426, 0.2276, 0.5732, 0.6356, 0.9748, 0.4952,\n",
       "         0.4504, 0.5004, 0.6431, 0.3709, 0.8027, 0.6442, 0.9530, 0.9856, 0.0747],\n",
       "        [0.9514, 0.1318, 0.8616, 0.4874, 0.3859, 0.3024, 0.3562, 0.7560, 0.7031,\n",
       "         0.3787, 0.4401, 0.2739, 0.6652, 0.2715, 0.4273, 0.1793, 0.6627, 0.9419,\n",
       "         0.5815, 0.8483, 0.2470, 0.2798, 0.8742, 0.0562, 0.6775, 0.6204, 0.2868,\n",
       "         0.1495, 0.5440, 0.8491, 0.1017, 0.9124, 0.4376, 0.2718, 0.5903, 0.4630,\n",
       "         0.6444, 0.4261, 0.8214, 0.2289, 0.2885, 0.2473, 0.7118, 0.7657, 0.7346],\n",
       "        [0.8960, 0.2348, 0.5370, 0.1318, 0.0707, 0.0818, 0.4754, 0.6057, 0.4388,\n",
       "         0.5577, 0.1769, 0.6735, 0.3176, 0.3013, 0.8135, 0.1553, 0.6159, 0.5002,\n",
       "         0.0371, 0.2624, 0.0620, 0.2993, 0.6101, 0.0365, 0.6722, 0.7709, 0.3049,\n",
       "         0.2647, 0.3742, 0.7305, 0.3421, 0.5848, 0.3171, 0.2467, 0.4940, 0.3388,\n",
       "         0.4432, 0.2020, 0.9434, 0.2822, 0.0872, 0.0807, 0.5832, 0.8732, 0.5541]],\n",
       "       device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_encoded(df, 2) #give the tensor of the complete embedded tweet (each 3 letter)\n",
    "\n",
    "#sentence_encoded(3).shape\n",
    "#30 for the alphabet size \n",
    "#the first argument is the tweet lenght"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">4. NN coupled with RNN to find the rt </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feelings=5 #return of RNN part\n",
    "n_mainstream=5+3 #followers, likes, verified... data that didn't get treated (no need) (after normalisation) +time\n",
    "n_PCA_words=4 #after PCA on words\n",
    "n_PCA_hashtag=3 #after PCA on hashtags\n",
    "\n",
    "final_dim=n_feelings+n_mainstream+n_PCA_words+n_PCA_hashtag\n",
    "final_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">4.1 RNN on embedded words: Understanding relations between words to extract a general opinion/feeling from the tweet</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeelingsFinder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        #RNN layer (30 for the input word vectors and 5 for the feeling vector of previous run)\n",
    "        self.recurrNN=nn.RNN(45, n_feelings)\n",
    "        #30 is the input vector and n_feelings the output vector\n",
    "        self.lin=nn.Linear(n_feelings,n_feelings)\n",
    "        #the rnn output 2 vectors : 1 output \"normal\" and one for the repetition\n",
    "        #the two args need to have the same size because the layer is expected to receive a same size input \n",
    "        \n",
    "    def forward(self,x): #x is a matrix of vectorised sentence\n",
    "            \n",
    "        #initialize first feeling vector \n",
    "        h=torch.zeros(1,n_feelings).to(device)\n",
    "        \n",
    "        #feed forward (x of shape (number of patches of 3, 100))\n",
    "        for i in range(x.shape[0]):\n",
    "            #we dont have to pay attention to the \"h\", because the thing we return is the \"out\" after it passed through the linear layer\n",
    "            out, _ =self.recurrNN(x[i:i+1,:],h)\n",
    "            out=self.lin(out)\n",
    "            h=out\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "ff = FeelingsFinder().to(device)\n",
    "ff\n",
    "\n",
    "dummy_input = torch.rand((40, 45)).to(device)\n",
    "dummy_input\n",
    "\n",
    "print(ff(dummy_input).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">4.2 NN to find out rt: takes as input the output of RNN & all the treated dimensions above (2 PCAs, normalised mainstream dimensions...)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RTFinder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.NN=nn.Sequential(\n",
    "        \n",
    "        nn.Linear(final_dim,10,bias=True),\n",
    "        nn.ReLU(True),\n",
    "            \n",
    "        nn.Linear(10,4,bias=True),\n",
    "        nn.ReLU(True),\n",
    "        \n",
    "        nn.Linear(4,1, bias=True),\n",
    "        nn.Sigmoid())\n",
    "        \n",
    "        self.feelings_finder = FeelingsFinder()\n",
    "        \n",
    "    def forward(self, x, y): #x is concatenatioon of all dimensions and y same as x in forward of FeelingsFinder\n",
    "        \n",
    "        feelings = self.feelings_finder(y)\n",
    "        \n",
    "        nn_input = torch.cat((x.T,feelings.T)).T\n",
    "        \n",
    "        return self.NN(nn_input)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6100]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand((40, 45)).to(device)\n",
    "\n",
    "RT= RTFinder().to(device)\n",
    "\n",
    "dummy_input2 = torch.rand((1, 15)).to(device)\n",
    "dummy_input3 = torch.rand((1, 15)).to(device)\n",
    "\n",
    "#print(torch.cat((dummy_input2.T, dummy_input3.T)).T.shape)\n",
    "print(RT(dummy_input2, dummy_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_train(line):\n",
    "    concat_data=np.zeros((1, 15))\n",
    "    concat_data[0,0]=DF[\"favorites_count\"][line]\n",
    "    concat_data[0,1]=DF[\"followers_count\"][line]\n",
    "    concat_data[0,2]=DF[\"friends_count\"][line]\n",
    "    concat_data[0,3]=DF[\"statuses_count\"][line]\n",
    "    concat_data[0,4]=DF[\"verified\"][line]\n",
    "    concat_data[0,5]=DF[\"month\"][line]\n",
    "    concat_data[0,6]=DF[\"day\"][line]\n",
    "    concat_data[0,7]=DF[\"moment\"][line]\n",
    "    \n",
    "    concat_data[0,8:12]=PCA_TRAIN_TEXT[0][line,:]\n",
    "    concat_data[0,12:15]=PCA_TRAIN_HASHTAGS[0][line,:]\n",
    "    \n",
    "    return torch.tensor(concat_data).float(), sentence_encoded(df, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  0.4428,  0.5961,  0.4815,  0.0000,  0.1818,  0.4333,  0.8881,\n",
       "          -0.2179, -0.1484,  0.1105,  0.1800,  0.1854,  0.0083,  0.0022]]),\n",
       " tensor([[0.5308, 0.5062, 0.5878, 0.5477, 0.5468, 0.5611, 0.5635, 0.5754, 0.5548,\n",
       "          0.5775, 0.5765, 0.5790, 0.5832, 0.5603, 0.5596, 0.5258, 0.5464, 0.5942,\n",
       "          0.5975, 0.5706, 0.5294, 0.4754, 0.6022, 0.5401, 0.5869, 0.5658, 0.5686,\n",
       "          0.4417, 0.5821, 0.5828, 0.5602, 0.5070, 0.6129, 0.6036, 0.4837, 0.5674,\n",
       "          0.5058, 0.5732, 0.5521, 0.5815, 0.6062, 0.5361, 0.4943, 0.5171, 0.5108],\n",
       "         [0.7496, 0.5721, 0.7364, 0.7245, 0.7107, 0.6977, 0.7076, 0.6837, 0.7266,\n",
       "          0.7465, 0.7701, 0.7281, 0.7885, 0.6604, 0.6155, 0.7408, 0.5699, 0.7993,\n",
       "          0.7039, 0.7586, 0.5278, 0.6289, 0.6611, 0.7006, 0.6862, 0.6786, 0.7577,\n",
       "          0.5990, 0.8145, 0.7897, 0.7148, 0.5105, 0.7817, 0.7444, 0.5978, 0.7716,\n",
       "          0.6830, 0.7060, 0.7575, 0.6547, 0.7279, 0.5758, 0.5047, 0.4125, 0.6628],\n",
       "         [0.6629, 0.5735, 0.6878, 0.6671, 0.6434, 0.6451, 0.6695, 0.6456, 0.6912,\n",
       "          0.6990, 0.7036, 0.6828, 0.7105, 0.6582, 0.6277, 0.6656, 0.5562, 0.7121,\n",
       "          0.6715, 0.6840, 0.5554, 0.6209, 0.6678, 0.6514, 0.6909, 0.6413, 0.7009,\n",
       "          0.5373, 0.7618, 0.7381, 0.6569, 0.5241, 0.7369, 0.6865, 0.5343, 0.7196,\n",
       "          0.6093, 0.6833, 0.6570, 0.6210, 0.7110, 0.5725, 0.5088, 0.5007, 0.5791],\n",
       "         [0.6161, 0.5185, 0.6349, 0.6314, 0.6187, 0.5868, 0.6190, 0.5727, 0.6220,\n",
       "          0.6431, 0.6571, 0.5932, 0.6338, 0.5756, 0.5880, 0.5935, 0.5310, 0.6275,\n",
       "          0.6174, 0.6254, 0.4972, 0.5594, 0.6118, 0.6356, 0.6316, 0.5928, 0.6349,\n",
       "          0.4841, 0.6532, 0.6493, 0.6012, 0.4990, 0.6846, 0.6449, 0.5109, 0.6321,\n",
       "          0.5816, 0.6174, 0.6362, 0.5914, 0.6391, 0.5557, 0.5089, 0.4754, 0.5627],\n",
       "         [0.4674, 0.4578, 0.4633, 0.5091, 0.5035, 0.4747, 0.5098, 0.4973, 0.4900,\n",
       "          0.5007, 0.5106, 0.4342, 0.4623, 0.5012, 0.5393, 0.4710, 0.4984, 0.4878,\n",
       "          0.5258, 0.5001, 0.4551, 0.4335, 0.4693, 0.5320, 0.5296, 0.5006, 0.5115,\n",
       "          0.4319, 0.5186, 0.5027, 0.4564, 0.5091, 0.4971, 0.5053, 0.4421, 0.4557,\n",
       "          0.4748, 0.5060, 0.5163, 0.4846, 0.5188, 0.4954, 0.4479, 0.5011, 0.4898],\n",
       "         [0.4255, 0.4393, 0.4365, 0.4344, 0.4851, 0.4477, 0.4607, 0.4736, 0.4690,\n",
       "          0.4832, 0.4734, 0.4011, 0.4105, 0.5007, 0.5440, 0.4285, 0.5089, 0.4469,\n",
       "          0.5314, 0.4251, 0.4896, 0.3939, 0.4565, 0.4999, 0.4915, 0.4822, 0.4617,\n",
       "          0.4336, 0.4924, 0.4735, 0.4072, 0.4925, 0.4777, 0.4576, 0.4240, 0.4129,\n",
       "          0.4415, 0.5064, 0.4595, 0.4297, 0.5090, 0.4897, 0.4437, 0.5478, 0.4666],\n",
       "         [0.5737, 0.4945, 0.6150, 0.5832, 0.5559, 0.5485, 0.5684, 0.5909, 0.5700,\n",
       "          0.5915, 0.6164, 0.5737, 0.5905, 0.5617, 0.5653, 0.5558, 0.5185, 0.5905,\n",
       "          0.5974, 0.5928, 0.5164, 0.4822, 0.6113, 0.5943, 0.5853, 0.5626, 0.5903,\n",
       "          0.4479, 0.5884, 0.5995, 0.5557, 0.4841, 0.6355, 0.6104, 0.4708, 0.5703,\n",
       "          0.5216, 0.5904, 0.5956, 0.6071, 0.5950, 0.5388, 0.5015, 0.4784, 0.5341],\n",
       "         [0.6754, 0.5622, 0.6460, 0.6957, 0.6859, 0.6485, 0.6425, 0.6170, 0.6828,\n",
       "          0.6618, 0.7226, 0.6604, 0.7184, 0.6495, 0.6075, 0.6679, 0.5508, 0.7204,\n",
       "          0.6597, 0.7039, 0.5017, 0.5869, 0.6348, 0.6967, 0.6617, 0.6704, 0.7165,\n",
       "          0.5080, 0.7362, 0.7048, 0.6899, 0.4653, 0.7126, 0.7192, 0.5375, 0.6932,\n",
       "          0.6091, 0.6578, 0.6973, 0.6528, 0.6772, 0.5511, 0.5292, 0.4436, 0.6194],\n",
       "         [0.5619, 0.4876, 0.5865, 0.5699, 0.5694, 0.5493, 0.5675, 0.5727, 0.5663,\n",
       "          0.5948, 0.6178, 0.5588, 0.5741, 0.5545, 0.5782, 0.5414, 0.5124, 0.5845,\n",
       "          0.5995, 0.5821, 0.5188, 0.5011, 0.5821, 0.5973, 0.5649, 0.5619, 0.5999,\n",
       "          0.4792, 0.5778, 0.5800, 0.5512, 0.4899, 0.6377, 0.5875, 0.4896, 0.5557,\n",
       "          0.5254, 0.5664, 0.6051, 0.5691, 0.5831, 0.5263, 0.4962, 0.4698, 0.5354],\n",
       "         [0.5974, 0.5221, 0.5585, 0.6321, 0.5808, 0.5730, 0.6006, 0.5487, 0.5730,\n",
       "          0.5746, 0.6090, 0.5502, 0.5901, 0.5875, 0.5377, 0.5854, 0.5099, 0.5944,\n",
       "          0.5713, 0.6366, 0.4706, 0.5400, 0.5380, 0.5939, 0.5957, 0.5764, 0.6116,\n",
       "          0.4681, 0.6252, 0.6223, 0.5366, 0.5194, 0.5990, 0.6091, 0.4943, 0.6007,\n",
       "          0.5520, 0.5307, 0.6060, 0.5549, 0.6047, 0.5416, 0.5205, 0.4411, 0.5405],\n",
       "         [0.5345, 0.4853, 0.5488, 0.5430, 0.5669, 0.5183, 0.5584, 0.5195, 0.5707,\n",
       "          0.5602, 0.5627, 0.4971, 0.5295, 0.5588, 0.5594, 0.5084, 0.5200, 0.5578,\n",
       "          0.5810, 0.5285, 0.5275, 0.4621, 0.5164, 0.5860, 0.5672, 0.5356, 0.5741,\n",
       "          0.4849, 0.6089, 0.5597, 0.5167, 0.5102, 0.5900, 0.5897, 0.4712, 0.5153,\n",
       "          0.4971, 0.5706, 0.5638, 0.5172, 0.5798, 0.5101, 0.4731, 0.5193, 0.5263],\n",
       "         [0.6232, 0.5730, 0.6744, 0.6547, 0.6422, 0.6216, 0.6287, 0.6254, 0.6500,\n",
       "          0.6558, 0.6885, 0.6409, 0.6826, 0.6198, 0.6236, 0.6121, 0.5678, 0.6901,\n",
       "          0.6543, 0.6785, 0.5176, 0.6002, 0.6483, 0.6617, 0.6594, 0.6479, 0.6601,\n",
       "          0.4988, 0.6989, 0.6929, 0.6416, 0.4946, 0.7069, 0.6753, 0.5474, 0.6550,\n",
       "          0.6025, 0.6324, 0.6533, 0.6281, 0.6894, 0.5738, 0.5281, 0.4849, 0.5892],\n",
       "         [0.7021, 0.5663, 0.6931, 0.6917, 0.6405, 0.6685, 0.6864, 0.6742, 0.6548,\n",
       "          0.6586, 0.6796, 0.6851, 0.7280, 0.6490, 0.5898, 0.6851, 0.5514, 0.7396,\n",
       "          0.6337, 0.7363, 0.5029, 0.5937, 0.6310, 0.6493, 0.6637, 0.6697, 0.6846,\n",
       "          0.5155, 0.7604, 0.7366, 0.6523, 0.5022, 0.6917, 0.6915, 0.5465, 0.7168,\n",
       "          0.6289, 0.6214, 0.6998, 0.6397, 0.7054, 0.5547, 0.5091, 0.4183, 0.6447],\n",
       "         [0.7114, 0.5917, 0.6959, 0.7142, 0.6822, 0.6829, 0.6992, 0.6547, 0.7078,\n",
       "          0.7078, 0.7447, 0.7105, 0.7578, 0.6884, 0.5750, 0.6980, 0.5062, 0.7404,\n",
       "          0.6372, 0.7479, 0.5113, 0.6363, 0.6420, 0.6844, 0.6882, 0.6922, 0.7409,\n",
       "          0.5052, 0.7818, 0.7930, 0.6750, 0.5107, 0.7392, 0.7125, 0.5252, 0.7459,\n",
       "          0.6416, 0.5929, 0.7361, 0.6459, 0.7056, 0.5921, 0.5289, 0.4316, 0.6070],\n",
       "         [0.5230, 0.4734, 0.5664, 0.5681, 0.5254, 0.5186, 0.5540, 0.5359, 0.5721,\n",
       "          0.5666, 0.5534, 0.4708, 0.5158, 0.5319, 0.5582, 0.4875, 0.4678, 0.5206,\n",
       "          0.5614, 0.5537, 0.5229, 0.4805, 0.5129, 0.5790, 0.5696, 0.5136, 0.5890,\n",
       "          0.4558, 0.5502, 0.5502, 0.5256, 0.5418, 0.5722, 0.5643, 0.4553, 0.5003,\n",
       "          0.4952, 0.5285, 0.5658, 0.5492, 0.5650, 0.5257, 0.4722, 0.4802, 0.5186]],\n",
       "        grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_train(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/3539690 [00:00<?, ?it/s]\u001b[A\u001b[A/Users/mathieu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/mathieu/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "\n",
      "\n",
      "  0%|          | 1/3539690 [00:01<1249:07:36,  1.27s/it]\u001b[A\u001b[A/Users/mathieu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "\n",
      "  0%|          | 10/3539690 [00:01<878:46:36,  1.12it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 16/3539690 [00:01<620:37:49,  1.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 24/3539690 [00:01<438:24:12,  2.24it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 29/3539690 [00:01<313:29:08,  3.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 37/3539690 [00:01<223:50:47,  4.39it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 44/3539690 [00:01<161:09:45,  6.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 52/3539690 [00:02<116:35:56,  8.43it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 63/3539690 [00:02<84:27:29, 11.64it/s] \u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 77/3539690 [00:02<61:14:31, 16.05it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 87/3539690 [00:02<45:51:59, 21.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 97/3539690 [00:02<35:16:13, 27.88it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 108/3539690 [00:02<27:31:58, 35.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 120/3539690 [00:02<21:53:42, 44.91it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 131/3539690 [00:02<18:14:52, 53.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 143/3539690 [00:02<15:21:31, 64.02it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 154/3539690 [00:03<13:56:44, 70.50it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 165/3539690 [00:03<13:18:06, 73.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 175/3539690 [00:03<12:48:58, 76.72it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 185/3539690 [00:03<12:08:47, 80.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 195/3539690 [00:03<11:51:27, 82.92it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 206/3539690 [00:03<11:06:55, 88.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 219/3539690 [00:03<10:21:42, 94.89it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 230/3539690 [00:03<10:24:05, 94.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 242/3539690 [00:03<9:56:23, 98.91it/s] \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 253/3539690 [00:04<10:10:03, 96.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 263/3539690 [00:04<10:10:56, 96.56it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 273/3539690 [00:04<10:39:02, 92.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 285/3539690 [00:04<10:03:45, 97.71it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 296/3539690 [00:04<9:55:01, 99.14it/s] \u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 307/3539690 [00:04<9:39:32, 101.79it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 318/3539690 [00:04<9:59:56, 98.32it/s] \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 328/3539690 [00:04<10:28:42, 93.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 338/3539690 [00:04<10:34:58, 92.90it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 350/3539690 [00:05<10:01:22, 98.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 363/3539690 [00:05<9:30:17, 103.44it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 374/3539690 [00:05<10:17:24, 95.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 384/3539690 [00:05<10:48:51, 90.91it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 397/3539690 [00:05<9:55:11, 99.11it/s] \u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 408/3539690 [00:05<9:53:44, 99.35it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 419/3539690 [00:05<10:01:51, 98.01it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 430/3539690 [00:05<10:03:04, 97.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 441/3539690 [00:05<9:55:03, 99.13it/s] \u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 452/3539690 [00:06<10:20:40, 95.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 462/3539690 [00:06<10:36:40, 92.65it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 472/3539690 [00:06<10:54:05, 90.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 482/3539690 [00:06<10:41:46, 91.91it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-385-9cd25233756f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mrt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mrt_target\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"retweets_count\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mrt_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrt_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-312-b26825f01cf4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#x is concatenatioon of all dimensions and y same as x in forward of FeelingsFinder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mfeelings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeelings_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mnn_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeelings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-310-04e6dac533fe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m#we dont have to pay attention to the \"h\", because the thing we return is the \"out\" after it passed through the linear layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_batched\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training loop (train for each line)\n",
    "\n",
    "UPDATE_EVERY = 750\n",
    "BIG_RANGE=len(df['TweetID'])\n",
    "\n",
    "RT=RTFinder().to(device)\n",
    "progressbar = tqdm(range(10*BIG_RANGE))\n",
    "loss=None\n",
    "loss_list=[]\n",
    "\n",
    "#optimizer = Adam(RT.parameters(),lr=0.001)\n",
    "\n",
    "for line in progressbar:\n",
    "    line=line%BIG_RANGE\n",
    "    #if loss is None:\n",
    "        #optimizer.zero_grad()\n",
    "    x0, x1 = data_to_train(line)\n",
    "    x0 = x0.to(device)\n",
    "    x1 = x1.to(device)\n",
    "    rt=RT(x0, x1)\n",
    "    rt_target=df[\"retweets_count\"][line]\n",
    "    rt_target = torch.tensor(rt_target).to(device)\n",
    "    loss_func=nn.MSELoss()\n",
    "    \n",
    "    if loss is None:\n",
    "        loss=loss_func(rt, torch.tensor(rt_target).float())\n",
    "    else:\n",
    "        loss+=loss_func(rt, torch.tensor(rt_target).float())\n",
    "    \n",
    "    if line%UPDATE_EVERY==UPDATE_EVERY-1:\n",
    "        loss/=UPDATE_EVERY\n",
    "        torch.save(RT.state_dict(),\"Final_Network.h5\")\n",
    "        \n",
    "        loss_list.append(loss.item()) #All this to update the loss plot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(loss_list)\n",
    "        fig.savefig(\"loss plot.png\")\n",
    "        plt.close(fig)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(f\"Loss: {loss.item(): .6f}\")\n",
    "        progressbar.set_description(f\"Loss: {loss.item(): .6f}\")\n",
    "        loss=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">5. Apply everything onto test dataset </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">5.1 Prepare test data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_test(line):\n",
    "    concat_data=np.zeros((1,15))\n",
    "    concat_data[0,0]=DF_test[\"favorites_count\"][line]\n",
    "    concat_data[0,1]=DF_test[\"followers_count\"][line]\n",
    "    concat_data[0,2]=DF_test[\"friends_count\"][line]\n",
    "    concat_data[0,3]=DF_test[\"statuses_count\"][line]\n",
    "    concat_data[0,4]=DF_test[\"verified\"][line]\n",
    "    concat_data[0,5]=DF_test[\"month\"][line]\n",
    "    concat_data[0,6]=DF_test[\"day\"][line]\n",
    "    concat_data[0,7]=DF_test[\"moment\"][line]\n",
    "    \n",
    "    concat_data[0,8:12]=PCA_TEST_TEXT[line,:]\n",
    "    concat_data[0,12:15]=PCA_TEST_HASHTAGS[line,:]\n",
    "    \n",
    "    return torch.tensor(concat_data).float(), sentence_encoded(df_test, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  0.3133,  0.5364,  0.6029,  0.0000,  0.1818,  0.4333,  0.6095,\n",
       "          -0.2672,  0.7977, -0.9882, -0.4286,  0.9586,  0.2287,  0.1284]]),\n",
       " tensor([[0.6961, 0.5868, 0.6672,  ..., 0.5232, 0.4691, 0.6114],\n",
       "         [0.5397, 0.4810, 0.5715,  ..., 0.4698, 0.4612, 0.5226],\n",
       "         [0.4621, 0.4756, 0.4674,  ..., 0.4636, 0.5319, 0.5057],\n",
       "         ...,\n",
       "         [0.6580, 0.5684, 0.7018,  ..., 0.5229, 0.4863, 0.6151],\n",
       "         [0.6431, 0.5401, 0.6848,  ..., 0.5308, 0.4555, 0.6012],\n",
       "         [0.4758, 0.4552, 0.4807,  ..., 0.4635, 0.4801, 0.4871]],\n",
       "        grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_test(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">5.2 Get the test data ready for submission</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117990"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(DF_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_myfunc(x):\n",
    "    return 10**(x)+1\n",
    "\n",
    "def submit(unnorm_df, norm_df_test):\n",
    "    \n",
    "    #First, get the rt predictions for each line\n",
    "    \n",
    "    RT_test=RTFinder()\n",
    "    RT_test.load_state_dict(torch.load(\"Final_Network 155bckprop.h5\", map_location=torch.device('cpu')))\n",
    "    \n",
    "    UNnorm_df=copy.deepcopy(unnom_df)\n",
    "    NORM_df_test=copy.deepcopy(norm_df_test)\n",
    "    \n",
    "    prediction=np.array(len(NORM_df_test))\n",
    "    \n",
    "    for i in range(len(NORM_df_test)):\n",
    "        x0, x1=data_to_test(i)\n",
    "        prediction[i]=RT_test(x0,x1)\n",
    "        \n",
    "    #Fill in the results of prediction into ad DF Rt_test \n",
    "    \n",
    "    Rt_test=pd.DataFrame(NORM_df_test,columns=[\"retweets_count\"])\n",
    "    Rt_test[\"retweets_count\"]=prediction\n",
    "    \n",
    "    #Now unnormalise according to the normalisation of the rt in the train set\n",
    "    \n",
    "    Rt_train=pd.DataFrame(UNnorm_df,columns=[\"retweets_count\"])\n",
    "    Rt_train['retweets_count'] = Rt_train['retweets_count'].transform(myfunc)\n",
    "    \n",
    "    scaler_rt=MinMaxScaler()\n",
    "    scaler_rt.fit(Rt_train)\n",
    "    new_predictions=scaler_rt.inverse_transform(Rt_test)\n",
    "\n",
    "    Result=pd.DataFrame(new_predictions,columns=[\"retweets_count\"])\n",
    "    Result['retweets_count'] = Result['retweets_count'].transform(inv_myfunc)\n",
    "    \n",
    "    Result['TweetID']=NORM_df_test['TweetID']\n",
    "    \n",
    "    return Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for RTFinder:\n\tMissing key(s) in state_dict: \"NN.0.weight\", \"NN.0.bias\", \"NN.2.weight\", \"NN.2.bias\", \"NN.4.weight\", \"NN.4.bias\", \"feelings_finder.recurrNN.weight_ih_l0\", \"feelings_finder.recurrNN.weight_hh_l0\", \"feelings_finder.recurrNN.bias_ih_l0\", \"feelings_finder.recurrNN.bias_hh_l0\", \"feelings_finder.lin.weight\", \"feelings_finder.lin.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.0.weight\", \"encoder.0.bias\", \"encoder.2.weight\", \"encoder.2.bias\", \"decoder.0.weight\", \"decoder.0.bias\", \"decoder.2.weight\", \"decoder.2.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-384-fc9a9e346742>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDF_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-383-f453215cf63d>\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(unnorm_df, norm_df_test)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mRT_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRTFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mRT_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Final_Network 155bckprop.h5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mUNnorm_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munnom_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m-> 1668\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m   1669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for RTFinder:\n\tMissing key(s) in state_dict: \"NN.0.weight\", \"NN.0.bias\", \"NN.2.weight\", \"NN.2.bias\", \"NN.4.weight\", \"NN.4.bias\", \"feelings_finder.recurrNN.weight_ih_l0\", \"feelings_finder.recurrNN.weight_hh_l0\", \"feelings_finder.recurrNN.bias_ih_l0\", \"feelings_finder.recurrNN.bias_hh_l0\", \"feelings_finder.lin.weight\", \"feelings_finder.lin.bias\". \n\tUnexpected key(s) in state_dict: \"encoder.0.weight\", \"encoder.0.bias\", \"encoder.2.weight\", \"encoder.2.bias\", \"decoder.0.weight\", \"decoder.0.bias\", \"decoder.2.weight\", \"decoder.2.bias\". "
     ]
    }
   ],
   "source": [
    "submit(df1, DF_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "58644109350f8e12cb67e1c1e77a7e72950bcd98a8aaf135bac033a9e112be78"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
