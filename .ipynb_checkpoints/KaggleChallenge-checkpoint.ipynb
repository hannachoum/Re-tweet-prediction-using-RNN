{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83927630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958ba4cc",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">1. Preprocessing </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a174b1e",
   "metadata": {},
   "source": [
    "##  <span style=\"color:indigo\"> 1.1 Dataset observation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29192bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lecture du fichier .csv par la libraire Pandas\n",
    "data=pd.read_csv('train.csv')\n",
    "df=data.copy()\n",
    "df_test=pd.read_csv('evaluation.csv')\n",
    "\n",
    "#We need to separate X and Y\n",
    "#X=data.loc[:,data.columns!=\"retweets_count\"]\n",
    "#Y=data['retweets_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a9652d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353969,)\n",
      "6 54 6.9\n"
     ]
    }
   ],
   "source": [
    "timestamp=df[\"timestamp\"][0]/1000\n",
    "print(np.array(df[\"timestamp\"]).shape)\n",
    "date=dt.fromtimestamp(timestamp)\n",
    "print(date.hour, date.minute, date.hour+date.minute/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fab3f0",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">1.2 Features explanations </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f9df47",
   "metadata": {},
   "source": [
    "df.quantile(0.99) #We check if there is a lot ludicrous values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1190231",
   "metadata": {},
   "source": [
    "#If our dataset contains empty values, we put the mean value of the collum\n",
    "if df.isnull().sum().sum()!=0: \n",
    "    imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "else: \n",
    "    print(\"No missing_values in this dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b370939",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "corr_matrix = df.corr()\n",
    "plt.figure(figsize=(28,24))\n",
    "sns.heatmap(data = corr_matrix,cmap='BrBG', annot=True, linewidths=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aca8aa",
   "metadata": {},
   "source": [
    " ------> We observe that the only strong correlation that we can see at this time is the one between [favorite_count] \n",
    "and [retweet_count] , so we can already say that to predict the number of retweet, the number of favorite count is very important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba67e94",
   "metadata": {},
   "source": [
    "#checking for missing values in output\n",
    "for i in range(df.shape[0]):\n",
    "    if df['retweets_count'][i]==[]:\n",
    "        print(df['retweets_count'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30de170a",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">1.3 Normalisations </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c080cb",
   "metadata": {},
   "source": [
    "On doit normaliser les données mais chaque colonne doit être normalisé différemment. \n",
    "- \"favorites_count\" -> moins de 1% de valeurs abhérantes (au top)\n",
    "- \"followers_count\", -> Exponential \n",
    "- \"statutes_count\",\n",
    "- \"friends_count\" -> moins de 1% de valeurs abhérantes (au top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaccd792",
   "metadata": {},
   "source": [
    "Normalization.quantile(0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c51fb4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_into_df(df):\n",
    "    result=pd.DataFrame(df,columns=[\"month\", \"day\", \"moment\"])\n",
    "    timestamps=np.array(df[\"timestamp\"])\n",
    "    \n",
    "    for i in range(timestamps.shape[0]):\n",
    "        date=dt.fromtimestamp(timestamps[i]/1000)\n",
    "        result[\"month\"][i]=date.month\n",
    "        result[\"day\"][i]=date.day\n",
    "        result[\"moment\"][i]=date.hour+date.minute/60\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1de22f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(x):\n",
    "     return np.log(1+x)\n",
    "\n",
    "def Normaliser(df, df_test):\n",
    "    \n",
    "    column_names=[\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\"]\n",
    "    \n",
    "    #Create DFs and apply log to them\n",
    "    \n",
    "    Norm_train=pd.DataFrame(df,columns=[\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\"])\n",
    "    Norm_train['favorites_count'] = Norm_train['favorites_count'].transform(myfunc)\n",
    "    Norm_train['followers_count'] = Norm_train['followers_count'].transform(myfunc)\n",
    "    Norm_train['friends_count'] = Norm_train['friends_count'].transform(myfunc)\n",
    "    Norm_train['statuses_count'] = Norm_train['statuses_count'].transform(myfunc)\n",
    "    \n",
    "    Norm_rt=pd.DataFrame(df,columns=[\"retweets_count\"])\n",
    "    Norm_rt['retweets_count'] = Norm_rt['retweets_count'].transform(myfunc)\n",
    "    \n",
    "    Norm_test=pd.DataFrame(df_test,columns=[\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\"])\n",
    "    Norm_test['favorites_count'] = Norm_test['favorites_count'].transform(myfunc)\n",
    "    Norm_test['followers_count'] = Norm_test['followers_count'].transform(myfunc)\n",
    "    Norm_test['friends_count'] = Norm_test['friends_count'].transform(myfunc)\n",
    "    Norm_test['statuses_count'] = Norm_test['statuses_count'].transform(myfunc)\n",
    "    \n",
    "    #Also add time\n",
    "    \n",
    "    Time_train=get_time_into_df(df)\n",
    "    Time_test=get_time_into_df(df_test)\n",
    "    \n",
    "    #Now rescale with min-max\n",
    "    \n",
    "    scaler_train=MinMaxScaler()\n",
    "    scaler_train.fit(Norm_train)\n",
    "    norm_train=scaler_train.transform(Norm_train)\n",
    "    norm_test=scaler_train.transform(Norm_test)\n",
    "    \n",
    "    scaler_rt=MinMaxScaler()\n",
    "    scaler_rt.fit(Norm_rt)\n",
    "    norm_rt=scaler_rt.transform(Norm_rt)\n",
    "    \n",
    "    scaler_time=MinMaxScaler()\n",
    "    scaler_time.fit(Time_train)\n",
    "    norm_time_train=scaler_time.transform(Time_train)\n",
    "    norm_time_test=scaler_time.transform(Time_test)\n",
    "    \n",
    "    #Now put the rescaled results into the original DFs\n",
    "    \n",
    "    Norm_train=pd.DataFrame(norm_train,columns=column_names)\n",
    "    Norm_test=pd.DataFrame(norm_test,columns=column_names)\n",
    "    Norm_rt=pd.DataFrame(norm_rt,columns=[\"retweets_count\"])\n",
    "    \n",
    "    NormT_train=pd.DataFrame(norm_time_train,columns=[\"month\", \"day\", \"moment\"])\n",
    "    NormT_test=pd.DataFrame(norm_time_test,columns=[\"month\", \"day\", \"moment\"])\n",
    "    \n",
    "    df['favorites_count']=Norm_train['favorites_count']\n",
    "    df['followers_count']=Norm_train['followers_count'] \n",
    "    df['statuses_count']=Norm_train['statuses_count']\n",
    "    df['friends_count']=Norm_train['friends_count']\n",
    "    df['retweets_count']=Norm_rt['retweets_count']\n",
    "    \n",
    "    df_test['favorites_count']=Norm_test['favorites_count']\n",
    "    df_test['followers_count']=Norm_test['followers_count'] \n",
    "    df_test['statuses_count']=Norm_test['statuses_count']\n",
    "    df_test['friends_count']=Norm_test['friends_count']\n",
    "    \n",
    "    df[\"month\"]=NormT_train[\"month\"]\n",
    "    df[\"day\"]=NormT_train[\"day\"]\n",
    "    df[\"moment\"]=NormT_train[\"moment\"]\n",
    "    \n",
    "    df_test[\"month\"]=NormT_test[\"month\"]\n",
    "    df_test[\"day\"]=NormT_test[\"day\"]\n",
    "    df_test[\"moment\"]=NormT_test[\"moment\"]\n",
    "\n",
    "    return df, df_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02f856d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_test= Normaliser(df,df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcea7aba",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">2. PCA Text and # treatment </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd498df8",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:indigo\">2.1 Preprocessing of hashtags and texts </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d45877d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for hashtags\n",
    "\n",
    "def most_important_hashtags(df, criteria):\n",
    "    DICO2={} #DICO2 is for hashtags\n",
    "    I=df.shape[0]\n",
    "    for i in range(I):\n",
    "        sentence=df[\"hashtags\"][i][1:-1].replace(' ', '').split(',')\n",
    "        for word in sentence:\n",
    "            extracted_word=word[1:-1]\n",
    "            if extracted_word in DICO2:\n",
    "                DICO2[extracted_word]+=1\n",
    "            else:\n",
    "                DICO2[extracted_word]=1\n",
    "    most_occurr_DICO2={}\n",
    "    for word in DICO2:\n",
    "        if DICO2[word]>criteria :#and word!=''\n",
    "            most_occurr_DICO2[word]=0\n",
    "    \n",
    "    important_hashtags=list(most_occurr_DICO2.keys())\n",
    "    \n",
    "    measurer2={}\n",
    "    for i in range(len(important_hashtags)):\n",
    "        measurer2[important_hashtags[i]]=i\n",
    "    measurer2\n",
    "    return important_hashtags, measurer2\n",
    "\n",
    "def make_array_training_hashtags(df, criteria):\n",
    "    possibilities, measurer=most_important_hashtags(df, criteria)\n",
    "    result=np.zeros((df.shape[0], len(possibilities)))\n",
    "    for line in range(df.shape[0]):\n",
    "        sentence=df[\"hashtags\"][line][1:-1].replace(' ', '').split(',')\n",
    "        for word in sentence:\n",
    "            extracted_word=word[1:-1]\n",
    "            if extracted_word in possibilities:\n",
    "                result[line,measurer[extracted_word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "def make_array_test_hashtags(df_test, criteria):\n",
    "    possibilities, measurer=most_important_hashtags(df, criteria)\n",
    "    result=np.zeros((df_test.shape[0], len(possibilities)))\n",
    "    for line in range(df_test.shape[0]):\n",
    "        sentence=df_test[\"hashtags\"][line][1:-1].replace(' ', '').split(',')\n",
    "        for word in sentence:\n",
    "            extracted_word=word[1:-1]\n",
    "            if extracted_word in possibilities:\n",
    "                result[line,measurer[extracted_word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "array_train_hashtags=make_array_training_hashtags(df,10)\n",
    "array_test_hashtags=make_array_test_hashtags(df_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25699cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for texts\n",
    "\n",
    "def most_important_words(df, criteria):\n",
    "    DICO={}\n",
    "    I=df.shape[0]\n",
    "    for i in range(I):\n",
    "        sentence=df[\"text\"][i].split()\n",
    "        for word in sentence:\n",
    "            if word in DICO:\n",
    "                DICO[word]+=1\n",
    "            else:\n",
    "                DICO[word]=1\n",
    "            \n",
    "    most_occurr_DICO={}\n",
    "    for word in DICO:\n",
    "        if DICO[word]>criteria:\n",
    "            most_occurr_DICO[word]=0\n",
    "    \n",
    "    important_words=list(most_occurr_DICO.keys())\n",
    "    measurer={}\n",
    "    for i in range(len(important_words)):\n",
    "        measurer[important_words[i]]=i\n",
    "    measurer\n",
    "    \n",
    "    return important_words, measurer\n",
    "\n",
    "def make_array_training_words(df, criteria):\n",
    "    possibilities, measurer=most_important_words(df, criteria)\n",
    "    result=np.zeros((df.shape[0], len(possibilities)))\n",
    "    for line in range(df.shape[0]):\n",
    "        sentence=df[\"text\"][line].split()\n",
    "        for word in sentence:\n",
    "            if word in possibilities:\n",
    "                result[line,measurer[word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "def make_array_test_words(df_test, criteria):\n",
    "    possibilities, measurer=most_important_words(df, criteria)\n",
    "    result=np.zeros((df_test.shape[0], len(possibilities)))\n",
    "    for line in range(df_test.shape[0]):\n",
    "        sentence=df_test[\"text\"][line].split()\n",
    "        for word in sentence:\n",
    "            if word in possibilities:\n",
    "                result[line,measurer[word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "array_train_text=make_array_training_words(df,5000)\n",
    "array_test_text=make_array_test_words(df_test, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680d2aa2",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "## <span style=\"color:indigo\">2.2 PCA on words and hashtags: Understanding the main components of bags of words </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b898fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_training(array, n_comp):\n",
    "    n=array.shape[1]\n",
    "    for col in range(n):\n",
    "        mean=np.mean(array[:,col])\n",
    "        array[:,col]-=mean\n",
    "            \n",
    "    C=np.matmul(array.T,array)\n",
    "    C/=array.shape[1]\n",
    "    \n",
    "    Lambda, Q=np.linalg.eigh(C)\n",
    "\n",
    "    Qk=np.zeros((n,n_comp))\n",
    "    for col in range(n_comp):\n",
    "        Qk[:,col]=Q[:,n-col-1]\n",
    "    return np.matmul(array,Qk), Qk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dd1ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_test(training_array, test_array, n_comp):\n",
    "    return np.matmul(test_array,PCA_training(training_array,n_comp)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba93a46",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">3. Preparing RNN on word sequences: Understanding relations between words </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f1ebfe",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:indigo\"> 3.1 Pre-treatment for word embedding </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd908de",
   "metadata": {},
   "source": [
    "We will use the FastText method. We divide each word into groups of 3 letters (spaces are the \"empty letter\"). We keep the order in the text and make an embedding also using the adjacent words. For instance:\n",
    "\"macron demission\"==> -ma,mac,acr,...,on-,n-d,-de,dem,... (- is the empty letter)\n",
    "\n",
    "The fast text method will guess the adjacent 3 letters to each given patch of 3 letters. Hence for \"mac\" we want a high probability of \"---\" (3 times empty letter) and \"ron\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b4241bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  device = \"cuda:0\" \n",
    "else:  \n",
    "  device = \"cpu\"  \n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f4996ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns an array with the words in the sentence cut (n=3 that is in pieces of 3)\n",
    "\n",
    "def cutter(sent, n):\n",
    "    sentence=sent.split()\n",
    "    length=len(sentence)+2-n\n",
    "    for word in sentence:\n",
    "        length+=len(word)\n",
    "    result=[]\n",
    "    padding=''\n",
    "    for i in range(n):\n",
    "        padding+=' '\n",
    "    sent=' '+sent+' '\n",
    "    padd_sent=padding+sent+padding\n",
    "    \n",
    "    for i in range(length):\n",
    "        middle=sent[i:i+n]\n",
    "        before=padd_sent[i:i+n]\n",
    "        after=padd_sent[2*n+i:3*n+i]\n",
    "        result.append([before, middle, after])\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6050273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphabet=30\n",
    "\n",
    "def batch_maker(size):\n",
    "    X=np.zeros((size,3*n_alphabet))\n",
    "    Y=np.zeros((size,6*n_alphabet))\n",
    "    for i in range(size):\n",
    "        \n",
    "        line=random.randrange(0,350000)\n",
    "        cut=cutter(df[\"text\"][line],3)\n",
    "        \n",
    "        alphabet={\n",
    "        ' ':0,'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,\n",
    "        'o':15,'p':16,'q':17,'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26,'é':27,\n",
    "        'è':28,\n",
    "        #thus use mod 30 (as 29 is for any other letter (arabic...))\n",
    "        }\n",
    "        \n",
    "        possibilities=[        \n",
    "        ' ','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x',\n",
    "        'y','z','é','è',]\n",
    "        \n",
    "        length=cut.shape[0]\n",
    "        word_index=random.randrange(0,length)\n",
    "        \n",
    "        word0=cut[word_index, 0]\n",
    "        word1=cut[word_index, 1]\n",
    "        word2=cut[word_index, 2]\n",
    "        for letter_ind in range(3):\n",
    "            index0=0\n",
    "            index1=0\n",
    "            index2=0\n",
    "            if (word0[letter_ind] not in possibilities):\n",
    "                index0=29\n",
    "            else:\n",
    "                index0=alphabet[word0[letter_ind]]\n",
    "                \n",
    "            if (word1[letter_ind] not in possibilities):\n",
    "                index1=29\n",
    "            else:\n",
    "                index1=alphabet[word1[letter_ind]]\n",
    "                \n",
    "            if (word2[letter_ind] not in possibilities):\n",
    "                index2=29\n",
    "            else:\n",
    "                index2=alphabet[word2[letter_ind]]\n",
    "                \n",
    "            Y[i,letter_ind*n_alphabet+index0]=1\n",
    "            X[i,letter_ind*n_alphabet+index1]=1\n",
    "            Y[i,3*n_alphabet+letter_ind*n_alphabet+index2]=1\n",
    "        \n",
    "    return torch.tensor(X, requires_grad=True).float(),torch.tensor(Y, requires_grad=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b58fe19b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 90])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_maker(100)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb83efe",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\"> 3.2 Encoder/decoder to mimic FastText</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cebc76",
   "metadata": {},
   "source": [
    "This model takes a \"word\" (3 letters patch) as input and return a size 100 vector who is encoded to take into consideration the past and future patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2c080e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embedd(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        #A sequential container: Modules will be added to it in the order they are passed in the constructor. \n",
    "        self.encoder=nn.Sequential(\n",
    "            \n",
    "        nn.Linear(3*n_alphabet,70,bias=True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(70,45,bias=True),\n",
    "        nn.Sigmoid())\n",
    "        \n",
    "        self.decoder=nn.Sequential(\n",
    "        \n",
    "        nn.Linear(45,110, bias=True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(110,6*n_alphabet,bias=True),\n",
    "        )\n",
    "        \n",
    "        #The forward() method of Sequential accepts \n",
    "        #any input and forwards it to the first module it contains.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x=self.encoder(x)\n",
    "        x=self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53471253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:14<00:00, 13.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# PARAMS\n",
    "\n",
    "BATCH_SIZE=100 #1000\n",
    "NUM_BACKWARDS=200\n",
    "LEARNING_RATE=0.001\n",
    "\n",
    "###############\n",
    "\n",
    "loss_list=[]\n",
    "Emb=embedd().to(device)\n",
    "Emb.train()\n",
    "optimizer = Adam(Emb.parameters(),lr=LEARNING_RATE)\n",
    "\n",
    "for n in tqdm(range(NUM_BACKWARDS)):\n",
    "    \n",
    "    x,y_target=batch_maker(BATCH_SIZE)\n",
    "    x = x.to(device) #we put the model and the variable on the gpu\n",
    "    y=Emb(x)\n",
    "    y = y.to(device)\n",
    "    y_target = y_target.to(device) #because we use y_target after and we neet to put it on the gpu\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss_func=nn.CrossEntropyLoss()\n",
    "    loss1_target = (y_target[:,:n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    loss2_target = (y_target[:,n_alphabet:2*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    loss3_target = (y_target[:,2*n_alphabet:3*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    \n",
    "    loss4_target = (y_target[:,3*n_alphabet:4*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    loss5_target = (y_target[:,4*n_alphabet:5*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    loss6_target = (y_target[:,5*n_alphabet:6*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "\n",
    "    loss1=loss_func(y[:,:n_alphabet],loss1_target)\n",
    "    loss2=loss_func(y[:,n_alphabet:2*n_alphabet],loss2_target)\n",
    "    loss3=loss_func(y[:,2*n_alphabet:3*n_alphabet],loss3_target)\n",
    "    \n",
    "    loss4=loss_func(y[:,3*n_alphabet:4*n_alphabet],loss4_target)\n",
    "    loss5=loss_func(y[:,4*n_alphabet:5*n_alphabet],loss5_target)\n",
    "    loss6=loss_func(y[:,5*n_alphabet:6*n_alphabet],loss6_target)\n",
    "    \n",
    "    \n",
    "    loss=(loss1+loss2+loss3+loss4+loss5+loss6)/6\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_list.append(loss.item()) #All this to update the loss plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(loss_list)\n",
    "    fig.savefig(\"loss plot embedd bigbatch.png\")\n",
    "    plt.close(fig)\n",
    "    \n",
    "    if NUM_BACKWARDS%1000==0:\n",
    "        torch.save(Emb.state_dict(),\"Model.h5\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da03b947",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_output(Model, word):\n",
    "\n",
    "    rev_alphabet={0:'_', 1:'a', 2:'b', 3:'c', 4:'d',5:'e',6:'f',7:'g',8:'h',9:'i',10:'j',11:'k',12:'l',\n",
    "                 13:'m',14:'n',15:'o',16:'p',17:'q',18:'r',19:'s',20:'t',21:'u',22:'v',23:'w',24:'x',\n",
    "                 25:'y',26:'z',27:'é',28:'è',29:'others'}\n",
    "\n",
    "    alphabet={\n",
    "            ' ':0,'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,\n",
    "            'o':15,'p':16,'q':17,'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26,'é':27,\n",
    "            'è':28}\n",
    "\n",
    "    possibilities=[        \n",
    "            ' ','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x',\n",
    "            'y','z','é','è',]\n",
    "\n",
    "    inp=np.zeros((1,3*n_alphabet))\n",
    "    for letter_ind in range(3):\n",
    "        if word[letter_ind] in possibilities:\n",
    "            inp[0,letter_ind*n_alphabet+alphabet[word[letter_ind]]]=1\n",
    "        else:\n",
    "            inp[0,letter_ind*n_alphabet+29]=1\n",
    "\n",
    "    inp=torch.tensor(inp, requires_grad=True).float()\n",
    "    y=Model(inp.to(device))\n",
    "    y = y.cpu()\n",
    "\n",
    "    y00=np.argmax(y[:,:n_alphabet].detach().numpy())\n",
    "    y01=np.argmax(y[:,n_alphabet:2*n_alphabet].detach().numpy())\n",
    "    y02=np.argmax(y[:,2*n_alphabet:3*n_alphabet].detach().numpy())\n",
    "    y10=np.argmax(y[:,3*n_alphabet:4*n_alphabet].detach().numpy())\n",
    "    y11=np.argmax(y[:,4*n_alphabet:5*n_alphabet].detach().numpy())\n",
    "    y12=np.argmax(y[:,5*n_alphabet:6*n_alphabet].detach().numpy())\n",
    "\n",
    "    before=rev_alphabet[y00]+rev_alphabet[y01]+rev_alphabet[y02]\n",
    "    after=rev_alphabet[y10]+rev_alphabet[y11]+rev_alphabet[y12]\n",
    "\n",
    "    return before, after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d404042a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('___', '___')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Emb = embedd()\n",
    "#Emb.load_state_dict(torch.load(\"C:/Users/feoni/OneDrive/Bureau/Polytechnique/ML/DeepLearning_Project/Model.h5\"))\n",
    "#Emb.eval()\n",
    "\n",
    "find_output(Emb, \"cro\")\n",
    "#Encoder avec plus de perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "53c5a15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_encoded(df, line):\n",
    "    \n",
    "    cut=cutter(df[\"text\"][line],3)\n",
    "    length=cut.shape[0]\n",
    "    X=np.zeros((length,3*n_alphabet))\n",
    "    \n",
    "    alphabet={\n",
    "        ' ':0,'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,\n",
    "        'o':15,'p':16,'q':17,'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26,'é':27,\n",
    "        'è':28,\n",
    "        #thus use mod 30 (as 29 is for any other letter (arabic...))\n",
    "        }\n",
    "        \n",
    "    possibilities=[        \n",
    "        ' ','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x',\n",
    "        'y','z','é','è',]\n",
    "\n",
    "    for word_index in range(length):\n",
    "\n",
    "        word=cut[word_index,1]\n",
    "        inp=np.zeros(3*n_alphabet)\n",
    "\n",
    "        for letter_ind in range(3):\n",
    "            \n",
    "            index=0\n",
    "\n",
    "            if (word[letter_ind] not in possibilities):\n",
    "                index0=29\n",
    "            else:\n",
    "                index0=alphabet[word[letter_ind]]\n",
    "                \n",
    "\n",
    "            X[word_index,letter_ind*n_alphabet+index0]=1\n",
    "\n",
    "        \n",
    "    return Emb.encoder(torch.tensor(X, requires_grad=True).float().to(device))#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a4cc5d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5773, 0.5207, 0.4953, 0.5446, 0.5642, 0.5657, 0.5275, 0.5231, 0.5690,\n",
       "         0.5456, 0.5602, 0.5600, 0.5773, 0.4580, 0.5433, 0.5825, 0.5473, 0.5538,\n",
       "         0.5074, 0.5575, 0.5918, 0.5856, 0.5623, 0.5745, 0.5371, 0.5709, 0.5184,\n",
       "         0.4635, 0.5636, 0.5387, 0.5659, 0.5372, 0.5658, 0.5266, 0.5777, 0.5855,\n",
       "         0.5090, 0.5086, 0.4897, 0.5377, 0.5747, 0.4635, 0.5166, 0.5478, 0.5909],\n",
       "        [0.7274, 0.7096, 0.5745, 0.7056, 0.7533, 0.7689, 0.7069, 0.6027, 0.7230,\n",
       "         0.7084, 0.7905, 0.7382, 0.7438, 0.4265, 0.6708, 0.7977, 0.7285, 0.7305,\n",
       "         0.4273, 0.7415, 0.7701, 0.7803, 0.7863, 0.8421, 0.5920, 0.7748, 0.7138,\n",
       "         0.6127, 0.7275, 0.6737, 0.7662, 0.6313, 0.7730, 0.5177, 0.8059, 0.7920,\n",
       "         0.5810, 0.6029, 0.4512, 0.6952, 0.7169, 0.3028, 0.5679, 0.7548, 0.7868],\n",
       "        [0.7609, 0.6891, 0.6614, 0.7328, 0.7659, 0.6729, 0.6793, 0.6059, 0.7364,\n",
       "         0.6168, 0.7899, 0.7634, 0.7906, 0.4867, 0.6797, 0.7444, 0.7652, 0.6925,\n",
       "         0.2090, 0.6409, 0.7825, 0.7684, 0.7526, 0.8809, 0.5473, 0.8249, 0.5842,\n",
       "         0.5597, 0.7481, 0.6678, 0.8256, 0.6657, 0.7372, 0.4836, 0.8192, 0.7947,\n",
       "         0.7200, 0.7147, 0.5239, 0.7380, 0.6934, 0.3192, 0.5337, 0.7120, 0.7882],\n",
       "        [0.5465, 0.4964, 0.5420, 0.5495, 0.5445, 0.5258, 0.5053, 0.4816, 0.5537,\n",
       "         0.4900, 0.5449, 0.5418, 0.5890, 0.4798, 0.5224, 0.5402, 0.5563, 0.5092,\n",
       "         0.4727, 0.5225, 0.5833, 0.5291, 0.5231, 0.5501, 0.5395, 0.5645, 0.4724,\n",
       "         0.4240, 0.5519, 0.5027, 0.5652, 0.5198, 0.5281, 0.5256, 0.5844, 0.5455,\n",
       "         0.5551, 0.5204, 0.5009, 0.5665, 0.5327, 0.4288, 0.5240, 0.5228, 0.5463],\n",
       "        [0.5266, 0.5062, 0.5371, 0.5274, 0.5551, 0.5422, 0.5043, 0.4994, 0.5535,\n",
       "         0.5019, 0.5462, 0.5512, 0.5559, 0.4706, 0.5026, 0.5389, 0.5478, 0.5042,\n",
       "         0.4633, 0.5271, 0.5605, 0.5474, 0.5056, 0.5454, 0.5104, 0.5430, 0.4826,\n",
       "         0.4672, 0.5335, 0.5015, 0.5547, 0.5322, 0.5267, 0.4995, 0.5421, 0.5524,\n",
       "         0.5435, 0.5140, 0.5083, 0.5541, 0.5299, 0.4572, 0.5098, 0.5134, 0.5710],\n",
       "        [0.5734, 0.5517, 0.5260, 0.5713, 0.5825, 0.5829, 0.5555, 0.5273, 0.5856,\n",
       "         0.5432, 0.5779, 0.5788, 0.5969, 0.4756, 0.5402, 0.6009, 0.5739, 0.5595,\n",
       "         0.5167, 0.5761, 0.6030, 0.5942, 0.5622, 0.5820, 0.5438, 0.5958, 0.5366,\n",
       "         0.4771, 0.5450, 0.5421, 0.5851, 0.5531, 0.5765, 0.4785, 0.5675, 0.5924,\n",
       "         0.5392, 0.5259, 0.4960, 0.5741, 0.5624, 0.4477, 0.5349, 0.5529, 0.5846],\n",
       "        [0.6672, 0.6310, 0.5719, 0.6639, 0.6623, 0.6290, 0.6278, 0.5988, 0.6404,\n",
       "         0.6224, 0.7073, 0.6922, 0.6793, 0.4832, 0.6053, 0.7207, 0.7019, 0.6502,\n",
       "         0.3982, 0.6240, 0.6769, 0.6872, 0.6898, 0.7675, 0.6019, 0.6953, 0.6015,\n",
       "         0.4963, 0.6725, 0.5687, 0.7012, 0.6075, 0.6623, 0.5059, 0.7390, 0.6982,\n",
       "         0.6167, 0.6197, 0.4947, 0.6476, 0.6563, 0.3661, 0.5516, 0.6655, 0.7208],\n",
       "        [0.5606, 0.5027, 0.5297, 0.5486, 0.5775, 0.5527, 0.5289, 0.5055, 0.5573,\n",
       "         0.5271, 0.5777, 0.5678, 0.5801, 0.4652, 0.5476, 0.5647, 0.5718, 0.5288,\n",
       "         0.4559, 0.5572, 0.5997, 0.5750, 0.5408, 0.5903, 0.5435, 0.5678, 0.4928,\n",
       "         0.4781, 0.5403, 0.5163, 0.5822, 0.5456, 0.5476, 0.5281, 0.5868, 0.5780,\n",
       "         0.5436, 0.5240, 0.4954, 0.5676, 0.5656, 0.4278, 0.5188, 0.5395, 0.5933],\n",
       "        [0.6746, 0.6759, 0.5775, 0.6729, 0.7027, 0.7174, 0.6473, 0.5733, 0.6672,\n",
       "         0.6603, 0.7347, 0.7033, 0.7060, 0.4325, 0.6229, 0.7470, 0.6878, 0.6933,\n",
       "         0.4393, 0.6859, 0.7235, 0.7237, 0.7023, 0.7724, 0.6142, 0.7049, 0.6605,\n",
       "         0.5856, 0.6759, 0.6365, 0.7165, 0.6002, 0.7047, 0.5084, 0.7466, 0.7317,\n",
       "         0.5710, 0.5718, 0.4675, 0.6388, 0.6827, 0.3470, 0.5386, 0.7109, 0.7317],\n",
       "        [0.6502, 0.5513, 0.6202, 0.6435, 0.6682, 0.5816, 0.5948, 0.5178, 0.6405,\n",
       "         0.5705, 0.6926, 0.6631, 0.6718, 0.4654, 0.6087, 0.6272, 0.6806, 0.6183,\n",
       "         0.3179, 0.5901, 0.6762, 0.6842, 0.6307, 0.7489, 0.5392, 0.6815, 0.5140,\n",
       "         0.5530, 0.6438, 0.5602, 0.6906, 0.6063, 0.6044, 0.5060, 0.7014, 0.6922,\n",
       "         0.6207, 0.5889, 0.5278, 0.6457, 0.6157, 0.3536, 0.5219, 0.5983, 0.7117],\n",
       "        [0.6531, 0.6238, 0.5851, 0.6364, 0.6379, 0.6293, 0.5899, 0.5562, 0.6439,\n",
       "         0.5990, 0.6756, 0.6443, 0.6772, 0.4672, 0.5766, 0.6598, 0.6775, 0.6208,\n",
       "         0.3899, 0.6038, 0.6831, 0.6821, 0.6466, 0.7179, 0.5240, 0.6895, 0.5541,\n",
       "         0.5160, 0.6587, 0.6047, 0.6807, 0.5958, 0.6349, 0.4947, 0.6833, 0.7030,\n",
       "         0.5938, 0.5828, 0.4986, 0.6201, 0.6280, 0.3691, 0.5421, 0.6150, 0.6825],\n",
       "        [0.5246, 0.4543, 0.5087, 0.5021, 0.5172, 0.4987, 0.4656, 0.4753, 0.5319,\n",
       "         0.4666, 0.5105, 0.4867, 0.5518, 0.4555, 0.5075, 0.5017, 0.5054, 0.4896,\n",
       "         0.4912, 0.4983, 0.5304, 0.5250, 0.4827, 0.5021, 0.5182, 0.5200, 0.4618,\n",
       "         0.4330, 0.5053, 0.4686, 0.5338, 0.5034, 0.4957, 0.5287, 0.5348, 0.5202,\n",
       "         0.5234, 0.4842, 0.5077, 0.5199, 0.5185, 0.4722, 0.5213, 0.4788, 0.5285],\n",
       "        [0.5101, 0.5234, 0.5239, 0.4908, 0.5315, 0.5183, 0.4972, 0.5051, 0.5350,\n",
       "         0.4897, 0.5219, 0.5320, 0.5585, 0.4618, 0.4936, 0.5394, 0.5405, 0.5087,\n",
       "         0.4918, 0.5186, 0.5395, 0.5558, 0.5025, 0.5255, 0.5128, 0.5355, 0.4850,\n",
       "         0.4444, 0.5257, 0.4889, 0.5282, 0.5110, 0.5354, 0.5087, 0.5432, 0.5568,\n",
       "         0.5165, 0.5079, 0.4856, 0.5336, 0.5248, 0.4647, 0.5209, 0.5262, 0.5454],\n",
       "        [0.6127, 0.5632, 0.5697, 0.5643, 0.6054, 0.5526, 0.5792, 0.5427, 0.6154,\n",
       "         0.5350, 0.6073, 0.6035, 0.6128, 0.4661, 0.5580, 0.6201, 0.6328, 0.5968,\n",
       "         0.4331, 0.6016, 0.6271, 0.6483, 0.5996, 0.6498, 0.5338, 0.6457, 0.5166,\n",
       "         0.4567, 0.6017, 0.5568, 0.6354, 0.5431, 0.5956, 0.5247, 0.6384, 0.6346,\n",
       "         0.5652, 0.5590, 0.4900, 0.5704, 0.5896, 0.4281, 0.5214, 0.5731, 0.6371],\n",
       "        [0.6733, 0.6118, 0.6119, 0.6772, 0.6881, 0.6751, 0.6131, 0.5489, 0.6796,\n",
       "         0.6023, 0.7246, 0.6798, 0.7020, 0.4931, 0.6120, 0.7048, 0.6924, 0.6322,\n",
       "         0.3576, 0.6536, 0.7173, 0.6692, 0.6856, 0.7695, 0.5699, 0.7050, 0.5822,\n",
       "         0.5708, 0.6552, 0.6112, 0.7346, 0.6274, 0.6587, 0.4972, 0.7067, 0.6969,\n",
       "         0.6128, 0.6297, 0.5382, 0.6690, 0.6547, 0.3343, 0.5238, 0.6673, 0.7204],\n",
       "        [0.6296, 0.5497, 0.5523, 0.6073, 0.6473, 0.5919, 0.5671, 0.5226, 0.5994,\n",
       "         0.5509, 0.6502, 0.6357, 0.6300, 0.4738, 0.5964, 0.6027, 0.6247, 0.5746,\n",
       "         0.3926, 0.5802, 0.6557, 0.6348, 0.5883, 0.6960, 0.5574, 0.6307, 0.5142,\n",
       "         0.5256, 0.5946, 0.5285, 0.6706, 0.5870, 0.5871, 0.5008, 0.6697, 0.6448,\n",
       "         0.5859, 0.5600, 0.4952, 0.6044, 0.6036, 0.4165, 0.5108, 0.5969, 0.6605],\n",
       "        [0.6393, 0.5549, 0.5462, 0.6071, 0.6123, 0.5976, 0.5774, 0.5295, 0.6234,\n",
       "         0.5802, 0.6423, 0.6176, 0.6526, 0.4892, 0.5777, 0.6423, 0.6401, 0.5861,\n",
       "         0.4081, 0.5970, 0.6465, 0.6509, 0.6208, 0.6740, 0.5342, 0.6393, 0.5151,\n",
       "         0.5258, 0.6113, 0.5597, 0.6382, 0.6009, 0.5949, 0.4942, 0.6443, 0.6401,\n",
       "         0.5561, 0.5745, 0.5374, 0.5973, 0.6114, 0.3779, 0.5362, 0.6000, 0.6560],\n",
       "        [0.6110, 0.5605, 0.5566, 0.6079, 0.6265, 0.5907, 0.5697, 0.5265, 0.5954,\n",
       "         0.5618, 0.6378, 0.6294, 0.6304, 0.4432, 0.5638, 0.6283, 0.6088, 0.6048,\n",
       "         0.4545, 0.5717, 0.6490, 0.6204, 0.5768, 0.6765, 0.5686, 0.6389, 0.5627,\n",
       "         0.5253, 0.5764, 0.5716, 0.6204, 0.5746, 0.5964, 0.5010, 0.6223, 0.6482,\n",
       "         0.5774, 0.5106, 0.4909, 0.5891, 0.6077, 0.4184, 0.5329, 0.6061, 0.6519],\n",
       "        [0.5362, 0.4970, 0.5296, 0.5093, 0.5348, 0.5142, 0.5044, 0.5039, 0.5451,\n",
       "         0.4923, 0.5385, 0.5272, 0.5503, 0.4511, 0.5164, 0.5409, 0.5466, 0.5052,\n",
       "         0.4717, 0.5140, 0.5731, 0.5496, 0.5150, 0.5507, 0.5487, 0.5403, 0.4760,\n",
       "         0.4316, 0.5264, 0.4877, 0.5748, 0.5042, 0.5178, 0.5348, 0.5731, 0.5587,\n",
       "         0.5411, 0.5168, 0.4924, 0.5332, 0.5351, 0.4600, 0.5051, 0.5051, 0.5744]],\n",
       "       device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_encoded(df, 2) #give the tensor of the complete embedded tweet (each 3 letter)\n",
    "\n",
    "#sentence_encoded(3).shape\n",
    "#30 for the alphabet size \n",
    "#the first argument is the tweet lenght"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42898d2d",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">4. NN coupled with RNN to find the rt </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c73c986a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feelings=5 #return of RNN part\n",
    "n_mainstream=5+3 #followers, likes, verified... data that didn't get treated (no need) (after normalisation) +time\n",
    "n_PCA_words=4 #after PCA on words\n",
    "n_PCA_hashtag=3 #after PCA on hashtags\n",
    "\n",
    "final_dim=n_feelings+n_mainstream+n_PCA_words+n_PCA_hashtag\n",
    "final_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42da847",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">4.1 RNN on embedded words: Understanding relations between words to extract a general opinion/feeling from the tweet</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45e35589",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeelingsFinder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        #RNN layer (30 for the input word vectors and 5 for the feeling vector of previous run)\n",
    "        self.recurrNN=nn.RNN(30, n_feelings)\n",
    "        #30 is the input vector and n_feelings the output vector\n",
    "        self.lin=nn.Linear(n_feelings,n_feelings)\n",
    "        #the rnn output 2 vectors : 1 output \"normal\" and one for the repetition\n",
    "        #the two args need to have the same size because the layer is expected to receive a same size input \n",
    "        \n",
    "    def forward(self,x): #x is a matrix of vectorised sentence\n",
    "            \n",
    "        #initialize first feeling vector \n",
    "        h=torch.zeros(1,n_feelings).to(device)\n",
    "        \n",
    "        #feed forward (x of shape (number of patches of 3, 100))\n",
    "        for i in range(x.shape[0]):\n",
    "            #we dont have to pay attention to the \"h\", because the thing we return is the \"out\" after it passed through the linear layer\n",
    "            out, _ =self.recurrNN(x[i:i+1,:],h)\n",
    "            out=self.lin(out)\n",
    "            h=out\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "656e2580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "ff = FeelingsFinder().to(device)\n",
    "ff\n",
    "\n",
    "dummy_input = torch.rand((40, 30)).to(device)\n",
    "dummy_input\n",
    "\n",
    "print(ff(dummy_input).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ef0c60",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">4.2 NN to find out rt: takes as input the output of RNN & all the treated dimensions above (2 PCAs, normalised mainstream dimensions...)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ada94945",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RTFinder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.NN=nn.Sequential(\n",
    "        \n",
    "        nn.Linear(final_dim,10,bias=True),\n",
    "        nn.ReLU(True),\n",
    "            \n",
    "        nn.Linear(10,4,bias=True),\n",
    "        nn.ReLU(True),\n",
    "        \n",
    "        nn.Linear(4,1, bias=True),\n",
    "        nn.Sigmoid())\n",
    "        \n",
    "        self.feelings_finder = FeelingsFinder()\n",
    "        \n",
    "    def forward(self, x, y): #x is concatenatioon of all dimensions and y same as x in forward of FeelingsFinder\n",
    "        \n",
    "        feelings = self.feelings_finder(y)\n",
    "        \n",
    "        nn_input = torch.cat((x.T,feelings.T)).T\n",
    "        \n",
    "        print(nn_input.shape)\n",
    "        \n",
    "        return self.NN(nn_input)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "762e06b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 16])\n",
      "tensor([[0.5453]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand((40, 30)).to(device)\n",
    "\n",
    "RT= RTFinder().to(device)\n",
    "\n",
    "dummy_input2 = torch.rand((1, 11)).to(device)\n",
    "dummy_input3 = torch.rand((1, 11)).to(device)\n",
    "\n",
    "#print(torch.cat((dummy_input2.T, dummy_input3.T)).T.shape)\n",
    "print(RT(dummy_input2, dummy_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "60bda9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_train(line):\n",
    "    concat_data=np.zeros((1, 15))\n",
    "    concat_data[0,0]=df[\"favorites_count\"][line]\n",
    "    concat_data[0,1]=df[\"followers_count\"][line]\n",
    "    concat_data[0,2]=df[\"friends_count\"][line]\n",
    "    concat_data[0,3]=df[\"statuses_count\"][line]\n",
    "    concat_data[0,4]=df[\"verified\"][line]\n",
    "    concat_data[0,5]=df[\"month\"][line]\n",
    "    concat_data[0,6]=df[\"day\"][line]\n",
    "    concat_data[0,7]=df[\"moment\"][line]\n",
    "    \n",
    "    #try to define the most important words so no need to redefine them later\n",
    "    \n",
    "    PCA_text=PCA_training(array_train_text,4)[0][line,:]\n",
    "    concat_data[0,8:12]=PCA_text\n",
    "    \n",
    "    PCA_hashtag=PCA_training(array_train_hashtags,3)[0][line,:]\n",
    "    concat_data[0,12:15]=PCA_hashtag\n",
    "    \n",
    "    return torch.tensor(concat_data).float(), sentence_encoded(df, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f949d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  0.4480,  0.5473,  0.7705,  0.0000,  0.1818,  0.4667,  0.4844,\n",
       "          -0.2490, -0.1701,  0.1340,  0.3202,  0.1854,  0.0083,  0.0022]]),\n",
       " tensor([[0.5830, 0.5485, 0.5376,  ..., 0.5263, 0.5842, 0.6271],\n",
       "         [0.6527, 0.6248, 0.6201,  ..., 0.5566, 0.6554, 0.7222],\n",
       "         [0.6211, 0.5855, 0.5617,  ..., 0.5190, 0.6119, 0.6321],\n",
       "         ...,\n",
       "         [0.7425, 0.7111, 0.6553,  ..., 0.5844, 0.7581, 0.8068],\n",
       "         [0.6641, 0.5897, 0.6085,  ..., 0.5647, 0.6333, 0.6876],\n",
       "         [0.5207, 0.4758, 0.5425,  ..., 0.5218, 0.4901, 0.5587]],\n",
       "        device='cuda:0', grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed77415c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                  | 0/35000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                  | 0/35000 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 30, got 45",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m x0 \u001b[38;5;241m=\u001b[39m x0\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     16\u001b[0m x1 \u001b[38;5;241m=\u001b[39m x1\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 17\u001b[0m rt\u001b[38;5;241m=\u001b[39m\u001b[43mRT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m rt_target\u001b[38;5;241m=\u001b[39mdf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretweets_count\u001b[39m\u001b[38;5;124m\"\u001b[39m][line]\n\u001b[1;32m     19\u001b[0m rt_target \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(rt_target)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/dev/perso/Tweet_Prediction/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[64], line 22\u001b[0m, in \u001b[0;36mRTFinder.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y): \u001b[38;5;66;03m#x is concatenatioon of all dimensions and y same as x in forward of FeelingsFinder\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     feelings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeelings_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     nn_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x\u001b[38;5;241m.\u001b[39mT,feelings\u001b[38;5;241m.\u001b[39mT))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(nn_input\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/dev/perso/Tweet_Prediction/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[42], line 22\u001b[0m, in \u001b[0;36mFeelingsFinder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m#feed forward (x of shape (number of patches of 3, 100))\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m#we dont have to pay attention to the \"h\", because the thing we return is the \"out\" after it passed through the linear layer\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m     out, _ \u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecurrNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(out)\n\u001b[1;32m     24\u001b[0m     h\u001b[38;5;241m=\u001b[39mout\n",
      "File \u001b[0;32m~/dev/perso/Tweet_Prediction/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/dev/perso/Tweet_Prediction/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:472\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    469\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[1;32m    471\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m hx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_TANH\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRNN_RELU\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/dev/perso/Tweet_Prediction/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:234\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[0;32m~/dev/perso/Tweet_Prediction/venv/lib/python3.8/site-packages/torch/nn/modules/rnn.py:210\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    208\u001b[0m             expected_input_dim, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    212\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 30, got 45"
     ]
    }
   ],
   "source": [
    "#Training loop (train for each line)\n",
    "\n",
    "RT=RTFinder().to(device)\n",
    "progressbar = tqdm(range(35000))\n",
    "loss=None\n",
    "loss_list=[]\n",
    "\n",
    "optimizer = Adam(RT.parameters(),lr=0.001)\n",
    "\n",
    "for line in progressbar:\n",
    "    print(line)\n",
    "    if loss is None:\n",
    "        optimizer.zero_grad()\n",
    "    x0, x1 = data_to_train(line)\n",
    "    x0 = x0.to(device)\n",
    "    x1 = x1.to(device)\n",
    "    rt=RT(x0, x1)\n",
    "    rt_target=df[\"retweets_count\"][line]\n",
    "    rt_target = torch.tensor(rt_target).to(device)\n",
    "    loss_func=nn.MSELoss()\n",
    "    \n",
    "    if loss is None:\n",
    "        loss=loss_func(rt, torch.tensor(rt_target).float())\n",
    "    else:\n",
    "        loss+=loss_func(rt, torch.tensor(rt_target).float())\n",
    "    \n",
    "    if line%500==0 and line!=0:\n",
    "        line/=500\n",
    "        torch.save(Emb.state_dict(),\"Final_Network.h5\")\n",
    "        \n",
    "        loss_list.append(loss.item()) #All this to update the loss plot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(loss_list)\n",
    "        fig.savefig(\"loss plot.png\")\n",
    "        plt.close(fig)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Loss: {loss.item(): .6f}\")\n",
    "        #progressbar.set_description(f\"Loss: {loss.item(): .6f}\")\n",
    "        loss=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3f978b",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">5. Apply everything onto test dataset </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fcd870",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">5.1 Prepare test data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cae7f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9194b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=Normaliser(df, df_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f98e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_test(line):\n",
    "    concat_data=np.zeros((1,15))\n",
    "    concat_data[0,0]=df_test[\"favorites_count\"][line]\n",
    "    concat_data[0,1]=df_test[\"followers_count\"][line]\n",
    "    concat_data[0,2]=df_test[\"friends_count\"][line]\n",
    "    concat_data[0,3]=df_test[\"statuses_count\"][line]\n",
    "    concat_data[0,4]=df_test[\"verified\"][line]\n",
    "    concat_data[0,5]=df_test[\"month\"][line]\n",
    "    concat_data[0,6]=df_test[\"day\"][line]\n",
    "    concat_data[0,7]=df_test[\"moment\"][line]\n",
    "    \n",
    "    PCA_text=PCA_test(array_train_text,array_test_text,4)[line,:]\n",
    "    concat_data[0,8:12]=PCA_text\n",
    "    \n",
    "    PCA_hashtag=PCA_test(array_train_hashtags,array_test_hashtags,3)[line,:]\n",
    "    concat_data[0,12:15]=PCA_hashtag\n",
    "    \n",
    "    return torch.tensor(concat_data).float(), sentence_encoded(df_test, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99026288",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_to_test(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01352ea3",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">5.2 Predict on the test data</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec25bf59",
   "metadata": {},
   "source": [
    "Loss function : Mean Absolute Error (MAE) ->\n",
    "The MAE metric is calculated by dividing the sum of absolute differences between the predicted\n",
    "number of retweets (pi) and the observed number of retweets (ai) by the number of observations\n",
    "(N), i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf77c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, predictions):\n",
    "    y_true, predictions = np.array(y_true), np.array(predictions)\n",
    "    return np.mean(np.abs(y_true - predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c7f346",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval=mae(Y,predictions)\n",
    "print(eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
