{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "84d73323",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1c13ff",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">1. Preprocessing </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06532983",
   "metadata": {},
   "source": [
    "##  <span style=\"color:indigo\"> 1.1 Dataset observation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "3260f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lecture du fichier .csv par la libraire Pandas\n",
    "data=pd.read_csv('train.csv')\n",
    "df1=data.copy()\n",
    "df_test1=pd.read_csv('evaluation.csv')\n",
    "\n",
    "#We need to separate X and Y\n",
    "#X=data.loc[:,data.columns!=\"retweets_count\"]\n",
    "#Y=data['retweets_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f01832",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">1.2 Features explanations </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d03fc63",
   "metadata": {},
   "source": [
    "df.quantile(0.99) #We check if there is a lot ludicrous values "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc394984",
   "metadata": {},
   "source": [
    "#If our dataset contains empty values, we put the mean value of the collum\n",
    "if df.isnull().sum().sum()!=0: \n",
    "    imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "else: \n",
    "    print(\"No missing_values in this dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee09ca7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "corr_matrix = df.corr()\n",
    "plt.figure(figsize=(28,24))\n",
    "sns.heatmap(data = corr_matrix,cmap='BrBG', annot=True, linewidths=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555418d0",
   "metadata": {},
   "source": [
    " ------> We observe that the only strong correlation that we can see at this time is the one between [favorite_count] \n",
    "and [retweet_count] , so we can already say that to predict the number of retweet, the number of favorite count is very important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16545ab",
   "metadata": {},
   "source": [
    "#checking for missing values in output\n",
    "for i in range(df.shape[0]):\n",
    "    if df['retweets_count'][i]==[]:\n",
    "        print(df['retweets_count'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75cb0c3",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">1.3 Normalisations </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d4a204",
   "metadata": {},
   "source": [
    "On doit normaliser les données mais chaque colonne doit être normalisé différemment. \n",
    "- \"favorites_count\" -> moins de 1% de valeurs abhérantes (au top)\n",
    "- \"followers_count\", -> Exponential \n",
    "- \"statutes_count\",\n",
    "- \"friends_count\" -> moins de 1% de valeurs abhérantes (au top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3f5be6",
   "metadata": {},
   "source": [
    "Normalization.quantile(0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "6882438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_into_df(df):\n",
    "    result=pd.DataFrame(df,columns=[\"month\", \"day\", \"moment\"])\n",
    "    timestamps=np.array(df[\"timestamp\"])\n",
    "    \n",
    "    for i in range(timestamps.shape[0]):\n",
    "        date=dt.fromtimestamp(timestamps[i]/1000)\n",
    "        result[\"month\"][i]=date.month\n",
    "        result[\"day\"][i]=date.day\n",
    "        result[\"moment\"][i]=date.hour+date.minute/60\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "af76d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(x):\n",
    "     return np.log(1+x)\n",
    "\n",
    "def Normaliser(df, df_test):\n",
    "    \n",
    "    column_names=[\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\"]\n",
    "    \n",
    "    #Create DFs and apply log to them\n",
    "    \n",
    "    Norm_train=pd.DataFrame(df,columns=[\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\"])\n",
    "    Norm_train['favorites_count'] = Norm_train['favorites_count'].transform(myfunc)\n",
    "    Norm_train['followers_count'] = Norm_train['followers_count'].transform(myfunc)\n",
    "    Norm_train['friends_count'] = Norm_train['friends_count'].transform(myfunc)\n",
    "    Norm_train['statuses_count'] = Norm_train['statuses_count'].transform(myfunc)\n",
    "    \n",
    "    Norm_rt=pd.DataFrame(df,columns=[\"retweets_count\"])\n",
    "    Norm_rt['retweets_count'] = Norm_rt['retweets_count'].transform(myfunc)\n",
    "    \n",
    "    Norm_test=pd.DataFrame(df_test,columns=[\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\"])\n",
    "    Norm_test['favorites_count'] = Norm_test['favorites_count'].transform(myfunc)\n",
    "    Norm_test['followers_count'] = Norm_test['followers_count'].transform(myfunc)\n",
    "    Norm_test['friends_count'] = Norm_test['friends_count'].transform(myfunc)\n",
    "    Norm_test['statuses_count'] = Norm_test['statuses_count'].transform(myfunc)\n",
    "    \n",
    "    #Also add time\n",
    "    \n",
    "    Time_train=get_time_into_df(df)\n",
    "    Time_test=get_time_into_df(df_test)\n",
    "    \n",
    "    #Now rescale with min-max\n",
    "    \n",
    "    scaler_train=MinMaxScaler()\n",
    "    scaler_train.fit(Norm_train)\n",
    "    norm_train=scaler_train.transform(Norm_train)\n",
    "    norm_test=scaler_train.transform(Norm_test)\n",
    "    \n",
    "    scaler_rt=MinMaxScaler()\n",
    "    scaler_rt.fit(Norm_rt)\n",
    "    norm_rt=scaler_rt.transform(Norm_rt)\n",
    "    \n",
    "    scaler_time=MinMaxScaler()\n",
    "    scaler_time.fit(Time_train)\n",
    "    norm_time_train=scaler_time.transform(Time_train)\n",
    "    norm_time_test=scaler_time.transform(Time_test)\n",
    "    \n",
    "    #Now put the rescaled results into the original DFs\n",
    "    \n",
    "    Norm_train=pd.DataFrame(norm_train,columns=column_names)\n",
    "    Norm_test=pd.DataFrame(norm_test,columns=column_names)\n",
    "    Norm_rt=pd.DataFrame(norm_rt,columns=[\"retweets_count\"])\n",
    "    \n",
    "    NormT_train=pd.DataFrame(norm_time_train,columns=[\"month\", \"day\", \"moment\"])\n",
    "    NormT_test=pd.DataFrame(norm_time_test,columns=[\"month\", \"day\", \"moment\"])\n",
    "    \n",
    "    df['favorites_count']=Norm_train['favorites_count']\n",
    "    df['followers_count']=Norm_train['followers_count'] \n",
    "    df['statuses_count']=Norm_train['statuses_count']\n",
    "    df['friends_count']=Norm_train['friends_count']\n",
    "    df['retweets_count']=Norm_rt['retweets_count']\n",
    "    \n",
    "    df_test['favorites_count']=Norm_test['favorites_count']\n",
    "    df_test['followers_count']=Norm_test['followers_count'] \n",
    "    df_test['statuses_count']=Norm_test['statuses_count']\n",
    "    df_test['friends_count']=Norm_test['friends_count']\n",
    "    \n",
    "    df[\"month\"]=NormT_train[\"month\"]\n",
    "    df[\"day\"]=NormT_train[\"day\"]\n",
    "    df[\"moment\"]=NormT_train[\"moment\"]\n",
    "    \n",
    "    df_test[\"month\"]=NormT_test[\"month\"]\n",
    "    df_test[\"day\"]=NormT_test[\"day\"]\n",
    "    df_test[\"moment\"]=NormT_test[\"moment\"]\n",
    "\n",
    "    return df, df_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "6fbc0749",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_test= Normaliser(df1,df_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa752937",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">2. PCA Text and # treatment </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d4d4cb",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:indigo\">2.1 Preprocessing of hashtags and texts </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "5f0c214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for hashtags\n",
    "\n",
    "def most_important_hashtags(df, criteria):\n",
    "    DICO2={} #DICO2 is for hashtags\n",
    "    I=df.shape[0]\n",
    "    for i in range(I):\n",
    "        sentence=df[\"hashtags\"][i][1:-1].replace(' ', '').split(',')\n",
    "        for word in sentence:\n",
    "            extracted_word=word[1:-1]\n",
    "            if extracted_word in DICO2:\n",
    "                DICO2[extracted_word]+=1\n",
    "            else:\n",
    "                DICO2[extracted_word]=1\n",
    "    most_occurr_DICO2={}\n",
    "    for word in DICO2:\n",
    "        if DICO2[word]>criteria :#and word!=''\n",
    "            most_occurr_DICO2[word]=0\n",
    "    \n",
    "    important_hashtags=list(most_occurr_DICO2.keys())\n",
    "    \n",
    "    measurer2={}\n",
    "    for i in range(len(important_hashtags)):\n",
    "        measurer2[important_hashtags[i]]=i\n",
    "    measurer2\n",
    "    return important_hashtags, measurer2\n",
    "\n",
    "def make_array_training_hashtags(df, criteria):\n",
    "    possibilities, measurer=most_important_hashtags(df, criteria)\n",
    "    result=np.zeros((df.shape[0], len(possibilities)))\n",
    "    for line in range(df.shape[0]):\n",
    "        sentence=df[\"hashtags\"][line][1:-1].replace(' ', '').split(',')\n",
    "        for word in sentence:\n",
    "            extracted_word=word[1:-1]\n",
    "            if extracted_word in possibilities:\n",
    "                result[line,measurer[extracted_word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "def make_array_test_hashtags(df_test, criteria):\n",
    "    possibilities, measurer=most_important_hashtags(df, criteria)\n",
    "    result=np.zeros((df_test.shape[0], len(possibilities)))\n",
    "    for line in range(df_test.shape[0]):\n",
    "        sentence=df_test[\"hashtags\"][line][1:-1].replace(' ', '').split(',')\n",
    "        for word in sentence:\n",
    "            extracted_word=word[1:-1]\n",
    "            if extracted_word in possibilities:\n",
    "                result[line,measurer[extracted_word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "array_train_hashtags=make_array_training_hashtags(df,10)\n",
    "array_test_hashtags=make_array_test_hashtags(df_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "612ac371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for texts\n",
    "\n",
    "def most_important_words(df, criteria):\n",
    "    DICO={}\n",
    "    I=df.shape[0]\n",
    "    for i in range(I):\n",
    "        sentence=df[\"text\"][i].split()\n",
    "        for word in sentence:\n",
    "            if word in DICO:\n",
    "                DICO[word]+=1\n",
    "            else:\n",
    "                DICO[word]=1\n",
    "            \n",
    "    most_occurr_DICO={}\n",
    "    for word in DICO:\n",
    "        if DICO[word]>criteria:\n",
    "            most_occurr_DICO[word]=0\n",
    "    \n",
    "    important_words=list(most_occurr_DICO.keys())\n",
    "    measurer={}\n",
    "    for i in range(len(important_words)):\n",
    "        measurer[important_words[i]]=i\n",
    "    measurer\n",
    "    \n",
    "    return important_words, measurer\n",
    "\n",
    "def make_array_training_words(df, criteria):\n",
    "    possibilities, measurer=most_important_words(df, criteria)\n",
    "    result=np.zeros((df.shape[0], len(possibilities)))\n",
    "    for line in range(df.shape[0]):\n",
    "        sentence=df[\"text\"][line].split()\n",
    "        for word in sentence:\n",
    "            if word in possibilities:\n",
    "                result[line,measurer[word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "def make_array_test_words(df_test, criteria):\n",
    "    possibilities, measurer=most_important_words(df, criteria)\n",
    "    result=np.zeros((df_test.shape[0], len(possibilities)))\n",
    "    for line in range(df_test.shape[0]):\n",
    "        sentence=df_test[\"text\"][line].split()\n",
    "        for word in sentence:\n",
    "            if word in possibilities:\n",
    "                result[line,measurer[word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "array_train_text=make_array_training_words(df,5000)\n",
    "array_test_text=make_array_test_words(df_test, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1224661d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "## <span style=\"color:indigo\">2.2 PCA on words and hashtags: Understanding the main components of bags of words </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "bcdada19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_training(array, n_comp):\n",
    "    n=array.shape[1]\n",
    "    for col in range(n):\n",
    "        mean=np.mean(array[:,col])\n",
    "        array[:,col]-=mean\n",
    "            \n",
    "    C=np.matmul(array.T,array)\n",
    "    C/=array.shape[1]\n",
    "    \n",
    "    Lambda, Q=np.linalg.eigh(C)\n",
    "\n",
    "    Qk=np.zeros((n,n_comp))\n",
    "    for col in range(n_comp):\n",
    "        Qk[:,col]=Q[:,n-col-1]\n",
    "    return np.matmul(array,Qk), Qk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "afdd7875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_test(training_array, test_array, n_comp):\n",
    "    return np.matmul(test_array,PCA_training(training_array,n_comp)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c5e43e",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">3. Preparing RNN on word sequences: Understanding relations between words </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9396b7",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:indigo\"> 3.1 Pre-treatment for word embedding </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e31ed4",
   "metadata": {},
   "source": [
    "We will use the FastText method. We divide each word into groups of 3 letters (spaces are the \"empty letter\"). We keep the order in the text and make an embedding also using the adjacent words. For instance:\n",
    "\"macron demission\"==> -ma,mac,acr,...,on-,n-d,-de,dem,... (- is the empty letter)\n",
    "\n",
    "The fast text method will guess the adjacent 3 letters to each given patch of 3 letters. Hence for \"mac\" we want a high probability of \"---\" (3 times empty letter) and \"ron\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "a0b2651f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  device = \"cuda:0\" \n",
    "else:  \n",
    "  device = \"cpu\"  \n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "d221d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns an array with the words in the sentence cut (n=3 that is in pieces of 3)\n",
    "\n",
    "def cutter(sent, n):\n",
    "    sentence=sent.split()\n",
    "    length=len(sentence)+2-n\n",
    "    for word in sentence:\n",
    "        length+=len(word)\n",
    "    result=[]\n",
    "    padding=''\n",
    "    for i in range(n):\n",
    "        padding+=' '\n",
    "    sent=' '+sent+' '\n",
    "    padd_sent=padding+sent+padding\n",
    "    \n",
    "    for i in range(length):\n",
    "        middle=sent[i:i+n]\n",
    "        before=padd_sent[i:i+n]\n",
    "        after=padd_sent[2*n+i:3*n+i]\n",
    "        result.append([before, middle, after])\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "669bec9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphabet=30\n",
    "\n",
    "def batch_maker(size):\n",
    "    X=np.zeros((size,3*n_alphabet))\n",
    "    Y=np.zeros((size,6*n_alphabet))\n",
    "    for i in range(size):\n",
    "        \n",
    "        line=random.randrange(0,350000)\n",
    "        cut=cutter(df[\"text\"][line],3)\n",
    "        \n",
    "        alphabet={\n",
    "        ' ':0,'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,\n",
    "        'o':15,'p':16,'q':17,'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26,'é':27,\n",
    "        'è':28,\n",
    "        #thus use mod 30 (as 29 is for any other letter (arabic...))\n",
    "        }\n",
    "        \n",
    "        possibilities=[        \n",
    "        ' ','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x',\n",
    "        'y','z','é','è',]\n",
    "        \n",
    "        length=cut.shape[0]\n",
    "        word_index=random.randrange(0,length)\n",
    "        \n",
    "        word0=cut[word_index, 0]\n",
    "        word1=cut[word_index, 1]\n",
    "        word2=cut[word_index, 2]\n",
    "        for letter_ind in range(3):\n",
    "            index0=0\n",
    "            index1=0\n",
    "            index2=0\n",
    "            if (word0[letter_ind] not in possibilities):\n",
    "                index0=29\n",
    "            else:\n",
    "                index0=alphabet[word0[letter_ind]]\n",
    "                \n",
    "            if (word1[letter_ind] not in possibilities):\n",
    "                index1=29\n",
    "            else:\n",
    "                index1=alphabet[word1[letter_ind]]\n",
    "                \n",
    "            if (word2[letter_ind] not in possibilities):\n",
    "                index2=29\n",
    "            else:\n",
    "                index2=alphabet[word2[letter_ind]]\n",
    "                \n",
    "            Y[i,letter_ind*n_alphabet+index0]=1\n",
    "            X[i,letter_ind*n_alphabet+index1]=1\n",
    "            Y[i,3*n_alphabet+letter_ind*n_alphabet+index2]=1\n",
    "        \n",
    "    return torch.tensor(X, requires_grad=True).float(),torch.tensor(Y, requires_grad=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "4b49c033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 90])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_maker(100)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe99eaa7",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\"> 3.2 Encoder/decoder to mimic FastText</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212deded",
   "metadata": {},
   "source": [
    "This model takes a \"word\" (3 letters patch) as input and return a size 100 vector who is encoded to take into consideration the past and future patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b92c3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class embedd(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        #A sequential container: Modules will be added to it in the order they are passed in the constructor. \n",
    "        self.encoder=nn.Sequential(\n",
    "            \n",
    "        nn.Linear(3*n_alphabet,70,bias=True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(70,45,bias=True),\n",
    "        nn.Sigmoid())\n",
    "        \n",
    "        self.decoder=nn.Sequential(\n",
    "        \n",
    "        nn.Linear(45,110, bias=True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(110,6*n_alphabet,bias=True),\n",
    "        )\n",
    "        \n",
    "        #The forward() method of Sequential accepts \n",
    "        #any input and forwards it to the first module it contains.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x=self.encoder(x)\n",
    "        x=self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "cb78c0f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "  1%|          | 2/200 [00:00<00:15, 13.09it/s]\u001b[A\n",
      "  2%|▏         | 4/200 [00:00<00:15, 12.60it/s]\u001b[A\n",
      "  2%|▎         | 5/200 [00:00<00:17, 11.02it/s]\u001b[A\n",
      "  4%|▎         | 7/200 [00:00<00:17, 11.09it/s]\u001b[A\n",
      "  4%|▍         | 9/200 [00:00<00:16, 11.53it/s]\u001b[A\n",
      "  6%|▌         | 11/200 [00:00<00:15, 12.06it/s]\u001b[A\n",
      "  6%|▋         | 13/200 [00:01<00:15, 12.15it/s]\u001b[A\n",
      "  8%|▊         | 15/200 [00:01<00:15, 12.25it/s]\u001b[A\n",
      "  8%|▊         | 17/200 [00:01<00:15, 12.08it/s]\u001b[A\n",
      " 10%|▉         | 19/200 [00:01<00:15, 11.46it/s]\u001b[A\n",
      " 10%|█         | 21/200 [00:01<00:15, 11.23it/s]\u001b[A\n",
      " 12%|█▏        | 23/200 [00:01<00:15, 11.11it/s]\u001b[A\n",
      " 12%|█▎        | 25/200 [00:02<00:15, 11.22it/s]\u001b[A\n",
      " 14%|█▎        | 27/200 [00:02<00:15, 11.37it/s]\u001b[A\n",
      " 14%|█▍        | 29/200 [00:02<00:14, 11.44it/s]\u001b[A\n",
      " 16%|█▌        | 31/200 [00:02<00:14, 11.57it/s]\u001b[A\n",
      " 16%|█▋        | 33/200 [00:02<00:15, 11.08it/s]\u001b[A\n",
      " 18%|█▊        | 35/200 [00:03<00:14, 11.07it/s]\u001b[A\n",
      " 18%|█▊        | 37/200 [00:03<00:14, 11.52it/s]\u001b[A\n",
      " 20%|█▉        | 39/200 [00:03<00:13, 11.92it/s]\u001b[A\n",
      " 20%|██        | 41/200 [00:03<00:13, 12.04it/s]\u001b[A\n",
      " 22%|██▏       | 43/200 [00:03<00:12, 12.33it/s]\u001b[A\n",
      " 22%|██▎       | 45/200 [00:03<00:12, 12.69it/s]\u001b[A\n",
      " 24%|██▎       | 47/200 [00:03<00:11, 12.91it/s]\u001b[A\n",
      " 24%|██▍       | 49/200 [00:04<00:11, 13.08it/s]\u001b[A\n",
      " 26%|██▌       | 51/200 [00:04<00:11, 13.18it/s]\u001b[A\n",
      " 26%|██▋       | 53/200 [00:04<00:11, 13.21it/s]\u001b[A\n",
      " 28%|██▊       | 55/200 [00:04<00:11, 12.99it/s]\u001b[A\n",
      " 28%|██▊       | 57/200 [00:05<00:24,  5.88it/s]\u001b[A\n",
      " 30%|██▉       | 59/200 [00:05<00:20,  6.95it/s]\u001b[A\n",
      " 30%|███       | 61/200 [00:05<00:17,  8.01it/s]\u001b[A\n",
      " 32%|███▏      | 63/200 [00:05<00:15,  9.03it/s]\u001b[A\n",
      " 32%|███▎      | 65/200 [00:05<00:13,  9.93it/s]\u001b[A\n",
      " 34%|███▎      | 67/200 [00:06<00:12, 10.74it/s]\u001b[A\n",
      " 34%|███▍      | 69/200 [00:06<00:11, 11.30it/s]\u001b[A\n",
      " 36%|███▌      | 71/200 [00:06<00:10, 11.87it/s]\u001b[A\n",
      " 36%|███▋      | 73/200 [00:06<00:10, 12.19it/s]\u001b[A\n",
      " 38%|███▊      | 75/200 [00:06<00:10, 12.37it/s]\u001b[A\n",
      " 38%|███▊      | 77/200 [00:06<00:09, 12.53it/s]\u001b[A\n",
      " 40%|███▉      | 79/200 [00:07<00:09, 12.58it/s]\u001b[A\n",
      " 40%|████      | 81/200 [00:07<00:09, 12.68it/s]\u001b[A\n",
      " 42%|████▏     | 83/200 [00:07<00:09, 12.89it/s]\u001b[A\n",
      " 42%|████▎     | 85/200 [00:07<00:08, 12.87it/s]\u001b[A\n",
      " 44%|████▎     | 87/200 [00:07<00:08, 12.95it/s]\u001b[A\n",
      " 44%|████▍     | 89/200 [00:07<00:08, 13.07it/s]\u001b[A\n",
      " 46%|████▌     | 91/200 [00:08<00:10, 10.07it/s]\u001b[A\n",
      " 46%|████▋     | 93/200 [00:08<00:09, 10.92it/s]\u001b[A\n",
      " 48%|████▊     | 95/200 [00:08<00:08, 11.68it/s]\u001b[A\n",
      " 48%|████▊     | 97/200 [00:08<00:08, 12.19it/s]\u001b[A\n",
      " 50%|████▉     | 99/200 [00:08<00:08, 12.46it/s]\u001b[A\n",
      " 50%|█████     | 101/200 [00:08<00:07, 12.62it/s]\u001b[A\n",
      " 52%|█████▏    | 103/200 [00:09<00:07, 12.84it/s]\u001b[A\n",
      " 52%|█████▎    | 105/200 [00:09<00:07, 13.11it/s]\u001b[A\n",
      " 54%|█████▎    | 107/200 [00:09<00:06, 13.30it/s]\u001b[A\n",
      " 55%|█████▍    | 109/200 [00:09<00:06, 13.36it/s]\u001b[A\n",
      " 56%|█████▌    | 111/200 [00:09<00:06, 13.31it/s]\u001b[A\n",
      " 56%|█████▋    | 113/200 [00:09<00:06, 13.25it/s]\u001b[A\n",
      " 57%|█████▊    | 115/200 [00:09<00:06, 13.30it/s]\u001b[A\n",
      " 58%|█████▊    | 117/200 [00:10<00:06, 13.31it/s]\u001b[A\n",
      " 60%|█████▉    | 119/200 [00:10<00:06, 13.20it/s]\u001b[A\n",
      " 60%|██████    | 121/200 [00:10<00:05, 13.17it/s]\u001b[A\n",
      " 62%|██████▏   | 123/200 [00:10<00:05, 13.17it/s]\u001b[A\n",
      " 62%|██████▎   | 125/200 [00:10<00:05, 13.17it/s]\u001b[A\n",
      " 64%|██████▎   | 127/200 [00:10<00:05, 13.07it/s]\u001b[A\n",
      " 64%|██████▍   | 129/200 [00:10<00:05, 13.13it/s]\u001b[A\n",
      " 66%|██████▌   | 131/200 [00:11<00:07,  9.57it/s]\u001b[A\n",
      " 66%|██████▋   | 133/200 [00:11<00:06, 10.47it/s]\u001b[A\n",
      " 68%|██████▊   | 135/200 [00:11<00:05, 11.12it/s]\u001b[A\n",
      " 68%|██████▊   | 137/200 [00:11<00:05, 11.24it/s]\u001b[A\n",
      " 70%|██████▉   | 139/200 [00:11<00:05, 11.33it/s]\u001b[A\n",
      " 70%|███████   | 141/200 [00:12<00:05, 11.34it/s]\u001b[A\n",
      " 72%|███████▏  | 143/200 [00:12<00:04, 11.44it/s]\u001b[A\n",
      " 72%|███████▎  | 145/200 [00:12<00:04, 11.59it/s]\u001b[A\n",
      " 74%|███████▎  | 147/200 [00:12<00:04, 11.79it/s]\u001b[A\n",
      " 74%|███████▍  | 149/200 [00:12<00:04, 12.00it/s]\u001b[A\n",
      " 76%|███████▌  | 151/200 [00:12<00:04, 12.17it/s]\u001b[A\n",
      " 76%|███████▋  | 153/200 [00:13<00:03, 12.13it/s]\u001b[A\n",
      " 78%|███████▊  | 155/200 [00:13<00:03, 12.02it/s]\u001b[A\n",
      " 78%|███████▊  | 157/200 [00:13<00:03, 11.67it/s]\u001b[A\n",
      " 80%|███████▉  | 159/200 [00:13<00:03, 11.64it/s]\u001b[A\n",
      " 80%|████████  | 161/200 [00:13<00:03, 11.81it/s]\u001b[A\n",
      " 82%|████████▏ | 163/200 [00:13<00:03, 11.94it/s]\u001b[A\n",
      " 82%|████████▎ | 165/200 [00:14<00:02, 11.86it/s]\u001b[A\n",
      " 84%|████████▎ | 167/200 [00:14<00:02, 11.84it/s]\u001b[A\n",
      " 84%|████████▍ | 169/200 [00:14<00:02, 11.80it/s]\u001b[A\n",
      " 86%|████████▌ | 171/200 [00:14<00:02, 11.82it/s]\u001b[A\n",
      " 86%|████████▋ | 173/200 [00:14<00:02, 12.06it/s]\u001b[A\n",
      " 88%|████████▊ | 175/200 [00:14<00:02, 12.17it/s]\u001b[A\n",
      " 88%|████████▊ | 177/200 [00:15<00:01, 11.98it/s]\u001b[A\n",
      " 90%|████████▉ | 179/200 [00:15<00:01, 11.85it/s]\u001b[A\n",
      " 90%|█████████ | 181/200 [00:15<00:02,  7.99it/s]\u001b[A\n",
      " 92%|█████████▏| 183/200 [00:15<00:01,  8.85it/s]\u001b[A\n",
      " 92%|█████████▎| 185/200 [00:16<00:01,  9.52it/s]\u001b[A\n",
      " 94%|█████████▎| 187/200 [00:16<00:01, 10.06it/s]\u001b[A\n",
      " 94%|█████████▍| 189/200 [00:16<00:01, 10.63it/s]\u001b[A\n",
      " 96%|█████████▌| 191/200 [00:16<00:00, 11.11it/s]\u001b[A\n",
      " 96%|█████████▋| 193/200 [00:16<00:00, 11.11it/s]\u001b[A\n",
      " 98%|█████████▊| 195/200 [00:16<00:00, 11.14it/s]\u001b[A\n",
      " 98%|█████████▊| 197/200 [00:17<00:00, 11.08it/s]\u001b[A\n",
      "100%|█████████▉| 199/200 [00:17<00:00, 11.32it/s]\u001b[A\n",
      "100%|██████████| 200/200 [00:17<00:00, 11.49it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# PARAMS\n",
    "\n",
    "BATCH_SIZE=1000\n",
    "NUM_BACKWARDS=10000\n",
    "LEARNING_RATE=0.001\n",
    "\n",
    "###############\n",
    "\n",
    "loss_list=[]\n",
    "Emb=embedd().to(device)\n",
    "Emb.train()\n",
    "optimizer = Adam(Emb.parameters(),lr=LEARNING_RATE)\n",
    "\n",
    "for n in tqdm(range(NUM_BACKWARDS)):\n",
    "    \n",
    "    x,y_target=batch_maker(BATCH_SIZE)\n",
    "    x = x.to(device) #we put the model and the variable on the gpu\n",
    "    y=Emb(x)\n",
    "    y = y.to(device)\n",
    "    y_target = y_target.to(device) #because we use y_target after and we neet to put it on the gpu\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss_func=nn.CrossEntropyLoss()\n",
    "    loss1_target = (y_target[:,:n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    loss2_target = (y_target[:,n_alphabet:2*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    loss3_target = (y_target[:,2*n_alphabet:3*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    \n",
    "    loss4_target = (y_target[:,3*n_alphabet:4*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    loss5_target = (y_target[:,4*n_alphabet:5*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    loss6_target = (y_target[:,5*n_alphabet:6*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "\n",
    "    loss1=loss_func(y[:,:n_alphabet],loss1_target)\n",
    "    loss2=loss_func(y[:,n_alphabet:2*n_alphabet],loss2_target)\n",
    "    loss3=loss_func(y[:,2*n_alphabet:3*n_alphabet],loss3_target)\n",
    "    \n",
    "    loss4=loss_func(y[:,3*n_alphabet:4*n_alphabet],loss4_target)\n",
    "    loss5=loss_func(y[:,4*n_alphabet:5*n_alphabet],loss5_target)\n",
    "    loss6=loss_func(y[:,5*n_alphabet:6*n_alphabet],loss6_target)\n",
    "    \n",
    "    \n",
    "    loss=(loss1+loss2+loss3+loss4+loss5+loss6)/6\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_list.append(loss.item()) #All this to update the loss plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(loss_list)\n",
    "    fig.savefig(\"loss plot embedd bigbatch.png\")\n",
    "    plt.close(fig)\n",
    "    \n",
    "    if NUM_BACKWARDS%1000==0:\n",
    "        torch.save(Emb.state_dict(),\"Model.h5\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "66c8db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_output(Model, word):\n",
    "\n",
    "    rev_alphabet={0:'_', 1:'a', 2:'b', 3:'c', 4:'d',5:'e',6:'f',7:'g',8:'h',9:'i',10:'j',11:'k',12:'l',\n",
    "                 13:'m',14:'n',15:'o',16:'p',17:'q',18:'r',19:'s',20:'t',21:'u',22:'v',23:'w',24:'x',\n",
    "                 25:'y',26:'z',27:'é',28:'è',29:'others'}\n",
    "\n",
    "    alphabet={\n",
    "            ' ':0,'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,\n",
    "            'o':15,'p':16,'q':17,'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26,'é':27,\n",
    "            'è':28}\n",
    "\n",
    "    possibilities=[        \n",
    "            ' ','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x',\n",
    "            'y','z','é','è',]\n",
    "\n",
    "    inp=np.zeros((1,3*n_alphabet))\n",
    "    for letter_ind in range(3):\n",
    "        if word[letter_ind] in possibilities:\n",
    "            inp[0,letter_ind*n_alphabet+alphabet[word[letter_ind]]]=1\n",
    "        else:\n",
    "            inp[0,letter_ind*n_alphabet+29]=1\n",
    "\n",
    "    inp=torch.tensor(inp, requires_grad=True).float()\n",
    "    y=Model(inp.to(device))\n",
    "    y = y.cpu()\n",
    "\n",
    "    y00=np.argmax(y[:,:n_alphabet].detach().numpy())\n",
    "    y01=np.argmax(y[:,n_alphabet:2*n_alphabet].detach().numpy())\n",
    "    y02=np.argmax(y[:,2*n_alphabet:3*n_alphabet].detach().numpy())\n",
    "    y10=np.argmax(y[:,3*n_alphabet:4*n_alphabet].detach().numpy())\n",
    "    y11=np.argmax(y[:,4*n_alphabet:5*n_alphabet].detach().numpy())\n",
    "    y12=np.argmax(y[:,5*n_alphabet:6*n_alphabet].detach().numpy())\n",
    "\n",
    "    before=rev_alphabet[y00]+rev_alphabet[y01]+rev_alphabet[y02]\n",
    "    after=rev_alphabet[y10]+rev_alphabet[y11]+rev_alphabet[y12]\n",
    "\n",
    "    return before, after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "fccddd34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('___', '___')"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Emb = embedd()\n",
    "#Emb.load_state_dict(torch.load(\"C:/Users/feoni/OneDrive/Bureau/Polytechnique/ML/DeepLearning_Project/Model.h5\"))\n",
    "#Emb.eval()\n",
    "\n",
    "find_output(Emb, \"cro\")\n",
    "#Encoder avec plus de perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "e1c57efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_encoded(df, line):\n",
    "    \n",
    "    cut=cutter(df[\"text\"][line],3)\n",
    "    length=cut.shape[0]\n",
    "    X=np.zeros((length,3*n_alphabet))\n",
    "    \n",
    "    alphabet={\n",
    "        ' ':0,'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,\n",
    "        'o':15,'p':16,'q':17,'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26,'é':27,\n",
    "        'è':28,\n",
    "        #thus use mod 30 (as 29 is for any other letter (arabic...))\n",
    "        }\n",
    "        \n",
    "    possibilities=[        \n",
    "        ' ','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x',\n",
    "        'y','z','é','è',]\n",
    "\n",
    "    for word_index in range(length):\n",
    "\n",
    "        word=cut[word_index,1]\n",
    "        inp=np.zeros(3*n_alphabet)\n",
    "\n",
    "        for letter_ind in range(3):\n",
    "            \n",
    "            index=0\n",
    "\n",
    "            if (word[letter_ind] not in possibilities):\n",
    "                index0=29\n",
    "            else:\n",
    "                index0=alphabet[word[letter_ind]]\n",
    "                \n",
    "\n",
    "            X[word_index,letter_ind*n_alphabet+index0]=1\n",
    "\n",
    "        \n",
    "    return Emb.encoder(torch.tensor(X, requires_grad=True).float().to(device))#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "1e774a1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5600, 0.5461, 0.6060, 0.5695, 0.5568, 0.5708, 0.5752, 0.6030, 0.5762,\n",
       "         0.5851, 0.5746, 0.5948, 0.6133, 0.5636, 0.5733, 0.5460, 0.5610, 0.6189,\n",
       "         0.5791, 0.6038, 0.5400, 0.4748, 0.6020, 0.5606, 0.6042, 0.5691, 0.5882,\n",
       "         0.4503, 0.6204, 0.6031, 0.5650, 0.5130, 0.6157, 0.6192, 0.5157, 0.5668,\n",
       "         0.5241, 0.5676, 0.5889, 0.5817, 0.6135, 0.5543, 0.4993, 0.5028, 0.5468],\n",
       "        [0.7478, 0.5982, 0.7229, 0.7135, 0.7089, 0.6854, 0.6841, 0.7047, 0.7108,\n",
       "         0.7161, 0.7559, 0.7455, 0.7823, 0.6544, 0.6023, 0.7513, 0.6075, 0.8137,\n",
       "         0.6579, 0.7679, 0.5015, 0.6150, 0.6448, 0.6846, 0.6652, 0.6913, 0.7548,\n",
       "         0.5739, 0.8074, 0.7901, 0.7386, 0.4884, 0.7597, 0.7312, 0.6066, 0.7601,\n",
       "         0.6970, 0.6994, 0.7451, 0.6524, 0.7288, 0.5712, 0.4973, 0.4317, 0.7228],\n",
       "        [0.7664, 0.6213, 0.7656, 0.7592, 0.7195, 0.7224, 0.7338, 0.7075, 0.7595,\n",
       "         0.7780, 0.7941, 0.7469, 0.8152, 0.7177, 0.6592, 0.7643, 0.5889, 0.7992,\n",
       "         0.7051, 0.7712, 0.5624, 0.6601, 0.7500, 0.7477, 0.7138, 0.7132, 0.7800,\n",
       "         0.5490, 0.8445, 0.8154, 0.7508, 0.5022, 0.8107, 0.7949, 0.5650, 0.8001,\n",
       "         0.6625, 0.7398, 0.7466, 0.6976, 0.7782, 0.6082, 0.5499, 0.4463, 0.6835],\n",
       "        [0.5030, 0.4714, 0.5345, 0.5373, 0.5187, 0.5431, 0.5441, 0.5261, 0.5219,\n",
       "         0.5415, 0.5404, 0.4844, 0.4973, 0.5123, 0.5586, 0.4697, 0.4721, 0.5226,\n",
       "         0.5608, 0.5497, 0.4929, 0.4856, 0.5192, 0.5474, 0.5427, 0.4996, 0.5588,\n",
       "         0.4418, 0.5266, 0.5216, 0.5338, 0.5417, 0.5452, 0.5436, 0.4513, 0.5013,\n",
       "         0.4977, 0.5044, 0.5554, 0.5444, 0.5470, 0.5079, 0.4675, 0.4636, 0.5159],\n",
       "        [0.4513, 0.4700, 0.4709, 0.4798, 0.5032, 0.5004, 0.4947, 0.4985, 0.5014,\n",
       "         0.5122, 0.5144, 0.4455, 0.4767, 0.5180, 0.5518, 0.4638, 0.5323, 0.4872,\n",
       "         0.5570, 0.4762, 0.5029, 0.4361, 0.5051, 0.5197, 0.5367, 0.5330, 0.5039,\n",
       "         0.4138, 0.5312, 0.5112, 0.4698, 0.5109, 0.5207, 0.5014, 0.4394, 0.4661,\n",
       "         0.4509, 0.5362, 0.4970, 0.4941, 0.5402, 0.5177, 0.4706, 0.5439, 0.4954],\n",
       "        [0.5416, 0.4933, 0.5280, 0.5198, 0.5332, 0.5150, 0.5201, 0.5417, 0.5285,\n",
       "         0.5310, 0.5598, 0.5101, 0.5234, 0.5323, 0.5419, 0.5026, 0.5273, 0.5585,\n",
       "         0.5428, 0.5247, 0.5134, 0.4292, 0.5590, 0.5468, 0.5513, 0.5367, 0.5408,\n",
       "         0.4250, 0.5759, 0.5672, 0.5102, 0.4815, 0.5628, 0.5320, 0.4387, 0.5179,\n",
       "         0.4856, 0.5598, 0.5403, 0.5291, 0.5823, 0.5156, 0.4848, 0.5295, 0.5284],\n",
       "        [0.6930, 0.5792, 0.6662, 0.6821, 0.6736, 0.6529, 0.6498, 0.6373, 0.6693,\n",
       "         0.6777, 0.7073, 0.6633, 0.7246, 0.6530, 0.5932, 0.6911, 0.5289, 0.7233,\n",
       "         0.6258, 0.6890, 0.5135, 0.5852, 0.6073, 0.6740, 0.6606, 0.6377, 0.7070,\n",
       "         0.5195, 0.7483, 0.7347, 0.6576, 0.4983, 0.7214, 0.6960, 0.5240, 0.6961,\n",
       "         0.6306, 0.6356, 0.7273, 0.6145, 0.6827, 0.5663, 0.4900, 0.4439, 0.6029],\n",
       "        [0.5822, 0.5035, 0.6190, 0.6111, 0.5699, 0.5704, 0.5942, 0.6122, 0.5968,\n",
       "         0.6327, 0.6200, 0.6125, 0.6016, 0.5701, 0.5778, 0.5633, 0.5454, 0.6185,\n",
       "         0.5984, 0.6212, 0.5542, 0.5163, 0.6395, 0.5631, 0.5975, 0.5628, 0.6510,\n",
       "         0.4700, 0.6111, 0.6190, 0.5834, 0.5266, 0.6511, 0.6125, 0.5108, 0.6101,\n",
       "         0.5236, 0.5832, 0.6047, 0.5858, 0.6283, 0.5593, 0.5096, 0.4674, 0.5701],\n",
       "        [0.7097, 0.5761, 0.7013, 0.6907, 0.6786, 0.6574, 0.6630, 0.6430, 0.6708,\n",
       "         0.6942, 0.7203, 0.6960, 0.7365, 0.6287, 0.6024, 0.7018, 0.5672, 0.7577,\n",
       "         0.6459, 0.7179, 0.5189, 0.6130, 0.6100, 0.6767, 0.6586, 0.6471, 0.7169,\n",
       "         0.5774, 0.7599, 0.7460, 0.6979, 0.5206, 0.7302, 0.6812, 0.5960, 0.7153,\n",
       "         0.6674, 0.6580, 0.7214, 0.6362, 0.6926, 0.5562, 0.4952, 0.4280, 0.6423],\n",
       "        [0.6407, 0.5310, 0.6764, 0.6735, 0.6310, 0.5953, 0.6328, 0.6424, 0.6312,\n",
       "         0.6589, 0.6874, 0.6464, 0.6588, 0.6141, 0.5799, 0.6301, 0.5292, 0.6488,\n",
       "         0.6379, 0.6744, 0.5184, 0.5759, 0.6615, 0.6377, 0.6595, 0.6068, 0.6843,\n",
       "         0.5008, 0.6696, 0.6737, 0.6211, 0.5099, 0.7088, 0.6625, 0.5271, 0.6786,\n",
       "         0.5476, 0.6284, 0.6485, 0.6321, 0.6663, 0.5777, 0.5434, 0.4655, 0.5853],\n",
       "        [0.6496, 0.5485, 0.6152, 0.6356, 0.6421, 0.6082, 0.6274, 0.6042, 0.6185,\n",
       "         0.6351, 0.6889, 0.6210, 0.6703, 0.5982, 0.6026, 0.6628, 0.5698, 0.6949,\n",
       "         0.6264, 0.6734, 0.4873, 0.5672, 0.6029, 0.6539, 0.6408, 0.6236, 0.6485,\n",
       "         0.5127, 0.7071, 0.6882, 0.6205, 0.4837, 0.6570, 0.6349, 0.5254, 0.6742,\n",
       "         0.5914, 0.6190, 0.6600, 0.5881, 0.6762, 0.5470, 0.5162, 0.4503, 0.5970],\n",
       "        [0.4821, 0.4528, 0.4962, 0.5151, 0.4974, 0.4861, 0.5150, 0.5090, 0.4984,\n",
       "         0.5147, 0.5140, 0.4583, 0.4649, 0.5092, 0.5405, 0.4771, 0.4841, 0.4922,\n",
       "         0.5319, 0.5065, 0.4784, 0.4470, 0.4847, 0.5320, 0.5216, 0.4946, 0.5175,\n",
       "         0.4487, 0.5208, 0.5085, 0.4655, 0.5190, 0.5128, 0.5023, 0.4452, 0.4607,\n",
       "         0.4862, 0.5127, 0.5133, 0.4973, 0.5158, 0.4922, 0.4467, 0.4909, 0.4836],\n",
       "        [0.4524, 0.4540, 0.4644, 0.4571, 0.5288, 0.4987, 0.4794, 0.4801, 0.4958,\n",
       "         0.4906, 0.5104, 0.4383, 0.4541, 0.5147, 0.5417, 0.4430, 0.5323, 0.4807,\n",
       "         0.5589, 0.4573, 0.4960, 0.4163, 0.4631, 0.5149, 0.5250, 0.5194, 0.5026,\n",
       "         0.4273, 0.5236, 0.5040, 0.4654, 0.4911, 0.5241, 0.5074, 0.4301, 0.4781,\n",
       "         0.4460, 0.5342, 0.4955, 0.4738, 0.5412, 0.4788, 0.4485, 0.5467, 0.4877],\n",
       "        [0.5648, 0.5468, 0.6125, 0.6068, 0.5602, 0.5883, 0.5797, 0.6094, 0.6029,\n",
       "         0.6030, 0.6240, 0.6021, 0.6432, 0.6043, 0.5887, 0.5836, 0.5750, 0.6684,\n",
       "         0.5949, 0.6310, 0.5199, 0.5033, 0.6379, 0.6030, 0.6188, 0.6105, 0.6118,\n",
       "         0.4432, 0.6513, 0.6480, 0.6037, 0.4873, 0.6330, 0.6352, 0.4975, 0.6155,\n",
       "         0.5242, 0.6101, 0.5947, 0.6154, 0.6619, 0.5521, 0.5187, 0.5064, 0.5559],\n",
       "        [0.6971, 0.5592, 0.6588, 0.7175, 0.6453, 0.6558, 0.6837, 0.6227, 0.6742,\n",
       "         0.6670, 0.6921, 0.6819, 0.7313, 0.6388, 0.5555, 0.6889, 0.5209, 0.7204,\n",
       "         0.6141, 0.7214, 0.5042, 0.6278, 0.5986, 0.6614, 0.6837, 0.6719, 0.6897,\n",
       "         0.5089, 0.7625, 0.7478, 0.6556, 0.5276, 0.6975, 0.6951, 0.5319, 0.7078,\n",
       "         0.6384, 0.6093, 0.6999, 0.6252, 0.6964, 0.5610, 0.5090, 0.4390, 0.6096],\n",
       "        [0.5722, 0.5305, 0.5965, 0.6018, 0.5713, 0.5619, 0.5720, 0.5603, 0.5980,\n",
       "         0.5929, 0.5802, 0.5289, 0.5839, 0.5928, 0.5611, 0.5475, 0.4877, 0.5864,\n",
       "         0.5811, 0.5881, 0.5367, 0.5136, 0.5473, 0.6179, 0.5983, 0.5552, 0.6135,\n",
       "         0.4792, 0.6245, 0.6085, 0.5531, 0.5377, 0.6297, 0.5906, 0.4899, 0.5363,\n",
       "         0.5451, 0.5607, 0.5950, 0.5533, 0.5982, 0.5408, 0.4961, 0.4906, 0.5363],\n",
       "        [0.6051, 0.5314, 0.6422, 0.6503, 0.6328, 0.5983, 0.6068, 0.6012, 0.6424,\n",
       "         0.6356, 0.6642, 0.6285, 0.6408, 0.5974, 0.5863, 0.5822, 0.5280, 0.6451,\n",
       "         0.6458, 0.6489, 0.5390, 0.5689, 0.6143, 0.6237, 0.6500, 0.6016, 0.6810,\n",
       "         0.4889, 0.6521, 0.6442, 0.6154, 0.5118, 0.6769, 0.6459, 0.5163, 0.6478,\n",
       "         0.5534, 0.6200, 0.6463, 0.6024, 0.6456, 0.5521, 0.5249, 0.4805, 0.5846],\n",
       "        [0.6457, 0.5342, 0.6211, 0.6217, 0.6182, 0.6191, 0.6165, 0.6134, 0.6109,\n",
       "         0.6367, 0.6673, 0.6285, 0.6651, 0.5934, 0.5807, 0.6310, 0.5491, 0.6905,\n",
       "         0.6206, 0.6546, 0.5205, 0.5572, 0.5692, 0.6354, 0.5950, 0.6320, 0.6649,\n",
       "         0.5362, 0.6746, 0.6667, 0.6242, 0.5053, 0.6802, 0.6147, 0.5498, 0.6442,\n",
       "         0.5963, 0.6108, 0.6647, 0.5881, 0.6373, 0.5280, 0.4989, 0.4473, 0.6028],\n",
       "        [0.5178, 0.4780, 0.5334, 0.5518, 0.5196, 0.5286, 0.5320, 0.5315, 0.5163,\n",
       "         0.5408, 0.5393, 0.4867, 0.5156, 0.5421, 0.5423, 0.4931, 0.4856, 0.5292,\n",
       "         0.5411, 0.5619, 0.4927, 0.4683, 0.5051, 0.5534, 0.5439, 0.5204, 0.5727,\n",
       "         0.4468, 0.5329, 0.5411, 0.4976, 0.5306, 0.5640, 0.5546, 0.4606, 0.5030,\n",
       "         0.5021, 0.5021, 0.5612, 0.5301, 0.5435, 0.5223, 0.4784, 0.4563, 0.4991]],\n",
       "       grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_encoded(df, 2) #give the tensor of the complete embedded tweet (each 3 letter)\n",
    "\n",
    "#sentence_encoded(3).shape\n",
    "#30 for the alphabet size \n",
    "#the first argument is the tweet lenght"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8557b530",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">4. NN coupled with RNN to find the rt </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "c7ef932b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feelings=5 #return of RNN part\n",
    "n_mainstream=5+3 #followers, likes, verified... data that didn't get treated (no need) (after normalisation) +time\n",
    "n_PCA_words=4 #after PCA on words\n",
    "n_PCA_hashtag=3 #after PCA on hashtags\n",
    "\n",
    "final_dim=n_feelings+n_mainstream+n_PCA_words+n_PCA_hashtag\n",
    "final_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe1c976",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">4.1 RNN on embedded words: Understanding relations between words to extract a general opinion/feeling from the tweet</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "6999e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeelingsFinder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        #RNN layer (30 for the input word vectors and 5 for the feeling vector of previous run)\n",
    "        self.recurrNN=nn.RNN(45, n_feelings)\n",
    "        #30 is the input vector and n_feelings the output vector\n",
    "        self.lin=nn.Linear(n_feelings,n_feelings)\n",
    "        #the rnn output 2 vectors : 1 output \"normal\" and one for the repetition\n",
    "        #the two args need to have the same size because the layer is expected to receive a same size input \n",
    "        \n",
    "    def forward(self,x): #x is a matrix of vectorised sentence\n",
    "            \n",
    "        #initialize first feeling vector \n",
    "        h=torch.zeros(1,n_feelings).to(device)\n",
    "        \n",
    "        #feed forward (x of shape (number of patches of 3, 100))\n",
    "        for i in range(x.shape[0]):\n",
    "            #we dont have to pay attention to the \"h\", because the thing we return is the \"out\" after it passed through the linear layer\n",
    "            out, _ =self.recurrNN(x[i:i+1,:],h)\n",
    "            out=self.lin(out)\n",
    "            h=out\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "69794723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "ff = FeelingsFinder().to(device)\n",
    "ff\n",
    "\n",
    "dummy_input = torch.rand((40, 45)).to(device)\n",
    "dummy_input\n",
    "\n",
    "print(ff(dummy_input).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65be5e67",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">4.2 NN to find out rt: takes as input the output of RNN & all the treated dimensions above (2 PCAs, normalised mainstream dimensions...)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "cc576147",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RTFinder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.NN=nn.Sequential(\n",
    "        \n",
    "        nn.Linear(final_dim,10,bias=True),\n",
    "        nn.ReLU(True),\n",
    "            \n",
    "        nn.Linear(10,4,bias=True),\n",
    "        nn.ReLU(True),\n",
    "        \n",
    "        nn.Linear(4,1, bias=True),\n",
    "        nn.Sigmoid())\n",
    "        \n",
    "        self.feelings_finder = FeelingsFinder()\n",
    "        \n",
    "    def forward(self, x, y): #x is concatenatioon of all dimensions and y same as x in forward of FeelingsFinder\n",
    "        \n",
    "        feelings = self.feelings_finder(y)\n",
    "        \n",
    "        nn_input = torch.cat((x.T,feelings.T)).T\n",
    "        \n",
    "        print(nn_input.shape)\n",
    "        \n",
    "        return self.NN(nn_input)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "e2eed56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "tensor([[0.4938]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand((40, 45)).to(device)\n",
    "\n",
    "RT= RTFinder().to(device)\n",
    "\n",
    "dummy_input2 = torch.rand((1, 15)).to(device)\n",
    "dummy_input3 = torch.rand((1, 15)).to(device)\n",
    "\n",
    "#print(torch.cat((dummy_input2.T, dummy_input3.T)).T.shape)\n",
    "print(RT(dummy_input2, dummy_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "09a0fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_train(line):\n",
    "    concat_data=np.zeros((1, 15))\n",
    "    concat_data[0,0]=df[\"favorites_count\"][line]\n",
    "    concat_data[0,1]=df[\"followers_count\"][line]\n",
    "    concat_data[0,2]=df[\"friends_count\"][line]\n",
    "    concat_data[0,3]=df[\"statuses_count\"][line]\n",
    "    concat_data[0,4]=df[\"verified\"][line]\n",
    "    concat_data[0,5]=df[\"month\"][line]\n",
    "    concat_data[0,6]=df[\"day\"][line]\n",
    "    concat_data[0,7]=df[\"moment\"][line]\n",
    "    \n",
    "    #try to define the most important words so no need to redefine them later\n",
    "    \n",
    "    PCA_text=PCA_training(array_train_text,4)[0][line,:]\n",
    "    concat_data[0,8:12]=PCA_text\n",
    "    \n",
    "    PCA_hashtag=PCA_training(array_train_hashtags,3)[0][line,:]\n",
    "    concat_data[0,12:15]=PCA_hashtag\n",
    "    \n",
    "    return torch.tensor(concat_data).float(), sentence_encoded(df, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "ee192c86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  0.4480,  0.5473,  0.7705,  0.0000,  0.1818,  0.4667,  0.4844,\n",
       "          -0.2490, -0.1701,  0.1340,  0.3202,  0.1854,  0.0083,  0.0022]]),\n",
       " tensor([[0.5715, 0.5098, 0.6071,  ..., 0.5087, 0.4968, 0.5676],\n",
       "         [0.7420, 0.5958, 0.7090,  ..., 0.5340, 0.3961, 0.6228],\n",
       "         [0.6288, 0.5413, 0.6631,  ..., 0.5223, 0.4651, 0.5973],\n",
       "         ...,\n",
       "         [0.8181, 0.6645, 0.7960,  ..., 0.5315, 0.4258, 0.7035],\n",
       "         [0.6547, 0.5258, 0.7143,  ..., 0.5258, 0.4252, 0.5873],\n",
       "         [0.4709, 0.4603, 0.4783,  ..., 0.4548, 0.4964, 0.4990]],\n",
       "        grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acaef2c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/35000 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathieu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/Users/mathieu/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "\n",
      "  0%|          | 1/35000 [00:11<113:47:15, 11.70s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mathieu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n",
      "  0%|          | 2/35000 [00:21<109:04:32, 11.22s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 3/35000 [00:32<106:19:12, 10.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 4/35000 [00:43<106:49:36, 10.99s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 5/35000 [00:54<108:05:56, 11.12s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 6/35000 [01:05<106:13:07, 10.93s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 20])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "#Training loop (train for each line)\n",
    "\n",
    "RT=RTFinder().to(device)\n",
    "progressbar = tqdm(range(35000))\n",
    "loss=None\n",
    "loss_list=[]\n",
    "\n",
    "optimizer = Adam(RT.parameters(),lr=0.001)\n",
    "\n",
    "for line in progressbar:\n",
    "    if loss is None:\n",
    "        optimizer.zero_grad()\n",
    "    x0, x1 = data_to_train(line)\n",
    "    x0 = x0.to(device)\n",
    "    x1 = x1.to(device)\n",
    "    rt=RT(x0, x1)\n",
    "    rt_target=df[\"retweets_count\"][line]\n",
    "    rt_target = torch.tensor(rt_target).to(device)\n",
    "    loss_func=nn.MSELoss()\n",
    "    \n",
    "    if loss is None:\n",
    "        loss=loss_func(rt, torch.tensor(rt_target).float())\n",
    "    else:\n",
    "        loss+=loss_func(rt, torch.tensor(rt_target).float())\n",
    "    \n",
    "    if line%500==0 and line!=0:\n",
    "        line/=500\n",
    "        torch.save(Emb.state_dict(),\"Final_Network.h5\")\n",
    "        \n",
    "        loss_list.append(loss.item()) #All this to update the loss plot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(loss_list)\n",
    "        fig.savefig(\"loss plot.png\")\n",
    "        plt.close(fig)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Loss: {loss.item(): .6f}\")\n",
    "        #progressbar.set_description(f\"Loss: {loss.item(): .6f}\")\n",
    "        loss=None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79616f1b",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">5. Apply everything onto test dataset </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33963a77",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">5.1 Prepare test data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700562be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e672ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=Normaliser(df, df_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd8fc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_test(line):\n",
    "    concat_data=np.zeros((1,15))\n",
    "    concat_data[0,0]=df_test[\"favorites_count\"][line]\n",
    "    concat_data[0,1]=df_test[\"followers_count\"][line]\n",
    "    concat_data[0,2]=df_test[\"friends_count\"][line]\n",
    "    concat_data[0,3]=df_test[\"statuses_count\"][line]\n",
    "    concat_data[0,4]=df_test[\"verified\"][line]\n",
    "    concat_data[0,5]=df_test[\"month\"][line]\n",
    "    concat_data[0,6]=df_test[\"day\"][line]\n",
    "    concat_data[0,7]=df_test[\"moment\"][line]\n",
    "    \n",
    "    PCA_text=PCA_test(array_train_text,array_test_text,4)[line,:]\n",
    "    concat_data[0,8:12]=PCA_text\n",
    "    \n",
    "    PCA_hashtag=PCA_test(array_train_hashtags,array_test_hashtags,3)[line,:]\n",
    "    concat_data[0,12:15]=PCA_hashtag\n",
    "    \n",
    "    return torch.tensor(concat_data).float(), sentence_encoded(df_test, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7284d0a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_to_test(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259e60a6",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">5.2 Predict on the test data</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dcf9f1",
   "metadata": {},
   "source": [
    "Loss function : Mean Absolute Error (MAE) ->\n",
    "The MAE metric is calculated by dividing the sum of absolute differences between the predicted\n",
    "number of retweets (pi) and the observed number of retweets (ai) by the number of observations\n",
    "(N), i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7064857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, predictions):\n",
    "    y_true, predictions = np.array(y_true), np.array(predictions)\n",
    "    return np.mean(np.abs(y_true - predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8a001d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval=mae(Y,predictions)\n",
    "print(eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
