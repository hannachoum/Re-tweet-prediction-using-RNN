{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tqdm import tqdm\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">1. Preprocessing </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style=\"color:indigo\"> 1.1 Dataset observation </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lecture du fichier .csv par la libraire Pandas\n",
    "data=pd.read_csv('train.csv')\n",
    "df=data.copy()\n",
    "df_test=pd.read_csv('evaluation.csv')\n",
    "\n",
    "#We need to separate X and Y\n",
    "#X=data.loc[:,data.columns!=\"retweets_count\"]\n",
    "#Y=data['retweets_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353969,)\n",
      "6 54 6.9\n"
     ]
    }
   ],
   "source": [
    "timestamp=df[\"timestamp\"][0]/1000\n",
    "print(np.array(df[\"timestamp\"]).shape)\n",
    "date=dt.fromtimestamp(timestamp)\n",
    "print(date.hour, date.minute, date.hour+date.minute/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">1.2 Features explanations </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.quantile(0.99) #We check if there is a lot ludicrous values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#If our dataset contains empty values, we put the mean value of the collum\n",
    "if df.isnull().sum().sum()!=0: \n",
    "    imputer=SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "else: \n",
    "    print(\"No missing_values in this dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "corr_matrix = df.corr()\n",
    "plt.figure(figsize=(28,24))\n",
    "sns.heatmap(data = corr_matrix,cmap='BrBG', annot=True, linewidths=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ------> We observe that the only strong correlation that we can see at this time is the one between [favorite_count] \n",
    "and [retweet_count] , so we can already say that to predict the number of retweet, the number of favorite count is very important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#checking for missing values in output\n",
    "for i in range(df.shape[0]):\n",
    "    if df['retweets_count'][i]==[]:\n",
    "        print(df['retweets_count'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">1.3 Normalisations </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On doit normaliser les données mais chaque colonne doit être normalisé différemment. \n",
    "- \"favorites_count\" -> moins de 1% de valeurs abhérantes (au top)\n",
    "- \"followers_count\", -> Exponential \n",
    "- \"statutes_count\",\n",
    "- \"friends_count\" -> moins de 1% de valeurs abhérantes (au top)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization.quantile(0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_into_df(df):\n",
    "    result=pd.DataFrame(df,columns=[\"month\", \"day\", \"moment\"])\n",
    "    timestamps=np.array(df[\"timestamp\"])\n",
    "    \n",
    "    for i in range(timestamps.shape[0]):\n",
    "        date=dt.fromtimestamp(timestamps[i]/1000)\n",
    "        result[\"month\"][i]=date.month\n",
    "        result[\"day\"][i]=date.day\n",
    "        result[\"moment\"][i]=date.hour+date.minute/60\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myfunc(x):\n",
    "     return np.log(1+x)\n",
    "\n",
    "def Normaliser(df, df_test):\n",
    "    \n",
    "    column_names=[\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\"]\n",
    "    \n",
    "    #Create DFs and apply log to them\n",
    "    \n",
    "    Norm_train=pd.DataFrame(df,columns=[\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\"])\n",
    "    Norm_train['favorites_count'] = Norm_train['favorites_count'].transform(myfunc)\n",
    "    Norm_train['followers_count'] = Norm_train['followers_count'].transform(myfunc)\n",
    "    Norm_train['friends_count'] = Norm_train['friends_count'].transform(myfunc)\n",
    "    Norm_train['statuses_count'] = Norm_train['statuses_count'].transform(myfunc)\n",
    "    \n",
    "    Norm_rt=pd.DataFrame(df,columns=[\"retweets_count\"])\n",
    "    Norm_rt['retweets_count'] = Norm_rt['retweets_count'].transform(myfunc)\n",
    "    \n",
    "    Norm_test=pd.DataFrame(df_test,columns=[\"favorites_count\",\"followers_count\",\"statuses_count\",\"friends_count\"])\n",
    "    Norm_test['favorites_count'] = Norm_test['favorites_count'].transform(myfunc)\n",
    "    Norm_test['followers_count'] = Norm_test['followers_count'].transform(myfunc)\n",
    "    Norm_test['friends_count'] = Norm_test['friends_count'].transform(myfunc)\n",
    "    Norm_test['statuses_count'] = Norm_test['statuses_count'].transform(myfunc)\n",
    "    \n",
    "    #Also add time\n",
    "    \n",
    "    Time_train=get_time_into_df(df)\n",
    "    Time_test=get_time_into_df(df_test)\n",
    "    \n",
    "    #Now rescale with min-max\n",
    "    \n",
    "    scaler_train=MinMaxScaler()\n",
    "    scaler_train.fit(Norm_train)\n",
    "    norm_train=scaler_train.transform(Norm_train)\n",
    "    norm_test=scaler_train.transform(Norm_test)\n",
    "    \n",
    "    scaler_rt=MinMaxScaler()\n",
    "    scaler_rt.fit(Norm_rt)\n",
    "    norm_rt=scaler_rt.transform(Norm_rt)\n",
    "    \n",
    "    scaler_time=MinMaxScaler()\n",
    "    scaler_time.fit(Time_train)\n",
    "    norm_time_train=scaler_time.transform(Time_train)\n",
    "    norm_time_test=scaler_time.transform(Time_test)\n",
    "    \n",
    "    #Now put the rescaled results into the original DFs\n",
    "    \n",
    "    Norm_train=pd.DataFrame(norm_train,columns=column_names)\n",
    "    Norm_test=pd.DataFrame(norm_test,columns=column_names)\n",
    "    Norm_rt=pd.DataFrame(norm_rt,columns=[\"retweets_count\"])\n",
    "    \n",
    "    NormT_train=pd.DataFrame(norm_time_train,columns=[\"month\", \"day\", \"moment\"])\n",
    "    NormT_test=pd.DataFrame(norm_time_test,columns=[\"month\", \"day\", \"moment\"])\n",
    "    \n",
    "    df['favorites_count']=Norm_train['favorites_count']\n",
    "    df['followers_count']=Norm_train['followers_count'] \n",
    "    df['statuses_count']=Norm_train['statuses_count']\n",
    "    df['friends_count']=Norm_train['friends_count']\n",
    "    df['retweets_count']=Norm_rt['retweets_count']\n",
    "    \n",
    "    df_test['favorites_count']=Norm_test['favorites_count']\n",
    "    df_test['followers_count']=Norm_test['followers_count'] \n",
    "    df_test['statuses_count']=Norm_test['statuses_count']\n",
    "    df_test['friends_count']=Norm_test['friends_count']\n",
    "    \n",
    "    df[\"month\"]=NormT_train[\"month\"]\n",
    "    df[\"day\"]=NormT_train[\"day\"]\n",
    "    df[\"moment\"]=NormT_train[\"moment\"]\n",
    "    \n",
    "    df_test[\"month\"]=NormT_test[\"month\"]\n",
    "    df_test[\"day\"]=NormT_test[\"day\"]\n",
    "    df_test[\"moment\"]=NormT_test[\"moment\"]\n",
    "\n",
    "    return df, df_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, df_test= Normaliser(df,df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">2. PCA Text and # treatment </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:indigo\">2.1 Preprocessing of hashtags and texts </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for hashtags\n",
    "\n",
    "def most_important_hashtags(df, criteria):\n",
    "    DICO2={} #DICO2 is for hashtags\n",
    "    I=df.shape[0]\n",
    "    for i in range(I):\n",
    "        sentence=df[\"hashtags\"][i][1:-1].replace(' ', '').split(',')\n",
    "        for word in sentence:\n",
    "            extracted_word=word[1:-1]\n",
    "            if extracted_word in DICO2:\n",
    "                DICO2[extracted_word]+=1\n",
    "            else:\n",
    "                DICO2[extracted_word]=1\n",
    "    most_occurr_DICO2={}\n",
    "    for word in DICO2:\n",
    "        if DICO2[word]>criteria :#and word!=''\n",
    "            most_occurr_DICO2[word]=0\n",
    "    \n",
    "    important_hashtags=list(most_occurr_DICO2.keys())\n",
    "    \n",
    "    measurer2={}\n",
    "    for i in range(len(important_hashtags)):\n",
    "        measurer2[important_hashtags[i]]=i\n",
    "    measurer2\n",
    "    return important_hashtags, measurer2\n",
    "\n",
    "def make_array_training_hashtags(df, criteria):\n",
    "    possibilities, measurer=most_important_hashtags(df, criteria)\n",
    "    result=np.zeros((df.shape[0], len(possibilities)))\n",
    "    for line in range(df.shape[0]):\n",
    "        sentence=df[\"hashtags\"][line][1:-1].replace(' ', '').split(',')\n",
    "        for word in sentence:\n",
    "            extracted_word=word[1:-1]\n",
    "            if extracted_word in possibilities:\n",
    "                result[line,measurer[extracted_word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "def make_array_test_hashtags(df_test, criteria):\n",
    "    possibilities, measurer=most_important_hashtags(df, criteria)\n",
    "    result=np.zeros((df_test.shape[0], len(possibilities)))\n",
    "    for line in range(df_test.shape[0]):\n",
    "        sentence=df_test[\"hashtags\"][line][1:-1].replace(' ', '').split(',')\n",
    "        for word in sentence:\n",
    "            extracted_word=word[1:-1]\n",
    "            if extracted_word in possibilities:\n",
    "                result[line,measurer[extracted_word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "array_train_hashtags=make_array_training_hashtags(df,10)\n",
    "array_test_hashtags=make_array_test_hashtags(df_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for texts\n",
    "\n",
    "def most_important_words(df, criteria):\n",
    "    DICO={}\n",
    "    I=df.shape[0]\n",
    "    for i in range(I):\n",
    "        sentence=df[\"text\"][i].split()\n",
    "        for word in sentence:\n",
    "            if word in DICO:\n",
    "                DICO[word]+=1\n",
    "            else:\n",
    "                DICO[word]=1\n",
    "            \n",
    "    most_occurr_DICO={}\n",
    "    for word in DICO:\n",
    "        if DICO[word]>criteria:\n",
    "            most_occurr_DICO[word]=0\n",
    "    \n",
    "    important_words=list(most_occurr_DICO.keys())\n",
    "    measurer={}\n",
    "    for i in range(len(important_words)):\n",
    "        measurer[important_words[i]]=i\n",
    "    measurer\n",
    "    \n",
    "    return important_words, measurer\n",
    "\n",
    "def make_array_training_words(df, criteria):\n",
    "    possibilities, measurer=most_important_words(df, criteria)\n",
    "    result=np.zeros((df.shape[0], len(possibilities)))\n",
    "    for line in range(df.shape[0]):\n",
    "        sentence=df[\"text\"][line].split()\n",
    "        for word in sentence:\n",
    "            if word in possibilities:\n",
    "                result[line,measurer[word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "def make_array_test_words(df_test, criteria):\n",
    "    possibilities, measurer=most_important_words(df, criteria)\n",
    "    result=np.zeros((df_test.shape[0], len(possibilities)))\n",
    "    for line in range(df_test.shape[0]):\n",
    "        sentence=df_test[\"text\"][line].split()\n",
    "        for word in sentence:\n",
    "            if word in possibilities:\n",
    "                result[line,measurer[word]]=1\n",
    "                \n",
    "    return result\n",
    "\n",
    "array_train_text=make_array_training_words(df,5000)\n",
    "array_test_text=make_array_test_words(df_test, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "## <span style=\"color:indigo\">2.2 PCA on words and hashtags: Understanding the main components of bags of words </span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_training(array, n_comp):\n",
    "    n=array.shape[1]\n",
    "    for col in range(n):\n",
    "        mean=np.mean(array[:,col])\n",
    "        array[:,col]-=mean\n",
    "            \n",
    "    C=np.matmul(array.T,array)\n",
    "    C/=array.shape[1]\n",
    "    \n",
    "    Lambda, Q=np.linalg.eigh(C)\n",
    "\n",
    "    Qk=np.zeros((n,n_comp))\n",
    "    for col in range(n_comp):\n",
    "        Qk[:,col]=Q[:,n-col-1]\n",
    "    return np.matmul(array,Qk), Qk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_test(training_array, test_array, n_comp):\n",
    "    return np.matmul(test_array,PCA_training(training_array,n_comp)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">3. Preparing RNN on word sequences: Understanding relations between words </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:indigo\"> 3.1 Pre-treatment for word embedding </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the FastText method. We divide each word into groups of 3 letters (spaces are the \"empty letter\"). We keep the order in the text and make an embedding also using the adjacent words. For instance:\n",
    "\"macron demission\"==> -ma,mac,acr,...,on-,n-d,-de,dem,... (- is the empty letter)\n",
    "\n",
    "The fast text method will guess the adjacent 3 letters to each given patch of 3 letters. Hence for \"mac\" we want a high probability of \"---\" (3 times empty letter) and \"ron\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "  device = \"cuda:0\" \n",
    "else:  \n",
    "  device = \"cpu\"  \n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns an array with the words in the sentence cut (n=3 that is in pieces of 3)\n",
    "\n",
    "def cutter(sent, n):\n",
    "    sentence=sent.split()\n",
    "    length=len(sentence)+2-n\n",
    "    for word in sentence:\n",
    "        length+=len(word)\n",
    "    result=[]\n",
    "    padding=''\n",
    "    for i in range(n):\n",
    "        padding+=' '\n",
    "    sent=' '+sent+' '\n",
    "    padd_sent=padding+sent+padding\n",
    "    \n",
    "    for i in range(length):\n",
    "        middle=sent[i:i+n]\n",
    "        before=padd_sent[i:i+n]\n",
    "        after=padd_sent[2*n+i:3*n+i]\n",
    "        result.append([before, middle, after])\n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphabet=30\n",
    "\n",
    "def batch_maker(size):\n",
    "    X=np.zeros((size,3*n_alphabet))\n",
    "    Y=np.zeros((size,6*n_alphabet))\n",
    "    for i in range(size):\n",
    "        \n",
    "        line=random.randrange(0,350000)\n",
    "        cut=cutter(df[\"text\"][line],3)\n",
    "        \n",
    "        alphabet={\n",
    "        ' ':0,'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,\n",
    "        'o':15,'p':16,'q':17,'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26,'é':27,\n",
    "        'è':28,\n",
    "        #thus use mod 30 (as 29 is for any other letter (arabic...))\n",
    "        }\n",
    "        \n",
    "        possibilities=[        \n",
    "        ' ','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x',\n",
    "        'y','z','é','è',]\n",
    "        \n",
    "        length=cut.shape[0]\n",
    "        word_index=random.randrange(0,length)\n",
    "        \n",
    "        word0=cut[word_index, 0]\n",
    "        word1=cut[word_index, 1]\n",
    "        word2=cut[word_index, 2]\n",
    "        for letter_ind in range(3):\n",
    "            index0=0\n",
    "            index1=0\n",
    "            index2=0\n",
    "            if (word0[letter_ind] not in possibilities):\n",
    "                index0=29\n",
    "            else:\n",
    "                index0=alphabet[word0[letter_ind]]\n",
    "                \n",
    "            if (word1[letter_ind] not in possibilities):\n",
    "                index1=29\n",
    "            else:\n",
    "                index1=alphabet[word1[letter_ind]]\n",
    "                \n",
    "            if (word2[letter_ind] not in possibilities):\n",
    "                index2=29\n",
    "            else:\n",
    "                index2=alphabet[word2[letter_ind]]\n",
    "                \n",
    "            Y[i,letter_ind*n_alphabet+index0]=1\n",
    "            X[i,letter_ind*n_alphabet+index1]=1\n",
    "            Y[i,3*n_alphabet+letter_ind*n_alphabet+index2]=1\n",
    "        \n",
    "    return torch.tensor(X, requires_grad=True).float(),torch.tensor(Y, requires_grad=True).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 90])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_maker(100)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\"> 3.2 Encoder/decoder to mimic FastText</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model takes a \"word\" (3 letters patch) as input and return a size 100 vector who is encoded to take into consideration the past and future patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class embedd(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "        #A sequential container: Modules will be added to it in the order they are passed in the constructor. \n",
    "        self.encoder=nn.Sequential(\n",
    "            \n",
    "        nn.Linear(3*n_alphabet,70,bias=True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(70,45,bias=True),\n",
    "        nn.Sigmoid())\n",
    "        \n",
    "        self.decoder=nn.Sequential(\n",
    "        \n",
    "        nn.Linear(45,110, bias=True),\n",
    "        nn.ReLU(),\n",
    "        \n",
    "        nn.Linear(110,6*n_alphabet,bias=True),\n",
    "        )\n",
    "        \n",
    "        #The forward() method of Sequential accepts \n",
    "        #any input and forwards it to the first module it contains.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x=self.encoder(x)\n",
    "        x=self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-254-94fe1f8ef834>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss plot embedd bigbatch.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3056\u001b[0m                         ax.patch._cm_set(facecolor='none', edgecolor='none'))\n\u001b[1;32m   3057\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3058\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3060\u001b[0m     def ginput(self, n=1, timeout=30, show_clicks=True,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2323\u001b[0m                         \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2324\u001b[0m                         \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2325\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   2326\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2327\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[1;32m    413\u001b[0m                          \u001b[0;32melse\u001b[0m \u001b[0mdeprecation_addendum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                 **kwargs)\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mDECORATORS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[1;32m    541\u001b[0m         mpl.image.imsave(\n\u001b[1;32m    542\u001b[0m             \u001b[0mfilename_or_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"upper\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m             dpi=self.figure.dpi, metadata=metadata, pil_kwargs=pil_kwargs)\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprint_to_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1673\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0mpil_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dpi\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1675\u001b[0;31m         \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpil_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2352\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2353\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2355\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mopen_fp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk, save_all)\u001b[0m\n\u001b[1;32m   1395\u001b[0m         \u001b[0m_write_multiple_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1397\u001b[0;31m         \u001b[0mImageFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_idat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zip\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrawmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1399\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0m_encode_tile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"flush\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_encode_tile\u001b[0;34m(im, fp, tile, bufsize, fh, exc)\u001b[0m\n\u001b[1;32m    524\u001b[0m                     \u001b[0;31m# compress to Python file-compatible object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m                         \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m                         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# PARAMS\n",
    "\n",
    "BATCH_SIZE=100 #1000\n",
    "NUM_BACKWARDS=200\n",
    "LEARNING_RATE=0.001\n",
    "\n",
    "###############\n",
    "\n",
    "loss_list=[]\n",
    "Emb=embedd().to(device)\n",
    "Emb.train()\n",
    "optimizer = Adam(Emb.parameters(),lr=LEARNING_RATE)\n",
    "\n",
    "for n in range(NUM_BACKWARDS):\n",
    "    \n",
    "    print(n)\n",
    "    \n",
    "    x,y_target=batch_maker(BATCH_SIZE)\n",
    "    x = x.to(device) #we put the model and the variable on the gpu\n",
    "    y=Emb(x)\n",
    "    y = y.to(device)\n",
    "    y_target = y_target.to(device) #because we use y_target after and we neet to put it on the gpu\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss_func=nn.CrossEntropyLoss()\n",
    "    loss1_target = (y_target[:,:n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    loss2_target = (y_target[:,n_alphabet:2*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    loss3_target = (y_target[:,2*n_alphabet:3*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    \n",
    "    loss4_target = (y_target[:,3*n_alphabet:4*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    loss5_target = (y_target[:,4*n_alphabet:5*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "    loss6_target = (y_target[:,5*n_alphabet:6*n_alphabet] == 1).nonzero(as_tuple=True)[1]\n",
    "\n",
    "    loss1=loss_func(y[:,:n_alphabet],loss1_target)\n",
    "    loss2=loss_func(y[:,n_alphabet:2*n_alphabet],loss2_target)\n",
    "    loss3=loss_func(y[:,2*n_alphabet:3*n_alphabet],loss3_target)\n",
    "    \n",
    "    loss4=loss_func(y[:,3*n_alphabet:4*n_alphabet],loss4_target)\n",
    "    loss5=loss_func(y[:,4*n_alphabet:5*n_alphabet],loss5_target)\n",
    "    loss6=loss_func(y[:,5*n_alphabet:6*n_alphabet],loss6_target)\n",
    "    \n",
    "    \n",
    "    loss=(loss1+loss2+loss3+loss4+loss5+loss6)/6\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_list.append(loss.item()) #All this to update the loss plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(loss_list)\n",
    "    fig.savefig(\"loss plot embedd bigbatch.png\")\n",
    "    plt.close(fig)\n",
    "    \n",
    "    if NUM_BACKWARDS%1000==0:\n",
    "        torch.save(Emb.state_dict(),\"Model.h5\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_output(Model, word):\n",
    "\n",
    "    rev_alphabet={0:'_', 1:'a', 2:'b', 3:'c', 4:'d',5:'e',6:'f',7:'g',8:'h',9:'i',10:'j',11:'k',12:'l',\n",
    "                 13:'m',14:'n',15:'o',16:'p',17:'q',18:'r',19:'s',20:'t',21:'u',22:'v',23:'w',24:'x',\n",
    "                 25:'y',26:'z',27:'é',28:'è',29:'others'}\n",
    "\n",
    "    alphabet={\n",
    "            ' ':0,'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,\n",
    "            'o':15,'p':16,'q':17,'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26,'é':27,\n",
    "            'è':28}\n",
    "\n",
    "    possibilities=[        \n",
    "            ' ','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x',\n",
    "            'y','z','é','è',]\n",
    "\n",
    "    inp=np.zeros((1,3*n_alphabet))\n",
    "    for letter_ind in range(3):\n",
    "        if word[letter_ind] in possibilities:\n",
    "            inp[0,letter_ind*n_alphabet+alphabet[word[letter_ind]]]=1\n",
    "        else:\n",
    "            inp[0,letter_ind*n_alphabet+29]=1\n",
    "\n",
    "    inp=torch.tensor(inp, requires_grad=True).float()\n",
    "    y=Model(inp)\n",
    "\n",
    "    y00=np.argmax(y[:,:n_alphabet].detach().numpy())\n",
    "    y01=np.argmax(y[:,n_alphabet:2*n_alphabet].detach().numpy())\n",
    "    y02=np.argmax(y[:,2*n_alphabet:3*n_alphabet].detach().numpy())\n",
    "    y10=np.argmax(y[:,3*n_alphabet:4*n_alphabet].detach().numpy())\n",
    "    y11=np.argmax(y[:,4*n_alphabet:5*n_alphabet].detach().numpy())\n",
    "    y12=np.argmax(y[:,5*n_alphabet:6*n_alphabet].detach().numpy())\n",
    "\n",
    "    before=rev_alphabet[y00]+rev_alphabet[y01]+rev_alphabet[y02]\n",
    "    after=rev_alphabet[y10]+rev_alphabet[y11]+rev_alphabet[y12]\n",
    "\n",
    "    return before, after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('___', '___')"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Emb = embedd()\n",
    "#Emb.load_state_dict(torch.load(\"C:/Users/feoni/OneDrive/Bureau/Polytechnique/ML/DeepLearning_Project/Model.h5\"))\n",
    "#Emb.eval()\n",
    "\n",
    "find_output(Emb, \"cro\")\n",
    "#Encoder avec plus de perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "embedd(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=90, out_features=60, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=60, out_features=30, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=30, out_features=100, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=100, out_features=180, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emb.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7098, -0.1151, -0.9215,  ..., -0.7594, -3.2250, -2.5376],\n",
       "        [ 1.6185,  0.0096, -0.4346,  ...,  0.1514, -2.4077, -2.6949],\n",
       "        [ 2.4542, -0.6780, -1.0046,  ..., -0.5537, -2.7246, -3.5244],\n",
       "        ...,\n",
       "        [ 1.9367,  0.0643, -2.1337,  ..., -0.3473, -4.3823, -5.0206],\n",
       "        [ 2.5790,  0.5447, -0.3419,  ...,  0.3784, -4.6896, -2.1500],\n",
       "        [ 1.7655, -0.3340, -0.1127,  ..., -0.0254, -3.5908, -2.3545]],\n",
       "       device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Emb(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_encoded(df, line):\n",
    "    \n",
    "    cut=cutter(df[\"text\"][line],3)\n",
    "    length=cut.shape[0]\n",
    "    X=np.zeros((length,3*n_alphabet))\n",
    "    \n",
    "    alphabet={\n",
    "        ' ':0,'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,\n",
    "        'o':15,'p':16,'q':17,'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26,'é':27,\n",
    "        'è':28,\n",
    "        #thus use mod 30 (as 29 is for any other letter (arabic...))\n",
    "        }\n",
    "        \n",
    "    possibilities=[        \n",
    "        ' ','a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x',\n",
    "        'y','z','é','è',]\n",
    "\n",
    "    for word_index in range(length):\n",
    "\n",
    "        word=cut[word_index,1]\n",
    "        inp=np.zeros(3*n_alphabet)\n",
    "\n",
    "        for letter_ind in range(3):\n",
    "            \n",
    "            index=0\n",
    "\n",
    "            if (word[letter_ind] not in possibilities):\n",
    "                index0=29\n",
    "            else:\n",
    "                index0=alphabet[word[letter_ind]]\n",
    "                \n",
    "\n",
    "            X[word_index,letter_ind*n_alphabet+index0]=1\n",
    "\n",
    "        \n",
    "    return Emb.encoder(torch.tensor(X, requires_grad=True).float())#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6318, 0.5499, 0.6140, 0.5668, 0.5703, 0.6230, 0.4715, 0.4736, 0.5711,\n",
       "         0.6080, 0.4908, 0.5881, 0.6227, 0.6069, 0.5859, 0.5568, 0.4563, 0.5723,\n",
       "         0.5595, 0.5943, 0.5117, 0.5951, 0.5305, 0.5432, 0.5277, 0.4934, 0.5730,\n",
       "         0.5742, 0.5926, 0.5404],\n",
       "        [0.7790, 0.6595, 0.6985, 0.6642, 0.7030, 0.8029, 0.4665, 0.5161, 0.7502,\n",
       "         0.7799, 0.5283, 0.7193, 0.8062, 0.7084, 0.7215, 0.7494, 0.4128, 0.7229,\n",
       "         0.6588, 0.6919, 0.6458, 0.7514, 0.6553, 0.6331, 0.6818, 0.5810, 0.6707,\n",
       "         0.7456, 0.7571, 0.6523],\n",
       "        [0.7618, 0.6741, 0.7536, 0.7190, 0.6620, 0.7705, 0.4214, 0.5513, 0.7419,\n",
       "         0.7272, 0.4995, 0.7578, 0.7774, 0.7779, 0.7628, 0.6701, 0.5320, 0.7337,\n",
       "         0.7239, 0.7513, 0.7278, 0.7659, 0.6878, 0.6726, 0.7246, 0.6040, 0.6665,\n",
       "         0.7220, 0.7642, 0.6930],\n",
       "        [0.5970, 0.5698, 0.5946, 0.5441, 0.5342, 0.5829, 0.4845, 0.5170, 0.5186,\n",
       "         0.5908, 0.5200, 0.5487, 0.5267, 0.5678, 0.5658, 0.5607, 0.5010, 0.5163,\n",
       "         0.4923, 0.5584, 0.5054, 0.5592, 0.5009, 0.5464, 0.5103, 0.5299, 0.5159,\n",
       "         0.5668, 0.5655, 0.5146],\n",
       "        [0.5492, 0.5072, 0.5842, 0.5226, 0.5019, 0.5189, 0.4504, 0.4781, 0.4845,\n",
       "         0.5402, 0.5057, 0.5005, 0.5074, 0.5505, 0.5506, 0.4794, 0.5311, 0.4945,\n",
       "         0.4820, 0.5586, 0.4880, 0.5205, 0.4925, 0.4699, 0.4962, 0.4647, 0.4990,\n",
       "         0.5158, 0.5023, 0.4976],\n",
       "        [0.5874, 0.5346, 0.5963, 0.5279, 0.5307, 0.5947, 0.4552, 0.4904, 0.5509,\n",
       "         0.5826, 0.5041, 0.5640, 0.5651, 0.5698, 0.5552, 0.5252, 0.4663, 0.5233,\n",
       "         0.4975, 0.5875, 0.4966, 0.5810, 0.4936, 0.5167, 0.5252, 0.4924, 0.5223,\n",
       "         0.5545, 0.5481, 0.5370],\n",
       "        [0.6933, 0.6165, 0.6685, 0.6234, 0.6181, 0.7025, 0.4972, 0.5202, 0.6536,\n",
       "         0.6750, 0.5568, 0.6613, 0.7085, 0.6734, 0.6633, 0.6106, 0.4664, 0.6333,\n",
       "         0.5970, 0.6727, 0.5907, 0.6559, 0.5663, 0.6015, 0.6250, 0.5819, 0.6351,\n",
       "         0.6412, 0.6791, 0.5954],\n",
       "        [0.6557, 0.5980, 0.6488, 0.5757, 0.6206, 0.6469, 0.4568, 0.4786, 0.5866,\n",
       "         0.6394, 0.5030, 0.6364, 0.6573, 0.6329, 0.6218, 0.6091, 0.4849, 0.6041,\n",
       "         0.5984, 0.6144, 0.5590, 0.6175, 0.5820, 0.5576, 0.5725, 0.5122, 0.5760,\n",
       "         0.6306, 0.6438, 0.5743],\n",
       "        [0.7287, 0.6523, 0.6603, 0.6018, 0.6593, 0.7523, 0.4863, 0.5510, 0.6774,\n",
       "         0.7313, 0.5506, 0.6956, 0.7529, 0.6820, 0.6645, 0.6860, 0.4141, 0.6658,\n",
       "         0.6351, 0.6487, 0.6434, 0.7070, 0.6002, 0.6311, 0.6742, 0.5974, 0.6374,\n",
       "         0.7125, 0.6928, 0.6370],\n",
       "        [0.6784, 0.6363, 0.6842, 0.6330, 0.6151, 0.6874, 0.4725, 0.5246, 0.6556,\n",
       "         0.6823, 0.5323, 0.6483, 0.6737, 0.6665, 0.6824, 0.6200, 0.4833, 0.6539,\n",
       "         0.6232, 0.6653, 0.6380, 0.6938, 0.6031, 0.6258, 0.6337, 0.5534, 0.6233,\n",
       "         0.6667, 0.6552, 0.6326],\n",
       "        [0.6775, 0.6067, 0.6679, 0.6017, 0.5979, 0.7088, 0.4404, 0.5356, 0.6511,\n",
       "         0.6561, 0.5439, 0.6354, 0.6448, 0.7050, 0.6564, 0.6087, 0.4363, 0.6121,\n",
       "         0.5959, 0.6354, 0.5936, 0.6709, 0.5764, 0.6175, 0.6389, 0.5241, 0.5957,\n",
       "         0.6465, 0.6384, 0.6266],\n",
       "        [0.5390, 0.4962, 0.5812, 0.5129, 0.4979, 0.5103, 0.4488, 0.4755, 0.4716,\n",
       "         0.5295, 0.4952, 0.5079, 0.4937, 0.5361, 0.5395, 0.4738, 0.5457, 0.4852,\n",
       "         0.4679, 0.5551, 0.4809, 0.5182, 0.4869, 0.4728, 0.4800, 0.4628, 0.4862,\n",
       "         0.4967, 0.4998, 0.4931],\n",
       "        [0.5708, 0.5298, 0.5995, 0.5295, 0.5325, 0.5461, 0.4459, 0.4865, 0.5179,\n",
       "         0.5587, 0.5017, 0.5378, 0.5502, 0.5666, 0.5639, 0.5074, 0.5445, 0.5321,\n",
       "         0.4888, 0.5657, 0.5120, 0.5438, 0.5015, 0.4877, 0.5108, 0.4867, 0.5000,\n",
       "         0.5468, 0.5444, 0.5148],\n",
       "        [0.6544, 0.5911, 0.6696, 0.5818, 0.5839, 0.6419, 0.4748, 0.5015, 0.6086,\n",
       "         0.6484, 0.4754, 0.6399, 0.6472, 0.6609, 0.6179, 0.5704, 0.4781, 0.5954,\n",
       "         0.5942, 0.6144, 0.5502, 0.6149, 0.5752, 0.5550, 0.5551, 0.5185, 0.6026,\n",
       "         0.6025, 0.6500, 0.5800],\n",
       "        [0.7044, 0.6187, 0.6413, 0.6475, 0.6401, 0.7053, 0.4914, 0.5253, 0.6318,\n",
       "         0.6747, 0.5350, 0.6831, 0.7189, 0.7162, 0.6751, 0.6323, 0.4080, 0.6487,\n",
       "         0.6828, 0.6808, 0.6297, 0.6852, 0.6118, 0.6326, 0.6655, 0.5810, 0.6481,\n",
       "         0.6881, 0.6693, 0.6423],\n",
       "        [0.6138, 0.5661, 0.6541, 0.5697, 0.5756, 0.6355, 0.4680, 0.5128, 0.5563,\n",
       "         0.5942, 0.5231, 0.6165, 0.6244, 0.6522, 0.6406, 0.5602, 0.5183, 0.5946,\n",
       "         0.6061, 0.6565, 0.6042, 0.6285, 0.5439, 0.5791, 0.6049, 0.5475, 0.5663,\n",
       "         0.5941, 0.5768, 0.6091],\n",
       "        [0.6786, 0.6101, 0.6643, 0.5956, 0.6066, 0.6611, 0.4728, 0.5073, 0.6018,\n",
       "         0.6702, 0.5119, 0.6473, 0.6835, 0.6369, 0.6482, 0.6183, 0.4780, 0.6148,\n",
       "         0.5820, 0.6238, 0.5965, 0.6268, 0.5843, 0.5826, 0.5773, 0.5540, 0.5909,\n",
       "         0.6507, 0.6479, 0.5798],\n",
       "        [0.6471, 0.6019, 0.6348, 0.5816, 0.5756, 0.6616, 0.4651, 0.5345, 0.6089,\n",
       "         0.6247, 0.5444, 0.6177, 0.6502, 0.6547, 0.6144, 0.5816, 0.4625, 0.5935,\n",
       "         0.5642, 0.6201, 0.5974, 0.6510, 0.5357, 0.5972, 0.6014, 0.5406, 0.5782,\n",
       "         0.6223, 0.6029, 0.5897],\n",
       "        [0.5510, 0.5226, 0.5783, 0.5205, 0.5158, 0.5303, 0.4630, 0.5080, 0.4899,\n",
       "         0.5615, 0.5139, 0.5147, 0.5175, 0.5427, 0.5537, 0.4966, 0.5162, 0.5124,\n",
       "         0.4741, 0.5553, 0.4938, 0.5455, 0.4847, 0.5132, 0.4974, 0.4807, 0.5032,\n",
       "         0.5341, 0.5132, 0.5102]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_encoded(df, 2) #give the tensor of the complete embedded tweet (each 3 letter)\n",
    "\n",
    "#sentence_encoded(3).shape\n",
    "#30 for the alphabet size \n",
    "#the first argument is the tweet lenght"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">4. NN coupled with RNN to find the rt </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_feelings=5 #return of RNN part\n",
    "n_mainstream=5+3 #followers, likes, verified... data that didn't get treated (no need) (after normalisation) +time\n",
    "n_PCA_words=4 #after PCA on words\n",
    "n_PCA_hashtag=3 #after PCA on hashtags\n",
    "\n",
    "final_dim=n_feelings+n_mainstream+n_PCA_words+n_PCA_hashtag\n",
    "final_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">4.1 RNN on embedded words: Understanding relations between words to extract a general opinion/feeling from the tweet</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeelingsFinder(nn.Module):\n",
    "    \n",
    "    def __init__(self,device):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        #RNN layer (30 for the input word vectors and 5 for the feeling vector of previous run)\n",
    "        self.recurrNN=nn.RNN(30, n_feelings)\n",
    "        #30 is the input vector and n_feelings the output vector\n",
    "        self.lin=nn.Linear(n_feelings,n_feelings)\n",
    "        #the rnn output 2 vectors : 1 output \"normal\" and one for the repetition\n",
    "        #the two args need to have the same size because the layer is expected to receive a same size input \n",
    "        \n",
    "    def forward(self,x): #x is a matrix of vectorised sentence\n",
    "            \n",
    "        #initialize first feeling vector \n",
    "        h=torch.zeros(1,n_feelings).to(device)\n",
    "        \n",
    "        #feed forward (x of shape (number of patches of 3, 100))\n",
    "        for i in range(x.shape[0]):\n",
    "            #we dont have to pay attention to the \"h\", because the thing we return is the \"out\" after it passed through the linear layer\n",
    "            out, _ =self.recurrNN(x[i:i+1,:],h)\n",
    "            out=self.lin(out)\n",
    "            h=out\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "ff = FeelingsFinder(\"cuda:0\").to(device)\n",
    "ff\n",
    "\n",
    "dummy_input = torch.rand((40, 30)).to(device)\n",
    "dummy_input\n",
    "\n",
    "print(ff(dummy_input).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">4.2 NN to find out rt: takes as input the output of RNN & all the treated dimensions above (2 PCAs, normalised mainstream dimensions...)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RTFinder(nn.Module):\n",
    "    \n",
    "    def __init__(self,device):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.NN=nn.Sequential(\n",
    "        \n",
    "        nn.Linear(final_dim,10,bias=True),\n",
    "        nn.ReLU(True),\n",
    "            \n",
    "        nn.Linear(10,4,bias=True),\n",
    "        nn.ReLU(True),\n",
    "        \n",
    "        nn.Linear(4,1, bias=True),\n",
    "        nn.Sigmoid())\n",
    "        \n",
    "        self.feelings_finder = FeelingsFinder(\"cuda:0\").to(device)\n",
    "        \n",
    "    def forward(self, x, y): #x is concatenatioon of all dimensions and y same as x in forward of FeelingsFinder\n",
    "        \n",
    "        return self.NN(torch.cat((x.T,self.feelings_finder(y).T)).T)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-cb35f0155859>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdummy_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mRT\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mRTFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdummy_input2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-204-a2faf4fea1e8>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m     16\u001b[0m         nn.Sigmoid())\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeelings_finder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeelingsFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#x is concatenatioon of all dimensions and y same as x in forward of FeelingsFinder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# Resets _flat_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    983\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    984\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 985\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cuda_getDeviceCount'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             raise AssertionError(\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "dummy_input = torch.rand((40, 30)).to(device)\n",
    "\n",
    "RT= RTFinder(\"cuda:0\").to(device)\n",
    "\n",
    "dummy_input2 = torch.rand((1, 11)).to(device)\n",
    "dummy_input3 = torch.rand((1, 11)).to(device)\n",
    "\n",
    "#print(torch.cat((dummy_input2.T, dummy_input3.T)).T.shape)\n",
    "print(RT(dummy_input2, dummy_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_train(line):\n",
    "    concat_data=np.zeros((1, 15))\n",
    "    concat_data[0,0]=df[\"favorites_count\"][line]\n",
    "    concat_data[0,1]=df[\"followers_count\"][line]\n",
    "    concat_data[0,2]=df[\"friends_count\"][line]\n",
    "    concat_data[0,3]=df[\"statuses_count\"][line]\n",
    "    concat_data[0,4]=df[\"verified\"][line]\n",
    "    concat_data[0,5]=df[\"month\"][line]\n",
    "    concat_data[0,6]=df[\"day\"][line]\n",
    "    concat_data[0,7]=df[\"moment\"][line]\n",
    "    \n",
    "    #try to define the most important words so no need to redefine them later\n",
    "    \n",
    "    PCA_text=PCA_training(array_train_text,4)[0][line,:]\n",
    "    concat_data[0,8:12]=PCA_text\n",
    "    \n",
    "    PCA_hashtag=PCA_training(array_train_hashtags,3)[0][line,:]\n",
    "    concat_data[0,12:15]=PCA_hashtag\n",
    "    \n",
    "    return torch.tensor(concat_data).float(), sentence_encoded(df, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  0.6174,  0.7047,  0.8673,  0.0000,  0.1818,  0.4667,  0.4844,\n",
       "          -0.2490, -0.1701,  0.1340,  0.3202,  0.1854,  0.0083,  0.0022]]),\n",
       " tensor([[0.5338, 0.5873, 0.5199,  ..., 0.5088, 0.5851, 0.5890],\n",
       "         [0.6137, 0.6587, 0.5689,  ..., 0.5270, 0.6280, 0.6703],\n",
       "         [0.5712, 0.6200, 0.5121,  ..., 0.5128, 0.5971, 0.6053],\n",
       "         ...,\n",
       "         [0.6598, 0.7306, 0.5928,  ..., 0.5418, 0.7118, 0.7265],\n",
       "         [0.6048, 0.6294, 0.4940,  ..., 0.4988, 0.5953, 0.6436],\n",
       "         [0.5104, 0.5490, 0.4892,  ..., 0.5130, 0.5443, 0.5634]],\n",
       "        grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RTFinder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-f4b249c22820>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Training loop (train for each line)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mRT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRTFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprogressbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m35000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RTFinder' is not defined"
     ]
    }
   ],
   "source": [
    "#Training loop (train for each line)\n",
    "\n",
    "RT=RTFinder(\"cuda:0\").to(device)\n",
    "progressbar = tqdm(range(35000))\n",
    "loss=None\n",
    "loss_list=[]\n",
    "\n",
    "optimizer = Adam(RT.parameters(),lr=0.001)\n",
    "\n",
    "for line in progressbar:\n",
    "    print(line)\n",
    "    if loss is None:\n",
    "        optimizer.zero_grad()\n",
    "    x0, x1 = data_to_train(line)\n",
    "    x0 = x0.to(device)\n",
    "    x1 = x1.to(device)\n",
    "    rt=RT(x0, x1)\n",
    "    rt_target=df[\"retweets_count\"][line]\n",
    "    rt_target = torch.tensor(rt_target).to(device)\n",
    "    loss_func=nn.MSELoss()\n",
    "    \n",
    "    if loss is None:\n",
    "        loss=loss_func(rt, torch.tensor(rt_target).float())\n",
    "    else:\n",
    "        loss+=loss_func(rt, torch.tensor(rt_target).float())\n",
    "    \n",
    "    if line%500==0 and line!=0:\n",
    "        line/=500\n",
    "        torch.save(Emb.state_dict(),\"Final_Network.h5\")\n",
    "        \n",
    "        loss_list.append(loss.item()) #All this to update the loss plot\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(loss_list)\n",
    "        fig.savefig(\"loss plot.png\")\n",
    "        plt.close(fig)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Loss: {loss.item(): .6f}\")\n",
    "        #progressbar.set_description(f\"Loss: {loss.item(): .6f}\")\n",
    "        loss=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <span style=\"color:darkred\">5. Apply everything onto test dataset </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">5.1 Prepare test data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv('evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=Normaliser(df, df_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_test(line):\n",
    "    concat_data=np.zeros((1,15))\n",
    "    concat_data[0,0]=df_test[\"favorites_count\"][line]\n",
    "    concat_data[0,1]=df_test[\"followers_count\"][line]\n",
    "    concat_data[0,2]=df_test[\"friends_count\"][line]\n",
    "    concat_data[0,3]=df_test[\"statuses_count\"][line]\n",
    "    concat_data[0,4]=df_test[\"verified\"][line]\n",
    "    concat_data[0,5]=df_test[\"month\"][line]\n",
    "    concat_data[0,6]=df_test[\"day\"][line]\n",
    "    concat_data[0,7]=df_test[\"moment\"][line]\n",
    "    \n",
    "    PCA_text=PCA_test(array_train_text,array_test_text,4)[line,:]\n",
    "    concat_data[0,8:12]=PCA_text\n",
    "    \n",
    "    PCA_hashtag=PCA_test(array_train_hashtags,array_test_hashtags,3)[line,:]\n",
    "    concat_data[0,12:15]=PCA_hashtag\n",
    "    \n",
    "    return torch.tensor(concat_data).float(), sentence_encoded(df_test, line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000,  0.4784,  0.6956,  0.7490,  0.0000,  0.1818,  0.4333,  0.6095,\n",
       "          -0.2672,  0.7977, -0.9882, -0.4286,  0.9586,  0.2287,  0.1284]]),\n",
       " tensor([[0.6038, 0.6599, 0.5267,  ..., 0.5169, 0.6527, 0.6630],\n",
       "         [0.5199, 0.5452, 0.5117,  ..., 0.5204, 0.5313, 0.5580],\n",
       "         [0.5245, 0.5361, 0.5000,  ..., 0.5035, 0.5449, 0.5595],\n",
       "         ...,\n",
       "         [0.5749, 0.6163, 0.5218,  ..., 0.5286, 0.6239, 0.6370],\n",
       "         [0.5540, 0.5622, 0.5204,  ..., 0.5110, 0.5730, 0.6113],\n",
       "         [0.4974, 0.5407, 0.4867,  ..., 0.5145, 0.5320, 0.5514]],\n",
       "        grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_test(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:indigo\">5.2 Predict on the test data</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loss function : Mean Absolute Error (MAE) ->\n",
    "The MAE metric is calculated by dividing the sum of absolute differences between the predicted\n",
    "number of retweets (pi) and the observed number of retweets (ai) by the number of observations\n",
    "(N), i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(y_true, predictions):\n",
    "    y_true, predictions = np.array(y_true), np.array(predictions)\n",
    "    return np.mean(np.abs(y_true - predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval=mae(Y,predictions)\n",
    "print(eval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
